{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Scikit-learn Models to Amazon SageMaker with the SageMaker Python SDK using Script mode\n",
    "> The aim of this notebook is to demonstrate how to train and deploy a scikit-learn model in Amazon SageMaker using script mode.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [aws, ml, sagemaker]\n",
    "- keyword: [aws, ml, sagemaker, sklearn, scikit-learn, python]\n",
    "- image: images/copied_from_nb/images/2022-07-07-sagemaker-script-mode.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/2022-07-07-sagemaker-script-mode.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "You may have trained a model with your favorite ML framework, and now you are asked to move your code to Amazon SageMaker. The good news is that SageMaker's fully managed training works well with many popular ML frameworks, including `scikit-learn.` In addition, SageMaker provides its prebuilt container for the scikit-learn framework, enabling us to port our scripts to SageMaker and benefit from its training and deployment capabilities. SageMaker's scikit-learn container is an open source library for making the scikit-learn framework run on the Amazon SageMaker platform. You can read more about sklearn container features from its GitHub page [SageMaker Scikit-learn Container](https://github.com/aws/sagemaker-scikit-learn-container).\n",
    "\n",
    "Amazon SageMaker also provides open source Python SDK to train and deploy models on SageMaker. SageMaker SDK provides several high-level abstractions (classes), including:\n",
    "* `Session` Provides a collection of methods for working with SageMaker resources \n",
    "* `Estimators` Encapsulate training on SageMaker\n",
    "* `Predictors` Provide real-time inference and transformation using Python data types against a SageMaker endpoint\n",
    "You can read more on SageMaker Python SDK from its official site [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html)\n",
    "\n",
    "This approach of using a custom training script with SageMaker's prebuilt container is commonly called **Script Mode**. To train a scikit-learn model by using the SageMaker Python SDK involves three steps:\n",
    "\n",
    "1. **Prepare a training script**. The training script is similar to any other scikit-learn training script that you might use outside of SageMaker\n",
    "2. **Create an Estimator object from class `sagemaker.sklearn.SKLearn`**. Scikit-learn estimator class handles end-to-end training and deployment of custom scikit-learn code. It will execute a scikit-learn script within a SageMaker Training Job. The managed scikit-learn environment is an Amazon-built Docker container that runs functions defined in the supplied `entry_point` Python script. \n",
    "3. **Call the Estimator's `fit` method on training data**. Training is started by calling `fit()` on this Estimator. After training is complete, calling `deploy()` creates a hosted SageMaker endpoint and returns a `SKLearnPredictor` instance that can be used to perform inference against the hosted model. We will discuss the `SKLearn` Estimator in more detail later in this post.\n",
    "\n",
    "To read more about using scikit-learn with the SageMaker Python SDK, you may refer to the official documentation [using Scikit-learn with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html). The official documentation is valuable, and I would highly recommend checking it and keeping it as a reference.\n",
    "\n",
    "In this post we will built a scikit-learn [RandomForrestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) on [iris public dataset](https://archive.ics.uci.edu/ml/datasets/iris). There is a similar example in SageMaker documentation. [Train a SKLearn Model using Script Mode](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-script-mode/sklearn/sklearn_byom_outputs.html). Still, it does not discuss many important elements of a scikit-learn container and its environment. This post will cover all the stages of training a scikit-learn model with script mode. I also noted that the example in the documentation uses `RandomForrestRegressor` on a classification problem which I believe is a mistake.\n",
    "\n",
    "We have much to cover and learn, so let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "This notebook is prepared with AWS SageMaker notebook running on `ml.t3.medium` instance and \"cond_python3\" kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.22.97 Python/3.8.12 Linux/5.10.102-99.473.amzn2.x86_64 botocore/1.24.19\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Amazon Linux\"\n",
      "VERSION=\"2\"\n",
      "ID=\"amzn\"\n",
      "ID_LIKE=\"centos rhel fedora\"\n",
      "VERSION_ID=\"2\"\n",
      "PRETTY_NAME=\"Amazon Linux 2\"\n",
      "ANSI_COLOR=\"0;33\"\n",
      "CPE_NAME=\"cpe:2.3:o:amazon:amazon_linux:2\"\n",
      "HOME_URL=\"https://amazonlinux.com/\"\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/ec2-user/anaconda3\n",
      "JupyterSystemEnv         /home/ec2-user/anaconda3/envs/JupyterSystemEnv\n",
      "R                        /home/ec2-user/anaconda3/envs/R\n",
      "amazonei_mxnet_p36       /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36\n",
      "amazonei_pytorch_latest_p37     /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37\n",
      "amazonei_tensorflow2_p36     /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36\n",
      "mxnet_p37                /home/ec2-user/anaconda3/envs/mxnet_p37\n",
      "python3               *  /home/ec2-user/anaconda3/envs/python3\n",
      "pytorch_p38              /home/ec2-user/anaconda3/envs/pytorch_p38\n",
      "tensorflow2_p38          /home/ec2-user/anaconda3/envs/tensorflow2_p38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and test data\n",
    "We will use **Iris flower dataset**. It includes three iris species (Iris setosa, Iris virginica, and Iris versicolor) with 50 samples each and some properties about each flower. You can read more about this dataset at [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class: Iris Setosa, Iris Versicolour, Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# download dataset\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\", \"datasets/tabular/iris/iris.data\", \"iris.data\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"iris.data\",\n",
    "    header=None,\n",
    "    names=[\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"class\"],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "      <th>class_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class  class_cat\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa          0\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa          0\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa          0\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa          0\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# Convert the three classes from strings to integers in {0,1,2}\n",
    "df[\"class_cat\"] = df[\"class\"].astype(\"category\").cat.codes\n",
    "categories_map = dict(enumerate(df[\"class\"].astype(\"category\").cat.categories))\n",
    "print(categories_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and store train and test sets as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (120, 6)\n",
      "test.shape: (30, 6)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "print(f\"test.shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our dataset ready. Let's define a local directory where we keep all the files and artifacts related to this post. I will refer to this directory as 'workspace'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# `local_path` will be the root directory for this post.\n",
    "local_path = \"./datasets/2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have train and test sets ready. Let's create two more directories in our workspace and store our data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_train_path: ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "local_test_path: ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "local_train_file: ./datasets/2022-07-07-sagemaker-script-mode/train/train.csv\n",
      "local_test_file: ./datasets/2022-07-07-sagemaker-script-mode/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# local paths\n",
    "local_train_path = f\"{local_path}/train\"\n",
    "local_test_path = f\"{local_path}/test\"\n",
    "\n",
    "# create local directories\n",
    "Path(local_train_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(local_test_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"local_train_path: {local_train_path}\")\n",
    "print(f\"local_test_path: {local_test_path}\")\n",
    "\n",
    "# local file names\n",
    "local_train_file = local_train_path + \"/train.csv\"\n",
    "local_test_file = local_test_path + \"/test.csv\"\n",
    "\n",
    "# write train and test CSV files\n",
    "train.to_csv(local_train_file, index=False)\n",
    "test.to_csv(local_test_file, index=False)\n",
    "\n",
    "print(f\"local_train_file: {local_train_file}\")\n",
    "print(f\"local_test_file: {local_test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.__version__: 2.86.2\n",
      "Session: <sagemaker.session.Session object at 0x7fb74511bfd0>\n",
      "Role: arn:aws:iam::801598032724:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "Bucket: sagemaker-us-east-1-801598032724\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "\n",
    "print(f\"sagemaker.__version__: {sagemaker.__version__}\")\n",
    "print(f\"Session: {session}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done is\n",
    "* imported the SageMaker Python SDK into our runtime\n",
    "* get a session to work with SageMaker API and other AWS services\n",
    "* get the execution role associated with the user profile. It is the same profile that is available to the user to work from console UI and has `AmazonSageMakerFullAccess` policy attached to it.\n",
    "* create or get a default bucket to use and return its name. Default bucket name has the format `sagemaker-{region}-{account_id}`. If it doesn't exist then our session will automatically create it. You may also use any other bucket in its place given that you have enough permission for reading and writing.\n",
    "* get the region name attached to our session\n",
    "\n",
    "Next, we will use this session to upload data to our default bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# You may choose any other prefix for your bucket.\n",
    "# All the data related to this post will be under this prefix.\n",
    "bucket_prefix = \"2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload the data. In the output, we will get the complete path (S3 URI) for our uploaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_train_uri: s3://sagemaker-us-east-1-801598032724/2022-07-07-sagemaker-script-mode/data/train.csv\n",
      "s3_test_uri: s3://sagemaker-us-east-1-801598032724/2022-07-07-sagemaker-script-mode/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "s3_train_uri = session.upload_data(local_train_file, key_prefix=bucket_prefix + \"/data\")\n",
    "s3_test_uri = session.upload_data(local_test_file, key_prefix=bucket_prefix + \"/data\")\n",
    "\n",
    "print(f\"s3_train_uri: {s3_train_uri}\")\n",
    "print(f\"s3_test_uri: {s3_test_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point our data preparation step is complete. Training and test CSV files are available both on the local system, and in our default Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker local environment\n",
    "The Amazon SageMaker training environment is managed, but SageMaker Python SDK also supports **local mode**, allowing you to train and deploy models to your local environment. This is a great way to test training scripts before running them in SageMaker's managed training or hosting environment.\n",
    "\n",
    "## How SageMaker managed environment works?\n",
    "When you send a request to SageMaker API (fit or deploy call)\n",
    "* it spins up new instances with the provided specification\n",
    "* loads the algorithm container\n",
    "* pulls the data from S3\n",
    "* runs the training code\n",
    "* store the results and trained model artifacts to S3\n",
    "* terminates the new instances\n",
    "\n",
    "All this happens behind the scenes with a single line of code and is a huge advantage. Spinning up new hardware every time can be good for repeatability and security, but it can add some friction while testing and debugging our code. We can test our code on a small dataset in our local environment with SageMaker local mode and then switch seamlessly to SageMaker managed environment by changing a single line of code.\n",
    "\n",
    "## Steps to prepare Amazon SageMaker local environment\n",
    "Install the following pre-requisites if you want to set up Amazon SageMaker on your local system.\n",
    "1. Install required Python packages:\n",
    "    ```\n",
    "    pip install boto3 sagemaker pandas scikit-learn\n",
    "    pip install 'sagemaker[local]'\n",
    "    ```\n",
    "2. Docker Desktop installed and running on your computer:\n",
    "    ```\n",
    "    docker ps\n",
    "    ```\n",
    "3. You should have AWS credentials configured on your local machine to be able to pull the docker image from ECR.\n",
    "\n",
    "### Instructions for SageMaker notebook instances\n",
    "You can also set up SageMaker's local environment in SageMaker notebook instances. Required Python packages and Docker service is already there. You only need to upgrade the `sagemaker[local]` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.86.2)\n",
      "Collecting sagemaker[local]\n",
      "  Downloading sagemaker-2.99.0.tar.gz (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.7/542.7 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<22,>=20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (20.3.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.21.42)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.20.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.3.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: urllib3==1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.26.8)\n",
      "Requirement already satisfied: docker-compose==1.29.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: docker~=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.0.3)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.20.0)\n",
      "Requirement already satisfied: websocket-client<1,>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.7.0)\n",
      "Collecting botocore<1.25.0,>=1.24.42\n",
      "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.5.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker[local]) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker[local]) (3.0.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2021.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker~=5.0.0->sagemaker[local]) (2.10.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (59.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2021.10.8)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (36.0.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (2.21)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.99.0-py2.py3-none-any.whl size=756462 sha256=4d372e4c8d01cf27f517215525f83cf711378fce26d91a18ef4af5cf6807b1a9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/fc/df/14/14b7871f4cf108cfe8891338510d97e28cfe2da00f37114fcf\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: botocore, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.19\n",
      "    Uninstalling botocore-1.24.19:\n",
      "      Successfully uninstalled botocore-1.24.19\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.86.2\n",
      "    Uninstalling sagemaker-2.86.2:\n",
      "      Successfully uninstalled sagemaker-2.86.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.22.97 requires botocore==1.24.42, but you have botocore 1.24.46 which is incompatible.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.24.46 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.24.46 sagemaker-2.99.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#collapse_output\n",
    "# this is required for SageMaker notebook instances\n",
    "!pip install 'sagemaker[local]' --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for SageMaker Studio environment\n",
    "Note that SageMaker local mode will not work in SageMaker Studio environment as it does not have docker service installed on instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker local session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.local.local_session.LocalSession at 0x7fb73bc07e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "session_local = LocalSession()\n",
    "session_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# configure local session\n",
    "session_local.config = {\"local\": {\"local_code\": True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker training script\n",
    "\n",
    "We will call our training script `train_and_serve.py` and place it in our workspace under the `/src` folder. Then, we will start with a simple `Hello World` message code. After that, we will update and complete our training script as we learn more about the SageMaker `scikit-learn` container environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_file_name: train_and_serve.py\n",
      "script_path: ./datasets/2022-07-07-sagemaker-script-mode/src\n",
      "script_file: ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "script_file_name = \"train_and_serve.py\"\n",
    "script_path = f\"{local_path}/src\"\n",
    "script_file = script_path + \"/\" + script_file_name\n",
    "\n",
    "print(f\"script_file_name: {script_file_name}\")\n",
    "print(f\"script_path: {script_path}\")\n",
    "print(f\"script_file: {script_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the directory exists\n",
    "Path(script_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*** Hello from the SageMaker script mode***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker SKLearn estimator\n",
    "\n",
    "To use our `train_and_serve.py` script with SageMaker SKLearn estimator, we need to provide the following required items\n",
    "* **`entry_point (str)`** Path (absolute or relative) to the Python source file, which should be executed as the entry point to training. If source_dir is specified, then entry_point must point to a file located at the root of source_dir.\n",
    "* **`framework_version (str)`** Scikit-learn version you want to use for executing your model training code.\n",
    "* **`role (str)`** An AWS IAM role (either name or full ARN)\n",
    "* **`instance_type (str)`** Type of instance to use for training. For local mode use string **`local`**\n",
    "* **`instance_count (int)`** Number of instances to use for training. Since we will train in the local environment and have a single instance, we will use '1' here.\n",
    "\n",
    "You can read more about the SKLearn Estimator class from the official documentation [Scikit Learn Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the SKLearn framework version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that version number `1.0.1` has to be provided to the SKLearn estimator class as **`1.0-1`**. Otherwise, you will get the following error message.\n",
    "```\n",
    "ValueError: Unsupported sklearn version: 1.0.1. You may need to upgrade your SDK version (pip install -U sagemaker) for newer sklearn versions. Supported sklearn version(s): 0.20.0, 0.23-1, 1.0-1.\n",
    "```\n",
    "\n",
    "Now let us create the SageMaker SKLearn estimator object and pass our training script to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0oypp60t6a-algo-1-z7ju5 ... \n",
      "Creating 0oypp60t6a-algo-1-z7ju5 ... done\n",
      "Attaching to 0oypp60t6a-algo-1-z7ju5\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:43,823 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:43,827 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:43,836 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:44,047 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:44,060 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:44,071 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:44,079 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m Training Env:\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m {\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"current_host\": \"algo-1-z7ju5\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m         \"algo-1-z7ju5\"\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     ],\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-14-17-49-30-667\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"master_hostname\": \"algo-1-z7ju5\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-49-30-667/source/sourcedir.tar.gz\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m         \"current_host\": \"algo-1-z7ju5\",\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m             \"algo-1-z7ju5\"\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m         ]\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     },\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m }\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m Environment variables:\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_HOSTS=[\"algo-1-z7ju5\"]\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_HPS={}\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-z7ju5\",\"hosts\":[\"algo-1-z7ju5\"]}\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_CURRENT_HOST=algo-1-z7ju5\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-49-30-667/source/sourcedir.tar.gz\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-z7ju5\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-z7ju5\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-14-17-49-30-667\",\"log_level\":20,\"master_hostname\":\"algo-1-z7ju5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-49-30-667/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-z7ju5\",\"hosts\":[\"algo-1-z7ju5\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m /miniconda3/bin/python train_and_serve.py\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m \n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 |\u001b[0m 2022-07-14 17:50:44,104 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m0oypp60t6a-algo-1-z7ju5 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    framework_version=\"1.0-1\",\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first run the SKLearn estimator, executing it may take some time as it has to download the scikit-learn container to the local docker environment. You will get the container logs in the output when the container completes the execution. The logs show that the container has successfully run the training script, and the `hello` message is also printed. But there is a lot more information available in the logs. So in the coming section, we will discuss that.\n",
    "\n",
    "![sklearn-output-1](images/2022-07-07-sagemaker-script-mode/sklearn-output-1.png)\n",
    "\n",
    "# Understanding SKLearn container output and environment varaibles\n",
    "From the SKLearn estimator output, we can see that our `train_and_server.py` script is executed by the container with the following command.\n",
    "\n",
    "```\n",
    "/miniconda3/bin/python train_and_server.py\n",
    "```\n",
    "\n",
    "## Inspecting SageMaker SKLearn docker image\n",
    "Since the container was executed in the local environment, we can also inspect the SageMaker SKLearn local image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                            TAG             IMAGE ID       CREATED      SIZE\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn   1.0-1-cpu-py3   8a6ea8272ad0   7 days ago   3.7GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the docker image. Notice the multiple container environment variables and their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Id\": \"sha256:8a6ea8272ad003ec816569b0f879b16c770116584301161565f065aadb99436c\",\n",
      "        \"RepoTags\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3\"\n",
      "        ],\n",
      "        \"RepoDigests\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:fc8c3a617ff0e436c25f3b64d03e1f485f1d159478c26757f3d1d267fc849445\"\n",
      "        ],\n",
      "        \"Parent\": \"\",\n",
      "        \"Comment\": \"\",\n",
      "        \"Created\": \"2022-07-06T18:55:02.854297671Z\",\n",
      "        \"Container\": \"11b9a5fec2d61294aee63e549100ed18ceb7aa0de6a4ff198da2f556dfe3ec2f\",\n",
      "        \"ContainerConfig\": {\n",
      "            \"Hostname\": \"11b9a5fec2d6\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"/bin/sh\",\n",
      "                \"-c\",\n",
      "                \"#(nop) \",\n",
      "                \"LABEL transform_id=9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:58b15b990d550868caed6f885423deee97a6c7f525c228a043096bf28e775d18\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6086988568\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"DockerVersion\": \"20.10.15\",\n",
      "        \"Author\": \"\",\n",
      "        \"Config\": {\n",
      "            \"Hostname\": \"\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"bash\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:58b15b990d550868caed6f885423deee97a6c7f525c228a043096bf28e775d18\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6086988568\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"Architecture\": \"amd64\",\n",
      "        \"Os\": \"linux\",\n",
      "        \"Size\": 3699696670,\n",
      "        \"VirtualSize\": 3699696670,\n",
      "        \"GraphDriver\": {\n",
      "            \"Data\": {\n",
      "                \"LowerDir\": \"/var/lib/docker/overlay2/b46666b981d5a4997a22665495b1fa000628d9208783ae20c66718e3734a4c0a/diff:/var/lib/docker/overlay2/71e41da89849c5db5fc437a9fc74e39d000b9984b03a8692a3453bc9fae8f79d/diff:/var/lib/docker/overlay2/544103a4030c96fb57d4bd72775ee9d21d31a25515ed7681aa82233db2b60cc5/diff:/var/lib/docker/overlay2/6fd80d253a5853e39fc7e826113bdd1de9e6b7f83d7017b00b73bc13a943a618/diff:/var/lib/docker/overlay2/2f9bc65ce064f1c84741ca8bb2eac84146aa51cc64b01d86dbc98741c46716d6/diff:/var/lib/docker/overlay2/3f2afb469627a33c345fdc96f48a5209147b0f0347f53a777cd084026685ba97/diff:/var/lib/docker/overlay2/ae148bc573458cddd1eebb8c0d3fb35b624bd78237fb23d713b003bbb0b65d80/diff:/var/lib/docker/overlay2/d21004ec07fd7f53c3faa4db2bd5ee27c82542c41f6cfd30370c308e5001f477/diff:/var/lib/docker/overlay2/99b16ceb1e30993f79050f5134cda6166b4cf5553239ac03dbd03b970a8aa572/diff:/var/lib/docker/overlay2/76de465562bfe1b000712cc9063d0ba3c5d973169dedc3c90f2e5d0a06b32dad/diff:/var/lib/docker/overlay2/a13bf7f7ecf27e3d0391cba959a37762b12e045ac048758ab438cc849ab8018c/diff:/var/lib/docker/overlay2/cee652bb563dd5346cfaae5bd23edf6860ea6cfa9e0eb3aafdc192704f38cdf3/diff:/var/lib/docker/overlay2/d24fd094e9d930b223b6651793c5c0e90e1aa82db69599eabaaacec26b2400d7/diff:/var/lib/docker/overlay2/4187d87dfada6e53f06e2eb98cdea26dfa9383c55e715d470b81be5703840f10/diff:/var/lib/docker/overlay2/555a4d1f80bb8048a76944f14664bb811576d3664943de0b104df55fa8d9db5f/diff:/var/lib/docker/overlay2/71dd73b19a47b33b6ba7781cbeac6edcdf3792623870e667be5a53f0dbf84c86/diff:/var/lib/docker/overlay2/4f40b4d926021e62ffd6b8ff429fee7f23f1aa613b1628461cd560ca8ff95d4c/diff\",\n",
      "                \"MergedDir\": \"/var/lib/docker/overlay2/6242b3a02f9c631975433cdacb1fbab5b91d5496d14f0d8b7db441e9d94d4887/merged\",\n",
      "                \"UpperDir\": \"/var/lib/docker/overlay2/6242b3a02f9c631975433cdacb1fbab5b91d5496d14f0d8b7db441e9d94d4887/diff\",\n",
      "                \"WorkDir\": \"/var/lib/docker/overlay2/6242b3a02f9c631975433cdacb1fbab5b91d5496d14f0d8b7db441e9d94d4887/work\"\n",
      "            },\n",
      "            \"Name\": \"overlay2\"\n",
      "        },\n",
      "        \"RootFS\": {\n",
      "            \"Type\": \"layers\",\n",
      "            \"Layers\": [\n",
      "                \"sha256:1dc52a6b4de8561423dd3ec5a1f7f77f5309fd8cb340f80b8bc3d87fa112003e\",\n",
      "                \"sha256:b13a10ce059365d68a2113e9dbcac05b17b51f181615fca6d717a0dcf9ba8ffb\",\n",
      "                \"sha256:790d00cf365a312488151b354f0b0ae826be031edffb8a4de6a1fab048774dc7\",\n",
      "                \"sha256:323e43c53a1cd5abbd55437588f19da04f716452bc6d05486759b35f3e485390\",\n",
      "                \"sha256:c99c9d462af0bac5511ed046178ab0de79b8cdad33cd85246e9f661e098426cd\",\n",
      "                \"sha256:4a3a4d9fb4d250b1b64629b23bc0a477a45ee2659a8410d59a31a181dad70002\",\n",
      "                \"sha256:27b35f432a27e5e275038e559ebbe1aa7e91447bf417f5da01e3326739ba9366\",\n",
      "                \"sha256:ee12325fe0b7e7930b76d9a3dc81fcc37fa51a3267b311d2ed7c38703f193d75\",\n",
      "                \"sha256:7ceb40593535cdc07299efa2ce3a2c2267c2fa683161515fd6ab97f733492bf0\",\n",
      "                \"sha256:f18dbe0eec054f0aedf54a94aa29dab0d2c0f3d920fb482c99819622b0094f47\",\n",
      "                \"sha256:df2a7845ea611463f9f3282ccb45156ba883f40b15013ee49bd0a569301738d8\",\n",
      "                \"sha256:bcbd5416b87e3e37e05c22e46cbff2e3503d9caa0ec283a44931dc63e51c8cb7\",\n",
      "                \"sha256:5bcbb3ccae766c8a72d98ce494500bfd44c32e5780a1cb153139a4c5c143a8d5\",\n",
      "                \"sha256:4ecc8a8ffa902f3ea9bebb8d610e02a32ce1ca94c1a3160a31da98b73c1f55a0\",\n",
      "                \"sha256:a7a7b8b26735eb2d137fd0f91b83c73ad48cf2c4b83e9d0cadece410d6e598ba\",\n",
      "                \"sha256:ae939a0c9d32674ad6674947853ecfda4ff0530a8137960064448ae5e45fa1c5\",\n",
      "                \"sha256:6948f39c8f3cf6ec104734ccd1112fcb4af85a7c26c9c3d43495494b9b799f25\",\n",
      "                \"sha256:affd18c8e88f35e75bd02158e0418f3aeb4eec4269a208ede24cc829fa88c850\"\n",
      "            ]\n",
      "        },\n",
      "        \"Metadata\": {\n",
      "            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!docker inspect 8a6ea8272ad0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass hyperparameters to SKLearn estimator\n",
    "\n",
    "Let's pass some dummy hyperparameters to the estimator and see how it affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 6pvujd9waw-algo-1-qiig3 ... \n",
      "Creating 6pvujd9waw-algo-1-qiig3 ... done\n",
      "Attaching to 6pvujd9waw-algo-1-qiig3\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,514 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,518 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,526 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,718 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,730 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,742 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,751 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m Training Env:\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m {\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"current_host\": \"algo-1-qiig3\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m         \"algo-1-qiig3\"\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     ],\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     },\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-14-17-51-43-520\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"master_hostname\": \"algo-1-qiig3\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-51-43-520/source/sourcedir.tar.gz\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m         \"current_host\": \"algo-1-qiig3\",\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m             \"algo-1-qiig3\"\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m         ]\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     },\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m }\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m Environment variables:\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_HOSTS=[\"algo-1-qiig3\"]\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-qiig3\",\"hosts\":[\"algo-1-qiig3\"]}\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_CURRENT_HOST=algo-1-qiig3\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-51-43-520/source/sourcedir.tar.gz\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-qiig3\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-qiig3\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-14-17-51-43-520\",\"log_level\":20,\"master_hostname\":\"algo-1-qiig3\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-51-43-520/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-qiig3\",\"hosts\":[\"algo-1-qiig3\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m \n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 |\u001b[0m 2022-07-14 17:51:45,776 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m6pvujd9waw-algo-1-qiig3 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-hyperparams](images/2022-07-07-sagemaker-script-mode/sklearn-output-hyperparams.png)\n",
    "\n",
    "From the output we can see that our hyperparameters were passed to our training script as command line arguments. This is an important point and we will update our script using this information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker SKLearn container environment variables\n",
    "Let's now discuss the essential environment variables we see in the output.\n",
    "\n",
    "### SM_MODULE_DIR\n",
    "```\n",
    "SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\n",
    "```\n",
    "`SM_MODULE_DIR` points to a location in the S3 bucket where SageMaker will automatically backup our source code for that particular run. SageMaker will create a separate folder in the default bucket for each new run. The default value is `s3://sagemaker-{aws-region}-{aws-id}/{training-job-name}/source/sourcedir.tar.gz`\n",
    "\n",
    "### SM_MODEL_DIR\n",
    "```\n",
    "SM_MODEL_DIR=/opt/ml/model\n",
    "```\n",
    "`SM_MODEL_DIR` points to a directory located inside the container. When the training job finishes, the container and its file system will be deleted, except for the `/opt/ml/model` and `/opt/ml/output` directories. Use `/opt/ml/model` to save the trained model artifacts. These artifacts are uploaded to S3 for model hosting.\n",
    "\n",
    "### SM_OUTPUT_DATA_DIR\n",
    "```\n",
    "SM_OUTPUT_DIR=/opt/ml/output\n",
    "```\n",
    "`SM_OUTPUT_DIR` points to a directory in the container to write output artifacts. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "### SM_CHANNELS\n",
    "From the SKLearn estimator output\n",
    "```\n",
    "SM_CHANNELS='[\"testing\",\"training\"]'\n",
    "```\n",
    "A channel is a named input source that training algorithms can consume. You can partition your training data into different logical \"channels\" when you run training. Depending on your problem, some common channel ideas are: \"training\", \"testing\", \"evaluation\" or \"images\" and \"labels\". You can read more about the channels from SageMaker API reference [Channel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Channel.html)\n",
    "\n",
    "### SM_CHANNEL_{channel_name}\n",
    "```\n",
    "SM_CHANNEL_TRAIN='/opt/ml/input/data/train'\n",
    "SM_CHANNEL_TEST='/opt/ml/input/data/test'\n",
    "```\n",
    "Supposing that you have passed two input channels, 'train' and 'test', to the Scikit-learn estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "* **`SM_CHANNEL_TRAIN`**: it points to the directory in the container that has the *train* channel data downloaded\n",
    "* **`SM_CHANNEL_TEST`**: Same as above, but for the *test* channel\n",
    "\n",
    "Note that the channel names `train` and `test` are the conventions. Still, you can use any name here, and the environment variables will be created accordingly. It is important to know that the SageMaker container automatically downloads the data from the provided input channels and makes them available in the respective local directories once it starts executing. The training script can then load the data from the local container directories.\n",
    "\n",
    "There are more environment variables available, and you can read about them from [Environment variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass input channel to SKLearn estimator\n",
    "\n",
    "Now that we understand the SKLearn container environment more let's pass the training data channel to the estimator and see if the data becomes available inside the container directory. \n",
    "\n",
    "Update our script to list all the files in the `SM_CHANNEL_TRAIN` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "\n",
    "    print(\"training_dir files list: \", dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating h0qjzqwkwe-algo-1-s9ja7 ... \n",
      "Creating h0qjzqwkwe-algo-1-s9ja7 ... done\n",
      "Attaching to h0qjzqwkwe-algo-1-s9ja7\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:02,846 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:02,850 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:02,859 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:03,062 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:03,075 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:03,088 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:03,097 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m Training Env:\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m {\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     },\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"current_host\": \"algo-1-s9ja7\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"algo-1-s9ja7\"\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     ],\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     },\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"train\": {\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         }\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     },\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-14-17-52-00-069\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"master_hostname\": \"algo-1-s9ja7\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-52-00-069/source/sourcedir.tar.gz\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"current_host\": \"algo-1-s9ja7\",\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m             \"algo-1-s9ja7\"\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m         ]\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     },\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m }\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m Environment variables:\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_HOSTS=[\"algo-1-s9ja7\"]\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-s9ja7\",\"hosts\":[\"algo-1-s9ja7\"]}\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_CURRENT_HOST=algo-1-s9ja7\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-52-00-069/source/sourcedir.tar.gz\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-s9ja7\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-s9ja7\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-14-17-52-00-069\",\"log_level\":20,\"master_hostname\":\"algo-1-s9ja7\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-52-00-069/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-s9ja7\",\"hosts\":[\"algo-1-s9ja7\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 |\u001b[0m 2022-07-14 17:52:03,136 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mh0qjzqwkwe-algo-1-s9ja7 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": f\"file://{local_train_path}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[image here]**\n",
    "From the output, we can see that `train.csv`, which was in our local environment, is now available inside the container on path `SM_CHANNEL_TRAIN=/opt/ml/input/data/train`. \n",
    "\n",
    "Let's also test the same with our training data on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mhmxon0p5y-algo-1-ke1pv ... \n",
      "Creating mhmxon0p5y-algo-1-ke1pv ... done\n",
      "Attaching to mhmxon0p5y-algo-1-ke1pv\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,686 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,690 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,698 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,869 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,882 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,896 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,905 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m Training Env:\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m {\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     },\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"current_host\": \"algo-1-ke1pv\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"algo-1-ke1pv\"\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     ],\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     },\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"train\": {\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         }\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     },\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-14-17-53-06-569\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"master_hostname\": \"algo-1-ke1pv\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-06-569/source/sourcedir.tar.gz\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"current_host\": \"algo-1-ke1pv\",\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m             \"algo-1-ke1pv\"\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m         ]\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     },\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m }\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m Environment variables:\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_HOSTS=[\"algo-1-ke1pv\"]\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ke1pv\",\"hosts\":[\"algo-1-ke1pv\"]}\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_CURRENT_HOST=algo-1-ke1pv\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-06-569/source/sourcedir.tar.gz\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-ke1pv\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-ke1pv\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-14-17-53-06-569\",\"log_level\":20,\"master_hostname\":\"algo-1-ke1pv\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-06-569/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ke1pv\",\"hosts\":[\"algo-1-ke1pv\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv |\u001b[0m 2022-07-14 17:53:08,943 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mmhmxon0p5y-algo-1-ke1pv exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the results are the same. SageMaker will download the data from the S3 bucket and make it available in the container. In the environment variables section we also learned that two directories are special `/opt/ml/model` and `/opt/ml/output`. Container environment variables `SM_MODEL_DIR` and `SM_OUTPUT_DATA_DIR` point to them, respectively. Whatever artifacts we put on them will be stored on the S3 bucket when the training job finishes. \"SM_MODEL_DIR\" is for trained models, and \"SM_OUTPUT_DATA_DIR\" is for other artifacts like logs, graphs, plots, resutls, etc. Let's update our training script and put some dummy data in these directories. Once the job is complete, we will verify the stored artifacts on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    # list files in SM_CHANNEL_TRAIN\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "    print(\"training_dir files list: \", dir_list)\n",
    "\n",
    "    # write dummy model file to SM_MODEL_DIR\n",
    "    sm_model_dir = os.environ.get(\"SM_MODEL_DIR\")\n",
    "    with open(f\"{sm_model_dir}/dummy-model.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy model\")\n",
    "\n",
    "    # write dummy artifact file to SM_OUTPUT_DATA_DIR\n",
    "    sm_output_data_dir = os.environ.get(\"SM_OUTPUT_DATA_DIR\")\n",
    "    with open(f\"{sm_output_data_dir}/dummy-output-data.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy output data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating owmroyetvf-algo-1-8pa1g ... \n",
      "Creating owmroyetvf-algo-1-8pa1g ... done\n",
      "Attaching to owmroyetvf-algo-1-8pa1g\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:35,795 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:35,800 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:35,814 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:36,055 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:36,068 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:36,080 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:36,089 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m Training Env:\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m {\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     },\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"current_host\": \"algo-1-8pa1g\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"algo-1-8pa1g\"\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     ],\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     },\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"train\": {\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         }\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     },\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-14-17-53-33-172\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"master_hostname\": \"algo-1-8pa1g\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/source/sourcedir.tar.gz\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"current_host\": \"algo-1-8pa1g\",\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m             \"algo-1-8pa1g\"\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m         ]\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     },\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m }\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m Environment variables:\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_HOSTS=[\"algo-1-8pa1g\"]\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-8pa1g\",\"hosts\":[\"algo-1-8pa1g\"]}\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_CURRENT_HOST=algo-1-8pa1g\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/source/sourcedir.tar.gz\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-8pa1g\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-8pa1g\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-14-17-53-33-172\",\"log_level\":20,\"master_hostname\":\"algo-1-8pa1g\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-8pa1g\",\"hosts\":[\"algo-1-8pa1g\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g |\u001b[0m 2022-07-14 17:53:36,135 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mowmroyetvf-algo-1-8pa1g exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpiy02yv65/algo-1-8pa1g Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training job is now complete. Let us check the S3 bucket to see if our dummy model and other artifacts are present.\n",
    "\n",
    "First, we need the S3 URI for these artifacts. For our dummy model (from SM_MODEL_DIR), we can use our estimator object to get the URI. Let's call it `model_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/model.tar.gz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = sk_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_data` from S3 will be downloaded to a local directory for verification. Let's create a local `tmp` to store these downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/2022-07-07-sagemaker-script-mode/tmp\n"
     ]
    }
   ],
   "source": [
    "local_tmp_path = local_path + \"/tmp\"\n",
    "print(local_tmp_path)\n",
    "\n",
    "# create the local '/tmp' directory\n",
    "Path(local_tmp_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SageMaker `S3Downloader` object to download the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "S3Downloader.download(\n",
    "    s3_uri=model_data, local_path=local_tmp_path, sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File is downloaded. Let's uncompress it to verify the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy-model.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_tmp_path/model.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the \"dummy-model.txt\" file is present. This tells us that SageMaker will automatically upload the files from the model directory (SM_MODEL_DIR) to the S3 bucket. Let's do the same for the output data directory (SM_OUTPUT_DATA_DIR). There is no direct way to get the S3 URI from the estimator object for the output data directory. But we can prepare it ourselves. So let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator.output_path:  s3://sagemaker-us-east-1-801598032724/\n",
      "estimator.latest_training_job.name:  sagemaker-scikit-learn-2022-07-14-17-53-33-172\n"
     ]
    }
   ],
   "source": [
    "print(\"estimator.output_path: \", sk_estimator.output_path)\n",
    "print(\"estimator.latest_training_job.name: \", sk_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_s3_output_uri(estimator):\n",
    "    return estimator.output_path + estimator.latest_training_job.name\n",
    "    \n",
    "get_s3_output_uri(sk_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/output.tar.gz'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for output data artifacts\n",
    "s3_output_uri = get_s3_output_uri(sk_estimator) + '/output.tar.gz'\n",
    "s3_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/model.tar.gz'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "# S3 URI for model artifact. We have already veirifed it.\n",
    "s3_model_uri = get_s3_output_uri(sk_estimator) + '/model.tar.gz'\n",
    "s3_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/source/sourcedir.tar.gz'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for source code\n",
    "s3_source_uri = get_s3_output_uri(sk_estimator) + '/source/sourcedir.tar.gz'\n",
    "s3_source_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download these artifacts to our local '/tmp' directory for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/output.tar.gz to datasets/2022-07-07-sagemaker-script-mode/tmp/output.tar.gz\n",
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-14-17-53-33-172/source/sourcedir.tar.gz to datasets/2022-07-07-sagemaker-script-mode/tmp/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $s3_output_uri $local_tmp_path\n",
    "!aws s3 cp $s3_source_uri $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/dummy-output-data.txt\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# extract the output data files from 'output.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/output.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# extract the source code files from 'sourcedir.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/sourcedir.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary till now\n",
    "Let's summarize what we have learned till now.\n",
    "* We can use SageMaker SKLearn local mode to test our code in a local environment\n",
    "* SKLearn container executes our provided script with the command `/miniconda3/bin/python train_and_server.py`\n",
    "* Hyperparameters passed to the container are passed to our script as command line arguments\n",
    "* Data from input channels will be downloaded by the container and made available for our script to load and process\n",
    "* '/opt/ml/model' and '/opt/ml/output' directories are special. Anything stored on them will be automatically backed up on the S3 bucket when the job finishes. These directories are defined in the container environment variables 'SM_MODEL_DIR' and 'SM_OUTPUT_DATA_DIR', respectively. SM_MODEL_DIR should be used to write model artifacts. SM_OUTPUT_DATA_DIR should be used to write any other supporting artifact.\n",
    "\n",
    "Let's use this knowledge to update our script to train a RandomForrestClassifier on the Iris flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup /tmp directory before moving to next section\n",
    "!rm -r $local_tmp_path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"command line arguments: \", args)\n",
    "    \n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "    \n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    print(f\"testing_dir: {testing_dir}\") # print testing_dir path\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\") # print testing_dir files list\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    \n",
    "    \n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "    \n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir+\"/model.joblib\")\n",
    "    \n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir+\"/y_pred.csv\")\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x $script_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean model output directory\n",
    "!rm -r $local_model_path/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command line arguments:  Namespace(estimators=10, sm_channel_test='./datasets/2022-07-07-sagemaker-script-mode/test', sm_channel_train='./datasets/2022-07-07-sagemaker-script-mode/train', sm_model_dir='./datasets/2022-07-07-sagemaker-script-mode/model', sm_output_data_dir='./datasets/2022-07-07-sagemaker-script-mode/output/data')\n",
      "training_dir: ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "training_dir files list: ['train.csv', '.ipynb_checkpoints']\n",
      "testing_dir: ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "testing_dir files list: ['.ipynb_checkpoints', 'test.csv']\n",
      "sm_model_dir: ./datasets/2022-07-07-sagemaker-script-mode/model\n",
      "output_data_dir: ./datasets/2022-07-07-sagemaker-script-mode/output/data\n",
      "X_train.shape: (120, 4)\n",
      "y_train.shape: (120,)\n",
      "X_train.shape: (30, 4)\n",
      "y_train.shape: (30,)\n",
      "sm_model_dir: ./datasets/2022-07-07-sagemaker-script-mode/model\n",
      "sm_model_dir files list: ['.ipynb_checkpoints', 'model.joblib']\n"
     ]
    }
   ],
   "source": [
    "!python3 $script_file \\\n",
    "    --sm-model-dir $local_model_path \\\n",
    "    --sm-channel-train $local_train_path \\\n",
    "    --sm-channel-test $local_test_path \\\n",
    "    --sm-output-data-dir $local_output_data_path \\\n",
    "    --estimators 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/model'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have tested our script locally. so let's test this with SageMaker SKlean container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0b3yb3qvjt-algo-1-n90bz ... \n",
      "Creating 0b3yb3qvjt-algo-1-n90bz ... done\n",
      "Attaching to 0b3yb3qvjt-algo-1-n90bz\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,304 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,308 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,317 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,498 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,512 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,525 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,534 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m Training Env:\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"current_host\": \"algo-1-n90bz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"algo-1-n90bz\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     ],\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"train\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"test\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         }\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-06-03-671\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"master_hostname\": \"algo-1-n90bz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/source/sourcedir.tar.gz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"current_host\": \"algo-1-n90bz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m             \"algo-1-n90bz\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         ]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m }\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m Environment variables:\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_HOSTS=[\"algo-1-n90bz\"]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-n90bz\",\"hosts\":[\"algo-1-n90bz\"]}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CURRENT_HOST=algo-1-n90bz\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/source/sourcedir.tar.gz\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-n90bz\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-n90bz\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-06-03-671\",\"log_level\":20,\"master_hostname\":\"algo-1-n90bz\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-n90bz\",\"hosts\":[\"algo-1-n90bz\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:07,727 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp5kv1g_u7/algo-1-n90bz Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/model.tar.gz'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/output.tar.gz'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_uri = get_s3_output_uri(sk_estimator) + '/output.tar.gz'\n",
    "s3_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/output/data'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/2022-07-07-sagemaker-script-mode/output/data\n"
     ]
    }
   ],
   "source": [
    "print(local_output_data_path)\n",
    "\n",
    "!rm -r $local_output_data_path/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/output.tar.gz to datasets/2022-07-07-sagemaker-script-mode/output/data/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $s3_output_uri $local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/y_pred.csv\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_output_data_path/output.tar.gz -C $local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### requirements and custom_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task we need to generate confusion matrix using seaborn library and store it in output data driectory\n",
    "# create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom library to save a seaborn CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_library_path: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library\n",
      "custom_library_file: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "custom_library_path = local_path+\"/my_custom_library\"\n",
    "custom_library_file = custom_library_path+\"/seaborn_confusion_matrix.py\"\n",
    "\n",
    "print(f\"custom_library_path: {custom_library_path}\")\n",
    "print(f\"custom_library_file: {custom_library_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom library folder\n",
    "Path(custom_library_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import argparse, os\n",
    "\n",
    "def save_confusion_matrix(cf_matrix, path=\"./\"):\n",
    "    sns_plot = sns.heatmap(cf_matrix, annot=True)\n",
    "    sns_plot.figure.savefig(path+\"/output_cm.png\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--path\", type=str, default=\"./\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    path = args.path\n",
    "    \n",
    "    dummy_cm = np.array([[23,  5],[ 3, 30]])\n",
    "    save_confusion_matrix(dummy_cm, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_path/__init__.py\n",
    "\n",
    "from .seaborn_confusion_matrix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $custom_library_file --path $local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"command line arguments: \", args)\n",
    "    \n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "    \n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    print(f\"testing_dir: {testing_dir}\") # print testing_dir path\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\") # print testing_dir files list\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    \n",
    "    \n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "    \n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir+\"/model.joblib\")\n",
    "    \n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir+\"/y_pred.csv\")\n",
    "    \n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "    \n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\") # print sm_model_dir path\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\") # print sm_model_dir files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/src'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path/requirements.txt\n",
    "\n",
    "matplotlib==3.5.2\n",
    "seaborn==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 96mwnip853-algo-1-gcn8f ... \n",
      "Creating 96mwnip853-algo-1-gcn8f ... done\n",
      "Attaching to 96mwnip853-algo-1-gcn8f\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,389 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,393 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,403 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,574 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Collecting matplotlib==3.5.2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting seaborn==0.11.2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting pyparsing>=2.2.1\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Collecting cycler>=0.10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: numpy>=1.17 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 3)) (1.5.3)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 3)) (1.1.3)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 3)) (2022.1)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.5.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.3 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[0m2022-07-13 13:07:51,183 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:51,197 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:51,210 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:51,219 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Training Env:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"current_host\": \"algo-1-gcn8f\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"algo-1-gcn8f\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     ],\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"train\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"test\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         }\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-07-43-761\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"master_hostname\": \"algo-1-gcn8f\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-07-43-761/source/sourcedir.tar.gz\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"current_host\": \"algo-1-gcn8f\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m             \"algo-1-gcn8f\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         ]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m }\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Environment variables:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_HOSTS=[\"algo-1-gcn8f\"]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-gcn8f\",\"hosts\":[\"algo-1-gcn8f\"]}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CURRENT_HOST=algo-1-gcn8f\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-07-43-761/source/sourcedir.tar.gz\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-gcn8f\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-gcn8f\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-07-43-761\",\"log_level\":20,\"master_hostname\":\"algo-1-gcn8f\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-07-43-761/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-gcn8f\",\"hosts\":[\"algo-1-gcn8f\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:53,296 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp58lfmx49/algo-1-gcn8f Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a trained model. Can we deploy this model already?\n",
    "\n",
    "If I try to deploy this model using command\n",
    "```\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")\n",
    "```\n",
    "i will get exception messages \n",
    "```\n",
    "[2022-07-09 06:15:45 +0000] [31] [ERROR] Error handling request /ping\n",
    "Traceback (most recent call last):\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
    "    return fn(*args, **kwargs)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/serving.py\", line 43, in default_model_fn\n",
    "    return transformer.default_model_fn(model_dir)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 35, in default_model_fn\n",
    "    raise NotImplementedError(\n",
    "NotImplementedError: \n",
    "Please provide a model_fn implementation.\n",
    "See documentation for model_fn at https://github.com/aws/sagemaker-python-sdk\n",
    "```\n",
    "this is because Before a model can be served, it must be loaded. The SageMaker Scikit-learn model server loads your model by invoking a model_fn function that you must provide in your script. The model_fn should have the following signature:\n",
    "\n",
    "def model_fn(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.train\n",
    "    \n",
    "    # print training_dir info\n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X = df.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y = df[\"class_cat\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestRegressor(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(regressor, os.path.join(sm_model_dir, \"model.joblib\"))\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "\n",
    "    \n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [[9.0, 3571, 1976, 0.525]]\n",
    "\n",
    "response  = sk_predictor.predict(request)\n",
    "response = int(response[0])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted class category {} ({})\".format(response, categories_map[response]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "* if you are already running a local endpoint then you will not be able to create a new one. if you have lost the kernel session then you can delete the running endpoint from terminal using kill command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the inputs and outputs\n",
    "# input in json and output in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # do i need this?\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.train\n",
    "    \n",
    "    # print training_dir info\n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X = df.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y = df[\"class_cat\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestRegressor(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(regressor, os.path.join(sm_model_dir, \"model.joblib\"))\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "\n",
    "    \n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == \"application/json\":\n",
    "        request_body = json.loads(request_body)\n",
    "        inpVar = request_body[\"Input\"]\n",
    "        return inpVar\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {\"Output\": res}\n",
    "    return respJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri})\n",
    "\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_endpoint_name = sk_predictor.endpoint_name\n",
    "sk_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "client = session_local.sagemaker_runtime_client\n",
    "\n",
    "request_body = {\"Input\": [[9.0, 3571, 1976, 0.525]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=sk_endpoint_name, ContentType=\"application/json\", Body=payload\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())[\"Output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted class category {} ({})\".format(result, categories_map[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
