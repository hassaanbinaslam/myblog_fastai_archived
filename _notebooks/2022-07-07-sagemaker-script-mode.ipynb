{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Scikit-learn Models to Amazon SageMaker with the SageMaker Python SDK using Script mode\n",
    "> The aim of this notebook is to demonstrate how to train and deploy a scikit-learn model in Amazon SageMaker using script mode.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [aws, ml, sagemaker]\n",
    "- keyword: [aws, ml, sagemaker, sklearn, scikit-learn, python]\n",
    "- image: images/copied_from_nb/images/2022-07-07-sagemaker-script-mode.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/2022-07-07-sagemaker-script-mode.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "You may have trained a model with your favorite ML framework, and now you are asked to move your code to Amazon SageMaker. The good news is that SageMaker's fully managed training works well with many popular ML frameworks, including `scikit-learn`. In addition, SageMaker provides its prebuilt container for the scikit-learn framework, enabling us to seemlessly port our scripts to SageMaker and benefit from its training and deployment capabilities. SageMaker's scikit-learn Container is an open source library for making the scikit-learn framework run on the Amazon SageMaker platform. You can read more about sklearn container features from its GitHub page [SageMaker Scikit-learn Container](https://github.com/aws/sagemaker-scikit-learn-container).\n",
    "\n",
    "Amazon SageMaker also provides open source Python SDK to train and deploy models on SageMaker. SageMaker SDK provides several high-level abstractions (classes), including:\n",
    "* `Session` Provides a collection of methods for working with SageMaker resources \n",
    "* `Estimators` Encapsulate training on SageMaker\n",
    "* `Predictors` Provide real-time inference and transformation using Python data types against a SageMaker endpoint\n",
    "\n",
    "You can read more on SageMaker Python SDK from its official site [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html)\n",
    "\n",
    "This approach of using a custom training script with SageMaker's prebuilt container is commonly called as **Script Mode**. To train a scikit-learn model by using the SageMaker Python SDK involves three steps:\n",
    "\n",
    "1. **Prepare a training script**. The training script is similar to any other scikit-learn training script that you might use outside of SageMaker\n",
    "2. **Create an Estimator object from class `sagemaker.sklearn.SKLearn`**. Scikit-learn estimator class handles end-to-end training and deployment of custom scikit-learn code. We pass our training script to the SKLearn estimator, and it executes the script within a SageMaker Training Job. This training job is an Amazon-built Docker container that runs functions defined in the provided Python script. \n",
    "3. **Call the Estimator's `fit` method on training data**. Training is started by calling `fit()` on this Estimator. After training is complete, calling `deploy()` creates a hosted SageMaker endpoint and returns a `SKLearnPredictor` instance that can be used to perform inference against the hosted model. We will discuss the `SKLearn` Estimator in more detail later in this post.\n",
    "\n",
    "To read more about using scikit-learn with the SageMaker Python SDK, you may refer to the official documentation [using Scikit-learn with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html). The official documentation is valuable, and I would highly recommend checking it and keeping it as a reference.\n",
    "\n",
    "In this post we will built a scikit-learn [RandomForrestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) on [iris public dataset](https://archive.ics.uci.edu/ml/datasets/iris). There is a similar example in SageMaker documentation. [Train a SKLearn Model using Script Mode](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-script-mode/sklearn/sklearn_byom_outputs.html). But it does not discuss many important aspects of a scikit-learn container and its environment. In this post, we will learn about them and cover all the details of training a scikit-learn model with script mode. I also noted that the example in the documentation uses `RandomForrestRegressor` on a classification problem which I believe is a mistake.\n",
    "\n",
    "We have much to cover and learn, so let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "This notebook is prepared with AWS SageMaker notebook running on `ml.t3.medium` instance and \"conda_python3\" kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.22.97 Python/3.8.12 Linux/5.10.102-99.473.amzn2.x86_64 botocore/1.24.46\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Amazon Linux\"\n",
      "VERSION=\"2\"\n",
      "ID=\"amzn\"\n",
      "ID_LIKE=\"centos rhel fedora\"\n",
      "VERSION_ID=\"2\"\n",
      "PRETTY_NAME=\"Amazon Linux 2\"\n",
      "ANSI_COLOR=\"0;33\"\n",
      "CPE_NAME=\"cpe:2.3:o:amazon:amazon_linux:2\"\n",
      "HOME_URL=\"https://amazonlinux.com/\"\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/ec2-user/anaconda3\n",
      "JupyterSystemEnv         /home/ec2-user/anaconda3/envs/JupyterSystemEnv\n",
      "R                        /home/ec2-user/anaconda3/envs/R\n",
      "amazonei_mxnet_p36       /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36\n",
      "amazonei_pytorch_latest_p37     /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37\n",
      "amazonei_tensorflow2_p36     /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36\n",
      "mxnet_p37                /home/ec2-user/anaconda3/envs/mxnet_p37\n",
      "python3               *  /home/ec2-user/anaconda3/envs/python3\n",
      "pytorch_p38              /home/ec2-user/anaconda3/envs/pytorch_p38\n",
      "tensorflow2_p38          /home/ec2-user/anaconda3/envs/tensorflow2_p38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and test data\n",
    "We will use **Iris flower dataset**. It includes three iris species (Iris setosa, Iris virginica, and Iris versicolor) with 50 samples each. Four features were measured for each sample: the length and the width of the sepals and petals, in centimeters. We can train a model to distinguish the species from each other based on the combination of these four features. You can read more about this dataset at [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). The dataset has five columns representing.\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class: Iris Setosa, Iris Versicolour, Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# download dataset\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\", \"datasets/tabular/iris/iris.data\", \"iris.data\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"iris.data\",\n",
    "    header=None,\n",
    "    names=[\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"class\"],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "      <th>class_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class  class_cat\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa          0\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa          0\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa          0\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa          0\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# Convert the three classes from strings to integers in {0,1,2}\n",
    "df[\"class_cat\"] = df[\"class\"].astype(\"category\").cat.codes\n",
    "categories_map = dict(enumerate(df[\"class\"].astype(\"category\").cat.categories))\n",
    "print(categories_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and store train and test sets as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (120, 6)\n",
      "test.shape: (30, 6)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "print(f\"test.shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our dataset ready. Let's define a local directory `local_path` to keep all the files and artifacts related to this post. I will refer to this directory as 'workspace'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# `local_path` will be the root directory for this post.\n",
    "local_path = \"./datasets/2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have train and test sets ready. Let's create two more directories in our workspace and store our data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_train_path:  ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "local_test_path:  ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "local_train_file:  ./datasets/2022-07-07-sagemaker-script-mode/train/train.csv\n",
      "local_test_file:  ./datasets/2022-07-07-sagemaker-script-mode/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# local paths\n",
    "local_train_path = local_path + \"/train\"\n",
    "local_test_path = local_path + \"/test\"\n",
    "\n",
    "# create local directories\n",
    "Path(local_train_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(local_test_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"local_train_path: \", local_train_path)\n",
    "print(\"local_test_path: \", local_test_path)\n",
    "\n",
    "# local file names\n",
    "local_train_file = local_train_path + \"/train.csv\"\n",
    "local_test_file = local_test_path + \"/test.csv\"\n",
    "\n",
    "# write train and test CSV files\n",
    "train.to_csv(local_train_file, index=False)\n",
    "test.to_csv(local_test_file, index=False)\n",
    "\n",
    "print(\"local_train_file: \", local_train_file)\n",
    "print(\"local_test_file: \", local_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.__version__:  2.99.0\n",
      "Session:  <sagemaker.session.Session object at 0x7f6b5415c640>\n",
      "Role:  arn:aws:iam::801598032724:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "Bucket:  sagemaker-us-east-1-801598032724\n",
      "Region:  us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "\n",
    "print(\"sagemaker.__version__: \", sagemaker.__version__)\n",
    "print(\"Session: \", session)\n",
    "print(\"Role: \", role)\n",
    "print(\"Bucket: \", bucket)\n",
    "print(\"Region: \", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done here is\n",
    "* imported the SageMaker Python SDK into our runtime\n",
    "* get a session to work with SageMaker API and other AWS services\n",
    "* get the execution role associated with the user profile. It is the same profile that is available to the user to work from console UI and has `AmazonSageMakerFullAccess` policy attached to it.\n",
    "* create or get a default bucket to use and return its name. Default bucket name has the format `sagemaker-{region}-{account_id}`. If it doesn't exist then our session will automatically create it. You may also use any other bucket in its place given that you have enough permission for reading and writing.\n",
    "* get the region name attached to our session\n",
    "\n",
    "Next, we will use this session to upload data to our default bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# You may choose any other prefix for your bucket.\n",
    "# All the data related to this post will be under this prefix.\n",
    "bucket_prefix = \"2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload the data. In the output, we will get the complete path (S3 URI) for our uploaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_train_uri:  s3://sagemaker-us-east-1-801598032724/2022-07-07-sagemaker-script-mode/data/train.csv\n",
      "s3_test_uri:  s3://sagemaker-us-east-1-801598032724/2022-07-07-sagemaker-script-mode/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "s3_train_uri = session.upload_data(local_train_file, key_prefix=bucket_prefix + \"/data\")\n",
    "s3_test_uri = session.upload_data(local_test_file, key_prefix=bucket_prefix + \"/data\")\n",
    "\n",
    "print(\"s3_train_uri: \", s3_train_uri)\n",
    "print(\"s3_test_uri: \", s3_test_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our data preparation step is complete. Train and test CSV files are available on the local system and in our default Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker local environment\n",
    "The Amazon SageMaker training environment is managed, but SageMaker Python SDK also supports **local mode**, allowing you to train and deploy models to your local environment. This is a great way to test training scripts before running them in SageMaker's managed training or hosting environment.\n",
    "\n",
    "## How SageMaker managed environment works?\n",
    "When you send a request to SageMaker API (`fit` or `deploy` call)\n",
    "* it spins up new instances with the provided specification\n",
    "* loads the algorithm container\n",
    "* pulls the data from S3\n",
    "* runs the training code\n",
    "* store the results and trained model artifacts to S3\n",
    "* terminates the new instances\n",
    "\n",
    "All this happens behind the scenes with a single line of code and is a huge advantage. Spinning up new hardware every time can be good for repeatability and security, but it can add some friction while testing and debugging our code. We can test our code on a small dataset in our local environment with SageMaker local mode and then switch seamlessly to SageMaker managed environment by changing a single line of code.\n",
    "\n",
    "## Steps to prepare Amazon SageMaker local environment\n",
    "Install the following pre-requisites if you want to set up Amazon SageMaker on your local system.\n",
    "1. Install required Python packages:\n",
    "    ```\n",
    "    pip install boto3 sagemaker pandas scikit-learn\n",
    "    pip install 'sagemaker[local]'\n",
    "    ```\n",
    "2. Docker Desktop installed and running on your computer:\n",
    "    ```\n",
    "    docker ps\n",
    "    ```\n",
    "3. You should have AWS credentials configured on your local machine to be able to pull the docker image from ECR.\n",
    "\n",
    "### Instructions for SageMaker notebook instances\n",
    "You can also set up SageMaker's local environment in SageMaker notebook instances. Required Python packages and Docker service is already there. You only need to upgrade the `sagemaker[local]` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.99.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.21.42)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (4.8.2)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (20.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.20.3)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.3.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (3.19.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: docker-compose==1.29.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: urllib3==1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.26.8)\n",
      "Requirement already satisfied: docker~=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: websocket-client<1,>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.7.0)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.20.0)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.42 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (1.24.46)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker[local]) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker[local]) (3.0.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker~=5.0.0->sagemaker[local]) (2.10.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (59.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (3.1)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (36.0.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (2.21)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#collapse_output\n",
    "# this is required for SageMaker notebook instances\n",
    "!pip install 'sagemaker[local]' --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for SageMaker Studio environment\n",
    "Note that SageMaker `local` mode will not work in SageMaker Studio environment as it does not have docker service installed on the provided instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker local session\n",
    "\n",
    "SageMaker local session is required for working in a local environment. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.local.local_session.LocalSession at 0x7f6b4f3169a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "session_local = LocalSession()\n",
    "session_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# configure local session\n",
    "session_local.config = {\"local\": {\"local_code\": True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker training script\n",
    "\n",
    "We will call our training script `train_and_serve.py` and place it in our workspace under the `/src` folder. Then, we will start with a simple `Hello World` message code. After that, we will update and complete our training script as we learn more about the SageMaker `scikit-learn` container environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_file_name:  train_and_serve.py\n",
      "script_path:  ./datasets/2022-07-07-sagemaker-script-mode/src\n",
      "script_file:  ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "script_file_name = \"train_and_serve.py\"\n",
    "script_path = local_path + \"/src\"\n",
    "script_file = script_path + \"/\" + script_file_name\n",
    "\n",
    "print(\"script_file_name: \", script_file_name)\n",
    "print(\"script_path: \", script_path)\n",
    "print(\"script_file: \", script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# make sure that the directory exists\n",
    "Path(script_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*** Hello from the SageMaker script mode***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker SKLearn estimator\n",
    "\n",
    "To create SKLearn Estimator object we need to pass it following items\n",
    "* **`entry_point (str)`** Path (absolute or relative) to the Python source file, which should be executed as the entry point to training\n",
    "* **`framework_version (str)`** Scikit-learn version you want to use for executing your model training code\n",
    "* **`role (str)`** An AWS IAM role (either name or full ARN)\n",
    "* **`instance_type (str)`** Type of instance to use for training. For local mode use string **`local`**\n",
    "* **`instance_count (int)`** Number of instances to use for training. Since we will train in the local environment and have a single instance, we will use '1' here\n",
    "\n",
    "You can read more about the SKLearn Estimator class from the official documentation [Scikit Learn Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the SKLearn framework version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that version number `1.0.1` has to be provided to the SKLearn estimator class as **`1.0-1`**. Otherwise, you will get the following error message.\n",
    "```\n",
    "ValueError: Unsupported sklearn version: 1.0.1. You may need to upgrade your SDK version (pip install -U sagemaker) for newer sklearn versions. Supported sklearn version(s): 0.20.0, 0.23-1, 1.0-1.\n",
    "```\n",
    "\n",
    "Now let us create the SageMaker SKLearn estimator object and pass our training script to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating l5ul3ase2t-algo-1-ff4c7 ... \n",
      "Creating l5ul3ase2t-algo-1-ff4c7 ... done\n",
      "Attaching to l5ul3ase2t-algo-1-ff4c7\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,483 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,487 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,497 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,728 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,742 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,755 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,764 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m Training Env:\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m {\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"current_host\": \"algo-1-ff4c7\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m         \"algo-1-ff4c7\"\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     ],\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-04-404\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"master_hostname\": \"algo-1-ff4c7\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-04-404/source/sourcedir.tar.gz\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m         \"current_host\": \"algo-1-ff4c7\",\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m             \"algo-1-ff4c7\"\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m         ]\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     },\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m }\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m Environment variables:\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_HOSTS=[\"algo-1-ff4c7\"]\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_HPS={}\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ff4c7\",\"hosts\":[\"algo-1-ff4c7\"]}\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_CURRENT_HOST=algo-1-ff4c7\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-04-404/source/sourcedir.tar.gz\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-ff4c7\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-ff4c7\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-04-404\",\"log_level\":20,\"master_hostname\":\"algo-1-ff4c7\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-04-404/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ff4c7\",\"hosts\":[\"algo-1-ff4c7\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m /miniconda3/bin/python train_and_serve.py\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m \n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 |\u001b[0m 2022-07-17 12:25:06,797 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36ml5ul3ase2t-algo-1-ff4c7 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    framework_version=\"1.0-1\"\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.local.local_session.LocalSession at 0x7f6b4f051130>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# The estimator will pick a local session when we use instance_type='local'\n",
    "sk_estimator.sagemaker_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first run the SKLearn estimator, executing it may take some time as it has to download the scikit-learn container to the local docker environment. You will get the container logs in the output when the container completes the execution. The logs show that the container has successfully run the training script, and the `hello` message is also printed. But there is a lot more information available in the logs. We will discuss it in the coming section.\n",
    "\n",
    "![sklearn-output-1](images/2022-07-07-sagemaker-script-mode/sklearn-output-1.png)\n",
    "\n",
    "# Understanding SKLearn container output and environment varaibles\n",
    "From the SKLearn estimator output, we can see that our `train_and_serve.py` script is executed by the container with the following command.\n",
    "\n",
    "```\n",
    "/miniconda3/bin/python train_and_serve.py\n",
    "```\n",
    "\n",
    "## Inspecting SageMaker SKLearn docker image\n",
    "Since the container was executed in the local environment, we can also inspect the SageMaker SKLearn local image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                            TAG             IMAGE ID       CREATED       SIZE\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn   1.0-1-cpu-py3   8a6ea8272ad0   10 days ago   3.7GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the docker image. Notice multiple container environment variables and their default values in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Id\": \"sha256:8a6ea8272ad003ec816569b0f879b16c770116584301161565f065aadb99436c\",\n",
      "        \"RepoTags\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3\"\n",
      "        ],\n",
      "        \"RepoDigests\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:fc8c3a617ff0e436c25f3b64d03e1f485f1d159478c26757f3d1d267fc849445\"\n",
      "        ],\n",
      "        \"Parent\": \"\",\n",
      "        \"Comment\": \"\",\n",
      "        \"Created\": \"2022-07-06T18:55:02.854297671Z\",\n",
      "        \"Container\": \"11b9a5fec2d61294aee63e549100ed18ceb7aa0de6a4ff198da2f556dfe3ec2f\",\n",
      "        \"ContainerConfig\": {\n",
      "            \"Hostname\": \"11b9a5fec2d6\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"/bin/sh\",\n",
      "                \"-c\",\n",
      "                \"#(nop) \",\n",
      "                \"LABEL transform_id=9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:58b15b990d550868caed6f885423deee97a6c7f525c228a043096bf28e775d18\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6086988568\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"DockerVersion\": \"20.10.15\",\n",
      "        \"Author\": \"\",\n",
      "        \"Config\": {\n",
      "            \"Hostname\": \"\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"bash\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:58b15b990d550868caed6f885423deee97a6c7f525c228a043096bf28e775d18\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6086988568\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"Architecture\": \"amd64\",\n",
      "        \"Os\": \"linux\",\n",
      "        \"Size\": 3699696670,\n",
      "        \"VirtualSize\": 3699696670,\n",
      "        \"GraphDriver\": {\n",
      "            \"Data\": {\n",
      "                \"LowerDir\": \"/var/lib/docker/overlay2/798819fb0922fb5f211d05c33fe8ad296d30d2f09469b75f22cede26ce663917/diff:/var/lib/docker/overlay2/9123a012d275ec8bd09a3cdf43bb615c553422a241f0cb2991fe0b4b2244b965/diff:/var/lib/docker/overlay2/2a4d7342b24f088dbb18fc4dbf53dc7888b2f5078d76037286f34f2e1a3f7d8f/diff:/var/lib/docker/overlay2/5b0adf07c5c61c42d71fe673e9b027aa7fde1f3be3afd0058dc11585837907f1/diff:/var/lib/docker/overlay2/4623d21066eae5924fa2459280400f2b9cc9b80d161096880390119cb086be57/diff:/var/lib/docker/overlay2/1e5b7f2c09a7f5ed7e0cbab6814a2a6746b0d8b95d94d71dad5c1e604071d9a9/diff:/var/lib/docker/overlay2/ba887d984e534831269a2f5a4f3a8b9321dbe31ff411319d7da60f058710a06d/diff:/var/lib/docker/overlay2/ed0e06b59d1f75a682cfe2b13b4bea6fcb21cd1ad0b118a3747b1e37731992a4/diff:/var/lib/docker/overlay2/1892db68e66ff3d1ba6630f932ca0bb72868ebc90c8524abb0efd20e0a38e7ed/diff:/var/lib/docker/overlay2/963412ef5161d3f692863a468cf173df63d7049fd1f48e661f1dac4cd1c0e3d1/diff:/var/lib/docker/overlay2/29fd18114d1b135c2447c38807339610f9d05c408594fa6eda5500b916f50ffe/diff:/var/lib/docker/overlay2/586a98a937bd4725f39a88cb544244ca87d6cbbfcfcbf7a56058f19edecfeab8/diff:/var/lib/docker/overlay2/3da6b3845f2b2a7b1a2aac05eaaf2366c01bcff318c3b43269f7e45ee6fbd4e6/diff:/var/lib/docker/overlay2/9e48532713f0b520a1ee3a04f08e23985877248ff387b4ae8f41561de9d707b6/diff:/var/lib/docker/overlay2/bfbd224fd22fe187e51e0512716459e4674030f58ee7e2ced29aaf63180f2017/diff:/var/lib/docker/overlay2/a717a43bddd10abeffcdebbf886b3f6fe402c32f3e890526f88d78624330b625/diff:/var/lib/docker/overlay2/e8405724c471772733f506697dcd968862a0ef7d1c3a4ddfb2809b4416326c7b/diff\",\n",
      "                \"MergedDir\": \"/var/lib/docker/overlay2/c1c243ee5dc3341e92ad8f8605713f02195045dfa538fa7a3fdbe2c8d2c6531b/merged\",\n",
      "                \"UpperDir\": \"/var/lib/docker/overlay2/c1c243ee5dc3341e92ad8f8605713f02195045dfa538fa7a3fdbe2c8d2c6531b/diff\",\n",
      "                \"WorkDir\": \"/var/lib/docker/overlay2/c1c243ee5dc3341e92ad8f8605713f02195045dfa538fa7a3fdbe2c8d2c6531b/work\"\n",
      "            },\n",
      "            \"Name\": \"overlay2\"\n",
      "        },\n",
      "        \"RootFS\": {\n",
      "            \"Type\": \"layers\",\n",
      "            \"Layers\": [\n",
      "                \"sha256:1dc52a6b4de8561423dd3ec5a1f7f77f5309fd8cb340f80b8bc3d87fa112003e\",\n",
      "                \"sha256:b13a10ce059365d68a2113e9dbcac05b17b51f181615fca6d717a0dcf9ba8ffb\",\n",
      "                \"sha256:790d00cf365a312488151b354f0b0ae826be031edffb8a4de6a1fab048774dc7\",\n",
      "                \"sha256:323e43c53a1cd5abbd55437588f19da04f716452bc6d05486759b35f3e485390\",\n",
      "                \"sha256:c99c9d462af0bac5511ed046178ab0de79b8cdad33cd85246e9f661e098426cd\",\n",
      "                \"sha256:4a3a4d9fb4d250b1b64629b23bc0a477a45ee2659a8410d59a31a181dad70002\",\n",
      "                \"sha256:27b35f432a27e5e275038e559ebbe1aa7e91447bf417f5da01e3326739ba9366\",\n",
      "                \"sha256:ee12325fe0b7e7930b76d9a3dc81fcc37fa51a3267b311d2ed7c38703f193d75\",\n",
      "                \"sha256:7ceb40593535cdc07299efa2ce3a2c2267c2fa683161515fd6ab97f733492bf0\",\n",
      "                \"sha256:f18dbe0eec054f0aedf54a94aa29dab0d2c0f3d920fb482c99819622b0094f47\",\n",
      "                \"sha256:df2a7845ea611463f9f3282ccb45156ba883f40b15013ee49bd0a569301738d8\",\n",
      "                \"sha256:bcbd5416b87e3e37e05c22e46cbff2e3503d9caa0ec283a44931dc63e51c8cb7\",\n",
      "                \"sha256:5bcbb3ccae766c8a72d98ce494500bfd44c32e5780a1cb153139a4c5c143a8d5\",\n",
      "                \"sha256:4ecc8a8ffa902f3ea9bebb8d610e02a32ce1ca94c1a3160a31da98b73c1f55a0\",\n",
      "                \"sha256:a7a7b8b26735eb2d137fd0f91b83c73ad48cf2c4b83e9d0cadece410d6e598ba\",\n",
      "                \"sha256:ae939a0c9d32674ad6674947853ecfda4ff0530a8137960064448ae5e45fa1c5\",\n",
      "                \"sha256:6948f39c8f3cf6ec104734ccd1112fcb4af85a7c26c9c3d43495494b9b799f25\",\n",
      "                \"sha256:affd18c8e88f35e75bd02158e0418f3aeb4eec4269a208ede24cc829fa88c850\"\n",
      "            ]\n",
      "        },\n",
      "        \"Metadata\": {\n",
      "            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!docker inspect 8a6ea8272ad0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass hyperparameters to SKLearn estimator\n",
    "\n",
    "Let's pass some dummy hyperparameters to the estimator and see how it affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating itmzsttsc9-algo-1-pikbz ... \n",
      "Creating itmzsttsc9-algo-1-pikbz ... done\n",
      "Attaching to itmzsttsc9-algo-1-pikbz\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:09,883 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:09,888 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:09,896 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:10,093 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:10,106 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:10,119 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:10,129 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m Training Env:\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m {\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"current_host\": \"algo-1-pikbz\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m         \"algo-1-pikbz\"\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     ],\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     },\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-07-583\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"master_hostname\": \"algo-1-pikbz\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-07-583/source/sourcedir.tar.gz\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m         \"current_host\": \"algo-1-pikbz\",\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m             \"algo-1-pikbz\"\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m         ]\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     },\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m }\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m Environment variables:\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_HOSTS=[\"algo-1-pikbz\"]\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-pikbz\",\"hosts\":[\"algo-1-pikbz\"]}\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_CURRENT_HOST=algo-1-pikbz\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-07-583/source/sourcedir.tar.gz\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-pikbz\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-pikbz\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-07-583\",\"log_level\":20,\"master_hostname\":\"algo-1-pikbz\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-07-583/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-pikbz\",\"hosts\":[\"algo-1-pikbz\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m \n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz |\u001b[0m 2022-07-17 12:25:10,157 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mitmzsttsc9-algo-1-pikbz exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-hyperparams](images/2022-07-07-sagemaker-script-mode/sklearn-output-hyperparams.png)\n",
    "\n",
    "From the output we can see that our hyperparameters are passed to our training script as command line arguments. This is an important point and we will update our script using this information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker SKLearn container environment variables\n",
    "Let's now discuss some important environment variables we see in the output.\n",
    "\n",
    "### SM_MODULE_DIR\n",
    "```\n",
    "SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\n",
    "```\n",
    "`SM_MODULE_DIR` points to a location in the S3 bucket where SageMaker will automatically backup our source code for that particular run. SageMaker will create a separate folder in the default bucket for each new run. The default value is `s3://sagemaker-{aws-region}-{aws-id}/{training-job-name}/source/sourcedir.tar.gz`\n",
    "\n",
    "**Note**: We have used `local_code` for the SKLean estimator, then why is the source code backed up on the S3 bucket. Should it not be backed on the local system and bypass S3 altogether in local mode? Well, this should have been the default behavior, but it looks like SageMaker SDK is doing it otherwise, and even with the local mode it is using the S3 bucket for keeping source code. You can read more about this behavior in this issue ticket [Model repack always uploads data to S3 bucket regardless of local mode settings](https://github.com/aws/sagemaker-python-sdk/issues/3031)\n",
    "\n",
    "### SM_MODEL_DIR\n",
    "```\n",
    "SM_MODEL_DIR=/opt/ml/model\n",
    "```\n",
    "`SM_MODEL_DIR` points to a directory located inside the container. When the training job finishes, the container and its file system will be deleted, except for the `/opt/ml/model` and `/opt/ml/output` directories. Use `/opt/ml/model` to save the trained model artifacts. These artifacts are uploaded to S3 for model hosting.\n",
    "\n",
    "### SM_OUTPUT_DATA_DIR\n",
    "```\n",
    "SM_OUTPUT_DIR=/opt/ml/output\n",
    "```\n",
    "`SM_OUTPUT_DIR` points to a directory in the container to write output artifacts. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "### SM_CHANNELS\n",
    "```\n",
    "SM_CHANNELS='[\"testing\",\"training\"]'\n",
    "```\n",
    "A channel is a named input source that training algorithms can consume. You can partition your training data into different logical \"channels\" when you run training. Depending on your problem, some common channel ideas are: \"training\", \"testing\", \"evaluation\" or \"images\" and \"labels\". You can read more about the channels from SageMaker API reference [Channel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Channel.html)\n",
    "\n",
    "### SM CHANNEL {channel_name}\n",
    "```\n",
    "SM_CHANNEL_TRAIN='/opt/ml/input/data/train'\n",
    "SM_CHANNEL_TEST='/opt/ml/input/data/test'\n",
    "```\n",
    "Suppose that you have passed two input channels, 'train' and 'test', to the Scikit-learn estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "* **`SM_CHANNEL_TRAIN`**: it points to the directory in the container that has the *train* channel data downloaded\n",
    "* **`SM_CHANNEL_TEST`**: Same as above, but for the *test* channel\n",
    "\n",
    "Note that the channel names `train` and `test` are the conventions. Still, you can use any name here, and the environment variables will be created accordingly. It is important to know that the SageMaker container automatically downloads the data from the provided input channels and makes them available in the respective local directories once it starts executing. The training script can then load the data from the local container directories.\n",
    "\n",
    "There are more environment variables available, and you can read about them from [Environment variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass input channel to SKLearn estimator\n",
    "\n",
    "Now that we understand the SKLearn container environment more let's pass the training data channel to the estimator and see if the data becomes available inside the container directory. \n",
    "\n",
    "Update our script to list all the files in the `SM_CHANNEL_TRAIN` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "\n",
    "    print(\"training_dir files list: \", dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 7oowjuanoi-algo-1-xcbv0 ... \n",
      "Creating 7oowjuanoi-algo-1-xcbv0 ... done\n",
      "Attaching to 7oowjuanoi-algo-1-xcbv0\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,701 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,706 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,715 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,894 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,908 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,920 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,929 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m Training Env:\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m {\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     },\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"current_host\": \"algo-1-xcbv0\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"algo-1-xcbv0\"\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     ],\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     },\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"train\": {\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         }\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     },\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-10-574\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"master_hostname\": \"algo-1-xcbv0\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-10-574/source/sourcedir.tar.gz\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"current_host\": \"algo-1-xcbv0\",\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m             \"algo-1-xcbv0\"\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m         ]\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     },\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m }\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m Environment variables:\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_HOSTS=[\"algo-1-xcbv0\"]\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-xcbv0\",\"hosts\":[\"algo-1-xcbv0\"]}\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_CURRENT_HOST=algo-1-xcbv0\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-10-574/source/sourcedir.tar.gz\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-xcbv0\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-xcbv0\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-10-574\",\"log_level\":20,\"master_hostname\":\"algo-1-xcbv0\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-10-574/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-xcbv0\",\"hosts\":[\"algo-1-xcbv0\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 |\u001b[0m 2022-07-17 12:25:12,968 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m7oowjuanoi-algo-1-xcbv0 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": f\"file://{local_train_path}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-traincsv](images/2022-07-07-sagemaker-script-mode/sklearn-output-traincsv.png)\n",
    "\n",
    "From the output, we can see that `train.csv`, which was in our local environment, is now available inside the container on path `SM_CHANNEL_TRAIN=/opt/ml/input/data/train`. \n",
    "\n",
    "Let's also test the same with our training data on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vjizgx2zqm-algo-1-m06ka ... \n",
      "Creating vjizgx2zqm-algo-1-m06ka ... done\n",
      "Attaching to vjizgx2zqm-algo-1-m06ka\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,654 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,659 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,667 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,847 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,862 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,880 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,889 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m Training Env:\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m {\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     },\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"current_host\": \"algo-1-m06ka\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"algo-1-m06ka\"\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     ],\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     },\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"train\": {\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         }\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     },\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-13-336\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"master_hostname\": \"algo-1-m06ka\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-13-336/source/sourcedir.tar.gz\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"current_host\": \"algo-1-m06ka\",\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m             \"algo-1-m06ka\"\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m         ]\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     },\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m }\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m Environment variables:\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_HOSTS=[\"algo-1-m06ka\"]\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-m06ka\",\"hosts\":[\"algo-1-m06ka\"]}\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_CURRENT_HOST=algo-1-m06ka\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-13-336/source/sourcedir.tar.gz\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-m06ka\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-m06ka\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-13-336\",\"log_level\":20,\"master_hostname\":\"algo-1-m06ka\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-13-336/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-m06ka\",\"hosts\":[\"algo-1-m06ka\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka |\u001b[0m 2022-07-17 12:25:15,927 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mvjizgx2zqm-algo-1-m06ka exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the results are the same. SageMaker will download the data from the S3 bucket and make it available in the container. In the environment variables section we also learned that two directories are special `/opt/ml/model` and `/opt/ml/output`. Container environment variables `SM_MODEL_DIR` and `SM_OUTPUT_DATA_DIR` point to them, respectively. Whatever artifacts we put on them will be stored on the S3 bucket when the training job finishes. \"SM_MODEL_DIR\" is for trained models, and \"SM_OUTPUT_DATA_DIR\" is for other artifacts like logs, graphs, plots, results, etc. Let's update our training script and put some dummy data in these directories. Once the job is complete, we will verify the stored artifacts on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    # list files in SM_CHANNEL_TRAIN\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "    print(\"training_dir files list: \", dir_list)\n",
    "\n",
    "    # write dummy model file to SM_MODEL_DIR\n",
    "    sm_model_dir = os.environ.get(\"SM_MODEL_DIR\")\n",
    "    with open(f\"{sm_model_dir}/dummy-model.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy model\")\n",
    "\n",
    "    # write dummy artifact file to SM_OUTPUT_DATA_DIR\n",
    "    sm_output_data_dir = os.environ.get(\"SM_OUTPUT_DATA_DIR\")\n",
    "    with open(f\"{sm_output_data_dir}/dummy-output-data.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy output data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 90hhy5fi8d-algo-1-r944l ... \n",
      "Creating 90hhy5fi8d-algo-1-r944l ... done\n",
      "Attaching to 90hhy5fi8d-algo-1-r944l\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,739 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,743 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,752 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,940 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,960 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,981 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:18,996 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m Training Env:\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m {\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     },\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"current_host\": \"algo-1-r944l\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"algo-1-r944l\"\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     ],\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     },\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"train\": {\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         }\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     },\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-16-297\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"master_hostname\": \"algo-1-r944l\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/source/sourcedir.tar.gz\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"current_host\": \"algo-1-r944l\",\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m             \"algo-1-r944l\"\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m         ]\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     },\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m }\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m Environment variables:\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_HOSTS=[\"algo-1-r944l\"]\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-r944l\",\"hosts\":[\"algo-1-r944l\"]}\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_CURRENT_HOST=algo-1-r944l\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/source/sourcedir.tar.gz\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-r944l\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-r944l\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-16-297\",\"log_level\":20,\"master_hostname\":\"algo-1-r944l\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-r944l\",\"hosts\":[\"algo-1-r944l\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l |\u001b[0m 2022-07-17 12:25:19,059 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m90hhy5fi8d-algo-1-r944l exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp5_rbrzm2/algo-1-r944l Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training job is now complete. Let us check the S3 bucket to see if our dummy model and other artifacts are present.\n",
    "\n",
    "First, we need the S3 URI for these artifacts. For our dummy model (from SM_MODEL_DIR), we can use our estimator object to get the URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/model.tar.gz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = sk_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download `model_data` from S3 to a local directory for verification. For this create a local `/tmp` to store these downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/2022-07-07-sagemaker-script-mode/tmp\n"
     ]
    }
   ],
   "source": [
    "local_tmp_path = local_path + \"/tmp\"\n",
    "print(local_tmp_path)\n",
    "\n",
    "# create the local '/tmp' directory\n",
    "Path(local_tmp_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SageMaker `S3Downloader` object to download the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "S3Downloader.download(\n",
    "    s3_uri=model_data, local_path=local_tmp_path, sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File is downloaded. Let's uncompress it to verify the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy-model.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_tmp_path/model.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the \"dummy-model.txt\" file is present. This tells us that SageMaker will automatically upload the files from the model directory (SM_MODEL_DIR) to the S3 bucket. Let's do the same for the output data directory (SM_OUTPUT_DATA_DIR). There is no direct way to get the S3 URI from the estimator object for the output data directory. But we can prepare it ourselves. So let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator.output_path:  s3://sagemaker-us-east-1-801598032724/\n",
      "estimator.latest_training_job.name:  sagemaker-scikit-learn-2022-07-17-12-25-16-297\n"
     ]
    }
   ],
   "source": [
    "print(\"estimator.output_path: \", sk_estimator.output_path)\n",
    "print(\"estimator.latest_training_job.name: \", sk_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_s3_output_uri(estimator):\n",
    "    return estimator.output_path + estimator.latest_training_job.name\n",
    "    \n",
    "get_s3_output_uri(sk_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/output.tar.gz'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for output data artifacts\n",
    "s3_output_uri = get_s3_output_uri(sk_estimator) + '/output.tar.gz'\n",
    "s3_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/model.tar.gz'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "# S3 URI for model artifact. We have already veirifed it.\n",
    "s3_model_uri = get_s3_output_uri(sk_estimator) + '/model.tar.gz'\n",
    "s3_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/source/sourcedir.tar.gz'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for source code\n",
    "s3_source_uri = get_s3_output_uri(sk_estimator) + '/source/sourcedir.tar.gz'\n",
    "s3_source_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download these artifacts to our local '/tmp' directory for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/output.tar.gz to datasets/2022-07-07-sagemaker-script-mode/tmp/output.tar.gz\n",
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-16-297/source/sourcedir.tar.gz to datasets/2022-07-07-sagemaker-script-mode/tmp/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $s3_output_uri $local_tmp_path\n",
    "!aws s3 cp $s3_source_uri $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/dummy-output-data.txt\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# extract the output data files from 'output.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/output.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# extract the source code files from 'sourcedir.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/sourcedir.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary till now\n",
    "Let's summarize what we have learned till now.\n",
    "* We can use SageMaker SKLearn local mode to test our code in a local environment\n",
    "* SKLearn container executes our provided script with the command `/miniconda3/bin/python train_and_server.py`\n",
    "* Hyperparameters passed to the container are passed to our script as command line arguments\n",
    "* Data from input channels will be downloaded by the container and made available for our script to load and process\n",
    "* '/opt/ml/model' and '/opt/ml/output' directories are special. Anything stored on them will be automatically backed up on the S3 bucket when the job finishes. These directories are defined in the container environment variables 'SM_MODEL_DIR' and 'SM_OUTPUT_DATA_DIR', respectively. SM_MODEL_DIR should be used to write model artifacts. SM_OUTPUT_DATA_DIR should be used to write any other supporting artifact.\n",
    "\n",
    "Let's use this knowledge to update our script to train a RandomForrestClassifier on the Iris flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# cleanup /tmp directory before moving to next section\n",
    "!rm -r $local_tmp_path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training script for RandomForestClassifier\n",
    "Let's update our training script to train a scikit-learn random forest classifier model on the iris data set. The script will read training and testing data from input data channel directories and trains a classifier on it. It will then save the model to the model directory and validation results ('y_pred.csv') to the output data directory. Notice that we have also parsed container environment variables as command line arguments. It makes sense for hyperparameters ('--estimators') because we know they will be passed to the script as command line parameters. For other environment variables (e.g. 'SM_MODEL_DIR'), we have checked first if they are given as command line arguments. If they are, then we parse them to get the values. Otherwise, we read their values from the environment. This is done so we can test our script locally from the command line without setting the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")\n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now give proper execution rights to the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x $script_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this script locally before passing it to the SKLearn estimator. We will invoke this script from a command line and pass the required parameters similar to how an estimator container will execute it. For testing this script, we need to pass four directory paths:\n",
    "* **sm-model-dir** This will point to a directory where our script will store the trained model. We can point it to '/tmp' directory for test purposes\n",
    "* **sm-channel-train** This will point to a directory containing training data. We already have it as 'local_train_path'\n",
    "* **sm-channel-test** This will point to a directory containing test data. We also have it as 'local_test_path'\n",
    "* **sm-output-data-dir** This will point to a directory where our script will store other artifacts. We can also point it to '/tmp' directory for test purposes\n",
    "\n",
    "Once the script is successfully run, we will find the trained model file 'model.joblib' and 'y_pred.csv' in the '/tmp' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command line arguments:  Namespace(estimators=10, sm_channel_test='./datasets/2022-07-07-sagemaker-script-mode/test', sm_channel_train='./datasets/2022-07-07-sagemaker-script-mode/train', sm_model_dir='./datasets/2022-07-07-sagemaker-script-mode/tmp', sm_output_data_dir='./datasets/2022-07-07-sagemaker-script-mode/tmp')\n",
      "training_dir: ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "training_dir files list: ['train.csv']\n",
      "testing_dir: ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "testing_dir files list: ['test.csv']\n",
      "sm_model_dir: ./datasets/2022-07-07-sagemaker-script-mode/tmp\n",
      "output_data_dir: ./datasets/2022-07-07-sagemaker-script-mode/tmp\n",
      "X_train.shape: (120, 4)\n",
      "y_train.shape: (120,)\n",
      "X_train.shape: (30, 4)\n",
      "y_train.shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!python3 $script_file \\\n",
    "    --sm-model-dir $local_tmp_path \\\n",
    "    --sm-channel-train $local_train_path \\\n",
    "    --sm-channel-test $local_test_path \\\n",
    "    --sm-output-data-dir $local_tmp_path \\\n",
    "    --estimators 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the local '/tmp' directory for artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib  y_pred.csv\n"
     ]
    }
   ],
   "source": [
    "!ls $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have test our script and it is working as expected, let's pass it to SKLean container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 8zzvvv6e73-algo-1-byidf ... \n",
      "Creating 8zzvvv6e73-algo-1-byidf ... done\n",
      "Attaching to 8zzvvv6e73-algo-1-byidf\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,289 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,294 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,303 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,483 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,497 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,510 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:25,518 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m Training Env:\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     },\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"current_host\": \"algo-1-byidf\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"algo-1-byidf\"\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     ],\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     },\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"train\": {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         },\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"test\": {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         }\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     },\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-22-848\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"master_hostname\": \"algo-1-byidf\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-22-848/source/sourcedir.tar.gz\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"current_host\": \"algo-1-byidf\",\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m             \"algo-1-byidf\"\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m         ]\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     },\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m }\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m Environment variables:\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_HOSTS=[\"algo-1-byidf\"]\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-byidf\",\"hosts\":[\"algo-1-byidf\"]}\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_CURRENT_HOST=algo-1-byidf\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-22-848/source/sourcedir.tar.gz\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-byidf\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-byidf\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-22-848\",\"log_level\":20,\"master_hostname\":\"algo-1-byidf\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-22-848/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-byidf\",\"hosts\":[\"algo-1-byidf\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m \n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf |\u001b[0m 2022-07-17 12:25:26,525 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m8zzvvv6e73-algo-1-byidf exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmppg_g0dd2/algo-1-byidf Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# cleanup /tmp directory before moving to next section\n",
    "!rm -r $local_tmp_path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing custom libraries and dependencies to SKLean container\n",
    "\n",
    "We have successfully trained our classifier but assume we have an additional task. One of your colleagues has created a library that takes the confusion matrix array and plots it with [seaborn visualization library](https://seaborn.pydata.org/). You have been told to use this custom library with the training script and save the confusion matrix plot to the output data directory.\n",
    "\n",
    "Let's prepare code for this custom library to take an array and return a confusion matrix plot from seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_library_path: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library\n",
      "custom_library_file: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "# create a path to store the custom library code\n",
    "custom_library_path = local_path + \"/my_custom_library\"\n",
    "custom_library_file = custom_library_path + \"/seaborn_confusion_matrix.py\"\n",
    "\n",
    "print(f\"custom_library_path: {custom_library_path}\")\n",
    "print(f\"custom_library_file: {custom_library_file}\")\n",
    "\n",
    "# make sure the path exists\n",
    "Path(custom_library_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_file\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import argparse, os\n",
    "\n",
    "\n",
    "def save_confusion_matrix(cf_matrix, path=\"./\"):\n",
    "    sns_plot = sns.heatmap(cf_matrix, annot=True)\n",
    "    sns_plot.figure.savefig(path + \"/output_cm.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--path\", type=str, default=\"./\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    path = args.path\n",
    "\n",
    "    dummy_cm = np.array([[23, 5], [3, 30]])\n",
    "    save_confusion_matrix(dummy_cm, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert directory container seaborn code into a Python package directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_path/__init__.py\n",
    "\n",
    "from .seaborn_confusion_matrix import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom library has a dependency on the seaborn Python package. So let's create 'requirements.txt' and put all our dependencies in it. Later it will be passed to the SKLean container to install them during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path/requirements.txt\n",
    "\n",
    "seaborn==0.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this library in our local environment first. It should plot a dummy confusion matrix in local temp directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: seaborn==0.11.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (4.28.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "# intall the dependiencies first\n",
    "!pip install -r $script_path/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# test the custom library\n",
    "!python3 $custom_library_file --path $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_cm.png\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# verify the custom library output from the /tmp directory\n",
    "!ls $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our custom library code works. Let's update our script to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")  \n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")\n",
    "\n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "\n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\")\n",
    "\n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all the ingredients are ready. Let's run our script from the SKLean container.\n",
    "\n",
    "In the next cell, you can see that we have passed two extra parameters to the estimator.\n",
    "* **source_dir** this path points to the directory with the **entry_point** script `train_and_serve.py` and `requirements.txt`. If any `requirements.txt` file is in this directory, the estimator will pick that and install those packages in the container during initialization.\n",
    "* **dependencies** this points to a list of dependencies (custom libraries) that we want available in the container.\n",
    "\n",
    "Our local directory structure is shown below.\n",
    "\n",
    "```\n",
    "local_path/\n",
    " my_custom_library/\n",
    "    seaborn_confusion_matrix.py\n",
    "    __init__.py\n",
    " src/\n",
    "     train_and_serve.py\n",
    "     requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lrh7l3x6jy-algo-1-4avl6 ... \n",
      "Creating lrh7l3x6jy-algo-1-4avl6 ... done\n",
      "Attaching to lrh7l3x6jy-algo-1-4avl6\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:33,735 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:33,740 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:33,749 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:33,924 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Collecting seaborn==0.11.2\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[?25hRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Requirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Requirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Collecting matplotlib>=2.2\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Requirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Collecting pyparsing>=2.2.1\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[?25hCollecting packaging>=20.0\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \u001b[0m2022-07-17 12:25:38,178 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:38,193 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:38,206 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:38,215 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Training Env:\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     },\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"current_host\": \"algo-1-4avl6\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"algo-1-4avl6\"\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     ],\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     },\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"train\": {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         },\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"test\": {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         }\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     },\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-31-415\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"master_hostname\": \"algo-1-4avl6\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-31-415/source/sourcedir.tar.gz\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"current_host\": \"algo-1-4avl6\",\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m             \"algo-1-4avl6\"\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m         ]\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     },\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m }\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Environment variables:\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_HOSTS=[\"algo-1-4avl6\"]\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-4avl6\",\"hosts\":[\"algo-1-4avl6\"]}\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_CURRENT_HOST=algo-1-4avl6\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-31-415/source/sourcedir.tar.gz\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-4avl6\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-4avl6\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-31-415\",\"log_level\":20,\"master_hostname\":\"algo-1-4avl6\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-31-415/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-4avl6\",\"hosts\":[\"algo-1-4avl6\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m \n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 |\u001b[0m 2022-07-17 12:25:40,251 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mlrh7l3x6jy-algo-1-4avl6 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpo6timl04/algo-1-4avl6 Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-train-complete](images/2022-07-07-sagemaker-script-mode/sklearn-output-train-complete.png)\n",
    "\n",
    "SKLearn container output shows that our classifier is successfully trained, and the model and output artifacts are placed in their respective folders. We know from the first section of this post that these artifacts will automatically be uploaded to the S3 bucket. This concludes the model training part of our implementation. Let's now proceed to model serving part of our solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve SKLearn model in local mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have our trained model ready. Can we deploy it already?\n",
    "\n",
    "The answer is no. If we try to deploy this model using command\n",
    "```\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")\n",
    "```\n",
    "It will generate an exception message telling us that the estimator does not know how to load the model. So we need to tell the estimator by implementing `model_fn` function in our script.\n",
    "\n",
    "```\n",
    "[2022-07-09 06:15:45 +0000] [31] [ERROR] Error handling request /ping\n",
    "Traceback (most recent call last):\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
    "    return fn(*args, **kwargs)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/serving.py\", line 43, in default_model_fn\n",
    "    return transformer.default_model_fn(model_dir)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 35, in default_model_fn\n",
    "    raise NotImplementedError(\n",
    "NotImplementedError: \n",
    "Please provide a model_fn implementation.\n",
    "See documentation for model_fn at https://github.com/aws/sagemaker-python-sdk\n",
    "```\n",
    "\n",
    "The *model_fn* has the following signature:\n",
    "```\n",
    "def model_fn(model_dir)\n",
    "```\n",
    "\n",
    "Besides loading the model, we also need to tell the model server how to get predictions from the loaded model. For this, we need to implement the second function *predict_fn*, which has the following signature.\n",
    "```\n",
    "def predict_fn(input_data, model)\n",
    "```\n",
    "\n",
    "After we have called the `fit` function on our SKLearn estimator, we can deploy it by calling the `deploy` function to create an inference endpoint. Once you call `deploy` on the estimator two objects are created in response\n",
    "* SageMaker scikit-learn Endpoint: This Endpoint encapsulates a model server running under it. The model server will load the model saved during training and perform inference on it. It requires two helper functions to load the model and make inferences on it: model_fn and predict_fn.\n",
    "* Predictor object: This object is returned in response to the deploy call. It can be used to do inference on the Endpoint hosting our SKLearn model.\n",
    "\n",
    "Let's update our script and add these two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")  \n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")\n",
    "\n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "\n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\")\n",
    "\n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\")\n",
    "\n",
    "\n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lofp48o42k-algo-1-nqtfs ... \n",
      "Creating lofp48o42k-algo-1-nqtfs ... done\n",
      "Attaching to lofp48o42k-algo-1-nqtfs\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:44,053 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:44,057 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:44,067 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:44,316 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Collecting seaborn==0.11.2\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[?25hCollecting matplotlib>=2.2\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[?25hRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Requirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Requirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Collecting fonttools>=4.22.0\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Requirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[?25hCollecting pyparsing>=2.2.1\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \u001b[0m2022-07-17 12:25:48,781 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:48,796 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:48,808 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:48,816 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Training Env:\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     },\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"current_host\": \"algo-1-nqtfs\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"algo-1-nqtfs\"\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     ],\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     },\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"train\": {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         },\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"test\": {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         }\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     },\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-25-41-704\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"master_hostname\": \"algo-1-nqtfs\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-41-704/source/sourcedir.tar.gz\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"current_host\": \"algo-1-nqtfs\",\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m             \"algo-1-nqtfs\"\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m         ]\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     },\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m }\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Environment variables:\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_HOSTS=[\"algo-1-nqtfs\"]\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-nqtfs\",\"hosts\":[\"algo-1-nqtfs\"]}\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_CURRENT_HOST=algo-1-nqtfs\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-41-704/source/sourcedir.tar.gz\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-nqtfs\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-nqtfs\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-25-41-704\",\"log_level\":20,\"master_hostname\":\"algo-1-nqtfs\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-25-41-704/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-nqtfs\",\"hosts\":[\"algo-1-nqtfs\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m \n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36mlofp48o42k-algo-1-nqtfs |\u001b[0m 2022-07-17 12:25:50,848 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpv9xn65bm/algo-1-nqtfs Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mlofp48o42k-algo-1-nqtfs exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is trained. Let's also deploy it in the local model. For model loading `model_fn`, SageMaker will download the model artifacts from S3 and mount them on `/opt/ml/model`. This way, our script can load the model from within the container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to mt618rjy05-algo-1-0hal1\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,247 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,251 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,252 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m worker_processes auto;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m daemon off;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m events {\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m }\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m http {\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   }\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   server {\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     }\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     location / {\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m     }\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   }\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m }\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,444 INFO - sagemaker-containers - Module train_and_serve does not provide a setup.py. \n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Generating setup.py\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,444 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,444 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:25:54,445 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hCollecting seaborn==0.11.2\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Requirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Requirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Collecting matplotlib>=2.2\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Collecting pyparsing>=2.2.1\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Building wheels for collected packages: train-and-serve\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Building wheel for train-and-serve (setup.py) ... \u001b[?25l2022/07/17 12:25:57 [crit] 14#14: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:25:57 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m done\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[?25h  Created wheel for train-and-serve: filename=train_and_serve-1.0.0-py2.py3-none-any.whl size=6122 sha256=976b0eaa523a775a785f448f72a50d51ee7928c485d3452dc77d8489da368447\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-u8ouj210/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Successfully built train-and-serve\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Installing collected packages: train-and-serve, pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2 train-and-serve-1.0.0\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m \u001b[0m2022/07/17 12:26:02 [crit] 14#14: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:02 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:26:03,356 INFO - matplotlib.font_manager - generated new fontManager\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m [2022-07-17 12:26:04 +0000] [35] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m [2022-07-17 12:26:04 +0000] [35] [INFO] Listening at: unix:/tmp/gunicorn.sock (35)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m [2022-07-17 12:26:04 +0000] [35] [INFO] Using worker: gevent\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m [2022-07-17 12:26:04 +0000] [37] [INFO] Booting worker with pid: 37\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m [2022-07-17 12:26:04 +0000] [39] [INFO] Booting worker with pid: 39\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:26:07,628 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m model_fn model_dir: /opt/ml/model\n",
      "!\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:09 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a sample request and get a prediction from our local inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 2022-07-17 12:26:09,633 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m model_fn model_dir: /opt/ml/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mmt618rjy05-algo-1-0hal1 |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:11 +0000] \"POST /invocations HTTP/1.1\" 200 136 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "request = [[9.0, 3571, 1976, 0.525]]\n",
    "\n",
    "response  = sk_predictor.predict(request)\n",
    "response = int(response[0])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class category 2 (Iris-virginica)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# map response to correct category type\n",
    "print(\"Predicted class category {} ({})\".format(response, categories_map[response]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the enpoint in running in the local environment we can observe a webserver running in a docker instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                                               COMMAND   CREATED          STATUS          PORTS                                       NAMES\n",
      "22f06fd3d03f   683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3   \"serve\"   18 seconds ago   Up 17 seconds   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp   mt618rjy05-algo-1-0hal1\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# delete the local endpoint\n",
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in local mode we can only serve a single model at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLean model server input and output processing\n",
    "\n",
    "SageMaker model server breaks the incoming request into three steps:\n",
    "1. input processing\n",
    "2. prediction, and\n",
    "3. output processing\n",
    "\n",
    "In the last section, we have seen that the `predict_fn` function in the source code file defines model prediction. Similarly, SageMaker provides two additional functions to control input and output processing, defined as `input_fn` and `output_fn`, respectively. Both these function have their default implementations. But we can override them by providing our own implementation for them in the source script. If no definition is provided in the source script, then the SageMaker scikit-learn model server will use the default implementation.\n",
    "\n",
    "* **`input_fn`**: Takes request data and deserializes the data into an object for prediction.\n",
    "* **`output_fn`**: Takes the prediction result and serializes this according to the response content type.\n",
    "\n",
    "Let's update our script to preprocess input request and output response as JSON objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")  \n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")\n",
    "\n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "\n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\")\n",
    "\n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\")\n",
    "    \n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == \"application/json\":\n",
    "        request_body = json.loads(request_body)\n",
    "        inpVar = request_body[\"Input\"]\n",
    "        return inpVar\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {\"Output\": res}\n",
    "    return respJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 3494su1ags-algo-1-zcktn ... \n",
      "Creating 3494su1ags-algo-1-zcktn ... done\n",
      "Attaching to 3494su1ags-algo-1-zcktn\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:14,634 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:14,638 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:14,647 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:14,849 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Collecting seaborn==0.11.2\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Collecting matplotlib>=2.2\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[?25hRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Requirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[?25hCollecting pyparsing>=2.2.1\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Requirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Collecting fonttools>=4.22.0\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \u001b[0m2022-07-17 12:26:19,250 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:19,264 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:19,277 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:19,286 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Training Env:\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     },\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"current_host\": \"algo-1-zcktn\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"algo-1-zcktn\"\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     ],\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     },\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"train\": {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         },\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"test\": {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         }\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     },\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-26-12-369\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"master_hostname\": \"algo-1-zcktn\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-26-12-369/source/sourcedir.tar.gz\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"current_host\": \"algo-1-zcktn\",\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m             \"algo-1-zcktn\"\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m         ]\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     },\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m }\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Environment variables:\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_HOSTS=[\"algo-1-zcktn\"]\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-zcktn\",\"hosts\":[\"algo-1-zcktn\"]}\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_CURRENT_HOST=algo-1-zcktn\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-26-12-369/source/sourcedir.tar.gz\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-zcktn\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-zcktn\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-26-12-369\",\"log_level\":20,\"master_hostname\":\"algo-1-zcktn\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-26-12-369/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-zcktn\",\"hosts\":[\"algo-1-zcktn\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m \n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36m3494su1ags-algo-1-zcktn |\u001b[0m 2022-07-17 12:26:21,317 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m3494su1ags-algo-1-zcktn exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpok7mhpfa/algo-1-zcktn Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n",
      "Attaching to vb2p0ax589-algo-1-h2nqv\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,668 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,672 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,674 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m worker_processes auto;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m daemon off;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m events {\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m }\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m http {\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   }\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   server {\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     }\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     location / {\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m     }\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   }\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m }\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,877 INFO - sagemaker-containers - Module train_and_serve does not provide a setup.py. \n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Generating setup.py\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,877 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,877 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:24,878 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hCollecting seaborn==0.11.2\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Collecting matplotlib>=2.2\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Requirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Requirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hCollecting pyparsing>=2.2.1\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Collecting fonttools>=4.22.0\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Building wheels for collected packages: train-and-serve\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Building wheel for train-and-serve (setup.py) ... \u001b[?25l2022/07/17 12:26:27 [crit] 14#14: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:27 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m done\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[?25h  Created wheel for train-and-serve: filename=train_and_serve-1.0.0-py2.py3-none-any.whl size=6682 sha256=042850ca13e6e15685ea1a08fac12f4f73cd931f06582f17c97506abed095064\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-w9gc11ll/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Successfully built train-and-serve\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Installing collected packages: train-and-serve, pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2 train-and-serve-1.0.0\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m \u001b[0m2022-07-17 12:26:32,811 INFO - matplotlib.font_manager - generated new fontManager\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022/07/17 12:26:32 [crit] 14#14: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:32 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m [2022-07-17 12:26:33 +0000] [35] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m [2022-07-17 12:26:33 +0000] [35] [INFO] Listening at: unix:/tmp/gunicorn.sock (35)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m [2022-07-17 12:26:33 +0000] [35] [INFO] Using worker: gevent\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m [2022-07-17 12:26:33 +0000] [37] [INFO] Booting worker with pid: 37\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m [2022-07-17 12:26:33 +0000] [38] [INFO] Booting worker with pid: 38\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:37,968 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m model_fn model_dir: /opt/ml/model\n",
      "!\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:39 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# train and deploy model with input and output as JSON objects\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})\n",
    "\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-scikit-learn-2022-07-17-12-26-22-608'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_endpoint_name = sk_predictor.endpoint_name\n",
    "sk_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 2022-07-17 12:26:39,338 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m model_fn model_dir: /opt/ml/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mvb2p0ax589-algo-1-h2nqv |\u001b[0m 172.18.0.1 - - [17/Jul/2022:12:26:40 +0000] \"POST /invocations HTTP/1.1\" 200 13 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# send JSON request to endpoint\n",
    "import json\n",
    "\n",
    "client = session_local.sagemaker_runtime_client\n",
    "\n",
    "request_body = {\"Input\": [[9.0, 3571, 1976, 0.525]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=sk_endpoint_name, ContentType=\"application/json\", Body=payload\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())[\"Output\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class category 2 (Iris-virginica)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# get JSON response from endpoint\n",
    "print(\"Predicted class category {} ({})\".format(result, categories_map[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn model training and serving in SageMaker managed environment\n",
    "\n",
    "We have our script successfully tested in a local environment, and now we are ready to train and serve in the SageMaker managed environment. For this, we only need to change the session type passed to the SKLearn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 12:26:40 Starting - Starting the training job...\n",
      "2022-07-17 12:27:04 Starting - Preparing the instances for trainingProfilerReport-1658060800: InProgress\n",
      "......\n",
      "2022-07-17 12:28:04 Downloading - Downloading input data......\n",
      "2022-07-17 12:29:04 Training - Downloading the training image...\n",
      "2022-07-17 12:29:30 Training - Training image download completed. Training in progress.\u001b[34m2022-07-17 12:29:33,369 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:33,375 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:33,400 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:33,837 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting seaborn==0.11.2\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "      292.8/292.8 kB 13.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "      11.3/11.3 MB 66.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "      98.3/98.3 kB 8.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "      944.1/944.1 kB 58.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "      1.2/1.2 MB 56.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "      40.8/40.8 kB 7.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\u001b[0m\n",
      "\u001b[34mSuccessfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:40,935 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:40,957 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:40,978 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:40,989 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"estimators\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2022-07-17-12-26-40-477\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-26-40-477/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_and_serve\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_and_serve.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"estimators\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_and_serve.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_and_serve\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-26-40-477/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-17-12-26-40-477\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-17-12-26-40-477/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_and_serve.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--estimators\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ESTIMATORS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train_and_serve.py --estimators 10\u001b[0m\n",
      "\u001b[34mcommand line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\u001b[0m\n",
      "\u001b[34mtraining_dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mtraining_dir files list: ['train.csv']\u001b[0m\n",
      "\u001b[34mtesting_dir: /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mtesting_dir files list: ['test.csv']\u001b[0m\n",
      "\u001b[34msm_model_dir: /opt/ml/model\u001b[0m\n",
      "\u001b[34moutput_data_dir: /opt/ml/output/data\u001b[0m\n",
      "\u001b[34mX_train.shape: (120, 4)\u001b[0m\n",
      "\u001b[34my_train.shape: (120,)\u001b[0m\n",
      "\u001b[34mX_train.shape: (30, 4)\u001b[0m\n",
      "\u001b[34my_train.shape: (30,)\u001b[0m\n",
      "\u001b[34msm_model_dir: /opt/ml/model\u001b[0m\n",
      "\u001b[34msm_model_dir files list: ['model.joblib']\u001b[0m\n",
      "\u001b[34moutput_data_dir: /opt/ml/output/data\u001b[0m\n",
      "\u001b[34moutput_data_dir files list: ['y_pred.csv', 'output_cm.png']\u001b[0m\n",
      "\u001b[34m2022-07-17 12:29:44,749 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-17 12:30:04 Uploading - Uploading generated training model\n",
      "2022-07-17 12:30:04 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# train and deploy model with input and output as JSON objects\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7f6b47fdd880>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_estimator.sagemaker_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# send JSON request to endpoint\n",
    "import json\n",
    "\n",
    "client = session.sagemaker_runtime_client\n",
    "\n",
    "request_body = {\"Input\": [[9.0, 3571, 1976, 0.525]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=sk_predictor.endpoint_name, \n",
    "    ContentType=\"application/json\", \n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())[\"Output\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class category 2 (Iris-virginica)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# get JSON response from endpoint\n",
    "print(\"Predicted class category {} ({})\".format(result, categories_map[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
