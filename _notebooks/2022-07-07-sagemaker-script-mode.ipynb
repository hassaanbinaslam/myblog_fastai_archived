{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Scikit-learn Models to Amazon SageMaker with the SageMaker Python SDK using Script mode\n",
    "> The aim of this notebook is to demonstrate how to train and deploy a scikit-learn model in Amazon SageMaker using script mode.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [aws, ml, sagemaker]\n",
    "- keyword: [aws, ml, sagemaker, sklearn, scikit-learn, python]\n",
    "- image: images/copied_from_nb/images/2022-07-07-sagemaker-script-mode.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/2022-07-07-sagemaker-script-mode.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "You may have trained a model with your favorite ML framework, and now you are asked to move your code to Amazon SageMaker. The good news is that SageMaker's fully managed training works well with many popular ML frameworks, including `scikit-learn`. In addition, SageMaker provides its prebuilt container for the scikit-learn framework, enabling us to seemlessly port our scripts to SageMaker and benefit from its training and deployment capabilities. SageMaker's scikit-learn Container is an open source library for making the scikit-learn framework run on the Amazon SageMaker platform. You can read more about sklearn container features from its GitHub page [SageMaker Scikit-learn Container](https://github.com/aws/sagemaker-scikit-learn-container).\n",
    "\n",
    "Amazon SageMaker also provides open source Python SDK to train and deploy models on SageMaker. SageMaker SDK provides several high-level abstractions (classes), including:\n",
    "* `Session` Provides a collection of methods for working with SageMaker resources \n",
    "* `Estimators` Encapsulate training on SageMaker\n",
    "* `Predictors` Provide real-time inference and transformation using Python data types against a SageMaker endpoint\n",
    "\n",
    "You can read more on SageMaker Python SDK from its official site [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html)\n",
    "\n",
    "This approach of using a custom training script with SageMaker's prebuilt container is commonly called as **Script Mode**. To train a scikit-learn model by using the SageMaker Python SDK involves three steps:\n",
    "\n",
    "1. **Prepare a training script**. The training script is similar to any other scikit-learn training script that you might use outside of SageMaker\n",
    "2. **Create an Estimator object from class `sagemaker.sklearn.SKLearn`**. Scikit-learn estimator class handles end-to-end training and deployment of custom scikit-learn code. We pass our training script to the SKLearn estimator, and it executes the script within a SageMaker Training Job. This training job is an Amazon-built Docker container that runs functions defined in the provided Python script. \n",
    "3. **Call the Estimator's `fit` method on training data**. Training is started by calling `fit()` on this Estimator. After training is complete, calling `deploy()` creates a hosted SageMaker endpoint and returns a `SKLearnPredictor` instance that can be used to perform inference against the hosted model. We will discuss the `SKLearn` Estimator in more detail later in this post.\n",
    "\n",
    "To read more about using scikit-learn with the SageMaker Python SDK, you may refer to the official documentation [using Scikit-learn with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html). The official documentation is valuable, and I would highly recommend checking it and keeping it as a reference.\n",
    "\n",
    "In this post we will built a scikit-learn [RandomForrestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) on [iris public dataset](https://archive.ics.uci.edu/ml/datasets/iris). There is a similar example in SageMaker documentation. [Train a SKLearn Model using Script Mode](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-script-mode/sklearn/sklearn_byom_outputs.html). But it does not discuss many important aspects of a scikit-learn container and its environment. In this post, we will learn about them and cover all the details of training a scikit-learn model with script mode. I also noted that the example in the documentation uses `RandomForrestRegressor` on a classification problem which I believe is a mistake.\n",
    "\n",
    "We have much to cover and learn, so let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "This notebook is prepared with AWS SageMaker notebook running on `ml.t3.medium` instance and \"conda_python3\" kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.22.97 Python/3.8.12 Linux/5.10.102-99.473.amzn2.x86_64 botocore/1.24.19\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Amazon Linux\"\n",
      "VERSION=\"2\"\n",
      "ID=\"amzn\"\n",
      "ID_LIKE=\"centos rhel fedora\"\n",
      "VERSION_ID=\"2\"\n",
      "PRETTY_NAME=\"Amazon Linux 2\"\n",
      "ANSI_COLOR=\"0;33\"\n",
      "CPE_NAME=\"cpe:2.3:o:amazon:amazon_linux:2\"\n",
      "HOME_URL=\"https://amazonlinux.com/\"\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/ec2-user/anaconda3\n",
      "JupyterSystemEnv         /home/ec2-user/anaconda3/envs/JupyterSystemEnv\n",
      "R                        /home/ec2-user/anaconda3/envs/R\n",
      "amazonei_mxnet_p36       /home/ec2-user/anaconda3/envs/amazonei_mxnet_p36\n",
      "amazonei_pytorch_latest_p37     /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37\n",
      "amazonei_tensorflow2_p36     /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36\n",
      "mxnet_p37                /home/ec2-user/anaconda3/envs/mxnet_p37\n",
      "python3               *  /home/ec2-user/anaconda3/envs/python3\n",
      "pytorch_p38              /home/ec2-user/anaconda3/envs/pytorch_p38\n",
      "tensorflow2_p38          /home/ec2-user/anaconda3/envs/tensorflow2_p38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and test data\n",
    "We will use **Iris flower dataset**. It includes three iris species (Iris setosa, Iris virginica, and Iris versicolor) with 50 samples each. Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. We can train a model to distinguish the species from each other based on the combination of these four features. You can read more about this dataset at [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class: Iris Setosa, Iris Versicolour, Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# download dataset\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\", \"datasets/tabular/iris/iris.data\", \"iris.data\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"iris.data\",\n",
    "    header=None,\n",
    "    names=[\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"class\"],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "      <th>class_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class  class_cat\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa          0\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa          0\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa          0\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa          0\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# Convert the three classes from strings to integers in {0,1,2}\n",
    "df[\"class_cat\"] = df[\"class\"].astype(\"category\").cat.codes\n",
    "categories_map = dict(enumerate(df[\"class\"].astype(\"category\").cat.categories))\n",
    "print(categories_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and store train and test sets as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (120, 6)\n",
      "test.shape: (30, 6)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "print(f\"test.shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our dataset ready. Let's define a local directory to keep all the files and artifacts related to this post. I will refer to this directory as 'local_path'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# `local_path` will be the root directory for this post.\n",
    "local_path = \"./datasets/2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have train and test sets ready. Let's create two more directories in our `local_path` and store our data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_train_path:  ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "local_test_path:  ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "local_train_file:  ./datasets/2022-07-07-sagemaker-script-mode/train/train.csv\n",
      "local_test_file:  ./datasets/2022-07-07-sagemaker-script-mode/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# local paths\n",
    "local_train_path = local_path + \"/train\"\n",
    "local_test_path = local_path + \"/test\"\n",
    "\n",
    "# create local directories\n",
    "Path(local_train_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(local_test_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"local_train_path: \", local_train_path)\n",
    "print(\"local_test_path: \", local_test_path)\n",
    "\n",
    "# local file names\n",
    "local_train_file = local_train_path + \"/train.csv\"\n",
    "local_test_file = local_test_path + \"/test.csv\"\n",
    "\n",
    "# write train and test CSV files\n",
    "train.to_csv(local_train_file, index=False)\n",
    "test.to_csv(local_test_file, index=False)\n",
    "\n",
    "print(\"local_train_file: \", local_train_file)\n",
    "print(\"local_test_file: \", local_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.__version__:  2.86.2\n",
      "Session:  <sagemaker.session.Session object at 0x7fead5e49a30>\n",
      "Role:  arn:aws:iam::801598032724:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "Bucket:  sagemaker-us-east-1-801598032724\n",
      "Region:  us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "\n",
    "print(\"sagemaker.__version__: \", sagemaker.__version__)\n",
    "print(\"Session: \", session)\n",
    "print(\"Role: \", role)\n",
    "print(\"Bucket: \", bucket)\n",
    "print(\"Region: \", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done is\n",
    "* imported the SageMaker Python SDK into our runtime\n",
    "* get a session to work with SageMaker API and other AWS services\n",
    "* get the execution role associated with the user profile. It is the same profile that is available to the user to work from console UI and has `AmazonSageMakerFullAccess` policy attached to it.\n",
    "* create or get a default bucket to use and return its name. Default bucket name has the format `sagemaker-{region}-{account_id}`. If it doesn't exist then our session will automatically create it. You may also use any other bucket in its place given that you have enough permission for reading and writing.\n",
    "* get the region name attached to our session\n",
    "\n",
    "Next, we will use this session to upload data to our default bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# You may choose any other prefix for your bucket.\n",
    "# All the data related to this post will be under this prefix.\n",
    "bucket_prefix = \"2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload the data. In the output, we will get the complete path (S3 URI) for our uploaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_train_uri:  s3://sagemaker-us-east-1-801598032724/2022-07-07-sagemaker-script-mode/data/train.csv\n",
      "s3_test_uri:  s3://sagemaker-us-east-1-801598032724/2022-07-07-sagemaker-script-mode/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "s3_train_uri = session.upload_data(local_train_file, key_prefix=bucket_prefix + \"/data\")\n",
    "s3_test_uri = session.upload_data(local_test_file, key_prefix=bucket_prefix + \"/data\")\n",
    "\n",
    "print(\"s3_train_uri: \", s3_train_uri)\n",
    "print(\"s3_test_uri: \", s3_test_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our data preparation step is complete. Train and test CSV files are available on the local system and in our default Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker local environment\n",
    "The Amazon SageMaker training environment is managed, but SageMaker Python SDK also supports **local mode**, allowing you to train and deploy models to your local environment. This is a great way to test training scripts before running them in SageMaker's managed training or hosting environment.\n",
    "\n",
    "## How SageMaker managed environment works?\n",
    "When you send a request to SageMaker API (`fit` or `deploy` call)\n",
    "* it spins up new instances with the provided specification\n",
    "* loads the algorithm container\n",
    "* pulls the data from S3\n",
    "* runs the training code\n",
    "* store the results and trained model artifacts to S3\n",
    "* terminates the new instances\n",
    "\n",
    "All this happens behind the scenes with a single line of code and is a huge advantage. Spinning up new hardware every time can be good for repeatability and security, but it can add some friction while testing and debugging our code. We can test our code on a small dataset in our local environment with SageMaker local mode and then switch seamlessly to SageMaker managed environment by changing a single line of code.\n",
    "\n",
    "## Steps to prepare Amazon SageMaker local environment\n",
    "Install the following pre-requisites if you want to set up Amazon SageMaker on your local system.\n",
    "1. Install required Python packages:\n",
    "    ```\n",
    "    pip install boto3 sagemaker pandas scikit-learn\n",
    "    pip install 'sagemaker[local]'\n",
    "    ```\n",
    "2. Docker Desktop installed and running on your computer:\n",
    "    ```\n",
    "    docker ps\n",
    "    ```\n",
    "3. You should have AWS credentials configured on your local machine to be able to pull the docker image from ECR.\n",
    "\n",
    "### Instructions for SageMaker notebook instances\n",
    "You can also set up SageMaker's local environment in SageMaker notebook instances. Required Python packages and Docker service is already there. You only need to upgrade the `sagemaker[local]` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.86.2)\n",
      "Collecting sagemaker[local]\n",
      "  Downloading sagemaker-2.99.0.tar.gz (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.7/542.7 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<22,>=20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (20.3.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.21.42)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.20.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.3.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: urllib3==1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.26.8)\n",
      "Requirement already satisfied: docker-compose==1.29.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: docker~=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.0.3)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.7.0)\n",
      "Requirement already satisfied: websocket-client<1,>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.20.0)\n",
      "Collecting botocore<1.25.0,>=1.24.42\n",
      "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.5.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker[local]) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker[local]) (3.0.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker~=5.0.0->sagemaker[local]) (2.10.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (59.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (3.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (36.0.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.5.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (2.21)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.99.0-py2.py3-none-any.whl size=756462 sha256=2439e47f0fe5b82303781358f58b39163c501b7b110b57ce1773bb098e2d4cfc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/fc/df/14/14b7871f4cf108cfe8891338510d97e28cfe2da00f37114fcf\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: botocore, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.19\n",
      "    Uninstalling botocore-1.24.19:\n",
      "      Successfully uninstalled botocore-1.24.19\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.86.2\n",
      "    Uninstalling sagemaker-2.86.2:\n",
      "      Successfully uninstalled sagemaker-2.86.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.22.97 requires botocore==1.24.42, but you have botocore 1.24.46 which is incompatible.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.24.46 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.24.46 sagemaker-2.99.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#collapse_output\n",
    "# this is required for SageMaker notebook instances\n",
    "!pip install 'sagemaker[local]' --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for SageMaker Studio environment\n",
    "Note that SageMaker `local` mode will not work in SageMaker Studio environment as it does not have docker service installed on the provided instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker local session\n",
    "\n",
    "SageMaker local session is required to for working in a local environment. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.local.local_session.LocalSession at 0x7fea8a5ca8b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "session_local = LocalSession()\n",
    "session_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# configure local session\n",
    "session_local.config = {\"local\": {\"local_code\": True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker training script\n",
    "\n",
    "We will call our training script `train_and_serve.py` and place it in our workspace under the `/src` folder. Then, we will start with a simple `Hello World` message code. After that, we will update and complete our training script as we learn more about the SageMaker `scikit-learn` container environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_file_name:  train_and_serve.py\n",
      "script_path:  ./datasets/2022-07-07-sagemaker-script-mode/src\n",
      "script_file:  ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "script_file_name = \"train_and_serve.py\"\n",
    "script_path = local_path + \"/src\"\n",
    "script_file = script_path + \"/\" + script_file_name\n",
    "\n",
    "print(\"script_file_name: \", script_file_name)\n",
    "print(\"script_path: \", script_path)\n",
    "print(\"script_file: \", script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the directory exists\n",
    "Path(script_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*** Hello from the SageMaker script mode***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker SKLearn estimator\n",
    "\n",
    "To use our `train_and_serve.py` script with SageMaker SKLearn estimator, we need to provide the following required items\n",
    "* **`entry_point (str)`** Path (absolute or relative) to the Python source file, which should be executed as the entry point to training\n",
    "* **`framework_version (str)`** Scikit-learn version you want to use for executing your model training code\n",
    "* **`role (str)`** An AWS IAM role (either name or full ARN)\n",
    "* **`instance_type (str)`** Type of instance to use for training. For local mode use string **`local`**\n",
    "* **`instance_count (int)`** Number of instances to use for training. Since we will train in the local environment and have a single instance, we will use '1' here\n",
    "\n",
    "You can read more about the SKLearn Estimator class from the official documentation [Scikit Learn Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the SKLearn framework version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that version number `1.0.1` has to be provided to the SKLearn estimator class as **`1.0-1`**. Otherwise, you will get the following error message.\n",
    "```\n",
    "ValueError: Unsupported sklearn version: 1.0.1. You may need to upgrade your SDK version (pip install -U sagemaker) for newer sklearn versions. Supported sklearn version(s): 0.20.0, 0.23-1, 1.0-1.\n",
    "```\n",
    "\n",
    "Now let us create the SageMaker SKLearn estimator object and pass our training script to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 2iubyr16bc-algo-1-c3wnw ... \n",
      "Creating 2iubyr16bc-algo-1-c3wnw ... done\n",
      "Attaching to 2iubyr16bc-algo-1-c3wnw\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,546 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,550 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,559 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,736 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,748 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,767 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,775 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m Training Env:\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m {\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"current_host\": \"algo-1-c3wnw\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m         \"algo-1-c3wnw\"\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     ],\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-16-09-17-58-186\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"master_hostname\": \"algo-1-c3wnw\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-16-09-17-58-186/source/sourcedir.tar.gz\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m         \"current_host\": \"algo-1-c3wnw\",\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m             \"algo-1-c3wnw\"\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m         ]\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     },\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m }\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m Environment variables:\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_HOSTS=[\"algo-1-c3wnw\"]\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_HPS={}\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-c3wnw\",\"hosts\":[\"algo-1-c3wnw\"]}\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_CURRENT_HOST=algo-1-c3wnw\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-16-09-17-58-186/source/sourcedir.tar.gz\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-c3wnw\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-c3wnw\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-16-09-17-58-186\",\"log_level\":20,\"master_hostname\":\"algo-1-c3wnw\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-16-09-17-58-186/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-c3wnw\",\"hosts\":[\"algo-1-c3wnw\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m /miniconda3/bin/python train_and_serve.py\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m \n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw |\u001b[0m 2022-07-16 09:18:00,802 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m2iubyr16bc-algo-1-c3wnw exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    framework_version=\"1.0-1\"\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.local.local_session.LocalSession at 0x7fea8b3a1f10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets confirm that we have used local session\n",
    "# The estimator will pick a local session when we use instance_type='local'\n",
    "sk_estimator.sagemaker_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first run the SKLearn estimator, executing it may take some time as it has to download the scikit-learn container to the local docker environment. You will get the container logs in the output when the container completes the execution. The logs show that the container has successfully run the training script, and the `hello` message is also printed. But there is a lot more information available in the logs. So in the coming section, we will discuss that.\n",
    "\n",
    "![sklearn-output-1](images/2022-07-07-sagemaker-script-mode/sklearn-output-1.png)\n",
    "\n",
    "# Understanding SKLearn container output and environment varaibles\n",
    "From the SKLearn estimator output, we can see that our `train_and_server.py` script is executed by the container with the following command.\n",
    "\n",
    "```\n",
    "/miniconda3/bin/python train_and_server.py\n",
    "```\n",
    "\n",
    "## Inspecting SageMaker SKLearn docker image\n",
    "Since the container was executed in the local environment, we can also inspect the SageMaker SKLearn local image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                            TAG             IMAGE ID       CREATED      SIZE\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn   1.0-1-cpu-py3   8a6ea8272ad0   8 days ago   3.7GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the docker image. Notice the multiple container environment variables and their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Id\": \"sha256:8a6ea8272ad003ec816569b0f879b16c770116584301161565f065aadb99436c\",\n",
      "        \"RepoTags\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3\"\n",
      "        ],\n",
      "        \"RepoDigests\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:fc8c3a617ff0e436c25f3b64d03e1f485f1d159478c26757f3d1d267fc849445\"\n",
      "        ],\n",
      "        \"Parent\": \"\",\n",
      "        \"Comment\": \"\",\n",
      "        \"Created\": \"2022-07-06T18:55:02.854297671Z\",\n",
      "        \"Container\": \"11b9a5fec2d61294aee63e549100ed18ceb7aa0de6a4ff198da2f556dfe3ec2f\",\n",
      "        \"ContainerConfig\": {\n",
      "            \"Hostname\": \"11b9a5fec2d6\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"/bin/sh\",\n",
      "                \"-c\",\n",
      "                \"#(nop) \",\n",
      "                \"LABEL transform_id=9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:58b15b990d550868caed6f885423deee97a6c7f525c228a043096bf28e775d18\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6086988568\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"DockerVersion\": \"20.10.15\",\n",
      "        \"Author\": \"\",\n",
      "        \"Config\": {\n",
      "            \"Hostname\": \"\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"bash\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:58b15b990d550868caed6f885423deee97a6c7f525c228a043096bf28e775d18\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6086988568\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"9be8b540-703b-4ecd-a127-c37333a0dcec_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"Architecture\": \"amd64\",\n",
      "        \"Os\": \"linux\",\n",
      "        \"Size\": 3699696670,\n",
      "        \"VirtualSize\": 3699696670,\n",
      "        \"GraphDriver\": {\n",
      "            \"Data\": {\n",
      "                \"LowerDir\": \"/var/lib/docker/overlay2/f2d27ccd86df21e5c165c380ab98a80a28ffda9bb06aa948d43606477f83e296/diff:/var/lib/docker/overlay2/8857decc7464b35f6e49b6ba3b27ad2f0779a78eefe6550f11cea821811fa393/diff:/var/lib/docker/overlay2/49803119e588abe9c2282d909fc6e95fb97b2d24a3c07b9b4f06234a15d5590f/diff:/var/lib/docker/overlay2/fa6b6a75022dc69e4c587ebd508c56cc2b2bce3c1cb98e8358a40b8baf5161b4/diff:/var/lib/docker/overlay2/afc135faff8b67492aa9a806cfaae3dd4f5091164a8862cd88bc92f607f2ad1b/diff:/var/lib/docker/overlay2/cfe66271016032a438f4d68c3b9c4622bdefdc1ce54369a856e530ccbd32a603/diff:/var/lib/docker/overlay2/f56945ee5cc8da5d5fe524bbb68ec3194d3cb97670c3415be20ea914d71f8fc5/diff:/var/lib/docker/overlay2/bb7cd6461080c4b4ca5aaa9828d2853b6d1de6f9904cae2bf6b47813284e6956/diff:/var/lib/docker/overlay2/0b7798d7d51fcc2aeac9b0266f3cdc7c368303e66bc60b5b16ac7a460b4e09ba/diff:/var/lib/docker/overlay2/60ea8778eb6504b6c639f18f865bb0201e33f38965c4e246bf44c3e767299bb4/diff:/var/lib/docker/overlay2/f4f9aed9ef3d37b8756719cc36dbc2f13bfbc4e178bd34fc4d5543cac2f8fa91/diff:/var/lib/docker/overlay2/87892835157f940f5c278e60fb6799d898562cb3cebcf45118d32604333ed1fe/diff:/var/lib/docker/overlay2/4eda4c0204d7e867ec3e1395fc473185474965820129f4495a92d93d9228a375/diff:/var/lib/docker/overlay2/92104b9c6462f881a0670d2d48827ecf52636487f5bfdba51a0765e82b314566/diff:/var/lib/docker/overlay2/999cea00b3e609c7a07bd1313380ba34f7d728f7c02ab523514473fd9ab286ea/diff:/var/lib/docker/overlay2/6ee94ecb57c98054be5f9b6cea083624ec67a72d527a22eb59ee0c880f59f85d/diff:/var/lib/docker/overlay2/3352e69dc1c1de67b0d311d76f81412a8d7f3caabf96e4290234102333a7d5b1/diff\",\n",
      "                \"MergedDir\": \"/var/lib/docker/overlay2/ff38286f945ff9b004d16724c0543819410a5b9924c8f1352c1432caab7c4aa3/merged\",\n",
      "                \"UpperDir\": \"/var/lib/docker/overlay2/ff38286f945ff9b004d16724c0543819410a5b9924c8f1352c1432caab7c4aa3/diff\",\n",
      "                \"WorkDir\": \"/var/lib/docker/overlay2/ff38286f945ff9b004d16724c0543819410a5b9924c8f1352c1432caab7c4aa3/work\"\n",
      "            },\n",
      "            \"Name\": \"overlay2\"\n",
      "        },\n",
      "        \"RootFS\": {\n",
      "            \"Type\": \"layers\",\n",
      "            \"Layers\": [\n",
      "                \"sha256:1dc52a6b4de8561423dd3ec5a1f7f77f5309fd8cb340f80b8bc3d87fa112003e\",\n",
      "                \"sha256:b13a10ce059365d68a2113e9dbcac05b17b51f181615fca6d717a0dcf9ba8ffb\",\n",
      "                \"sha256:790d00cf365a312488151b354f0b0ae826be031edffb8a4de6a1fab048774dc7\",\n",
      "                \"sha256:323e43c53a1cd5abbd55437588f19da04f716452bc6d05486759b35f3e485390\",\n",
      "                \"sha256:c99c9d462af0bac5511ed046178ab0de79b8cdad33cd85246e9f661e098426cd\",\n",
      "                \"sha256:4a3a4d9fb4d250b1b64629b23bc0a477a45ee2659a8410d59a31a181dad70002\",\n",
      "                \"sha256:27b35f432a27e5e275038e559ebbe1aa7e91447bf417f5da01e3326739ba9366\",\n",
      "                \"sha256:ee12325fe0b7e7930b76d9a3dc81fcc37fa51a3267b311d2ed7c38703f193d75\",\n",
      "                \"sha256:7ceb40593535cdc07299efa2ce3a2c2267c2fa683161515fd6ab97f733492bf0\",\n",
      "                \"sha256:f18dbe0eec054f0aedf54a94aa29dab0d2c0f3d920fb482c99819622b0094f47\",\n",
      "                \"sha256:df2a7845ea611463f9f3282ccb45156ba883f40b15013ee49bd0a569301738d8\",\n",
      "                \"sha256:bcbd5416b87e3e37e05c22e46cbff2e3503d9caa0ec283a44931dc63e51c8cb7\",\n",
      "                \"sha256:5bcbb3ccae766c8a72d98ce494500bfd44c32e5780a1cb153139a4c5c143a8d5\",\n",
      "                \"sha256:4ecc8a8ffa902f3ea9bebb8d610e02a32ce1ca94c1a3160a31da98b73c1f55a0\",\n",
      "                \"sha256:a7a7b8b26735eb2d137fd0f91b83c73ad48cf2c4b83e9d0cadece410d6e598ba\",\n",
      "                \"sha256:ae939a0c9d32674ad6674947853ecfda4ff0530a8137960064448ae5e45fa1c5\",\n",
      "                \"sha256:6948f39c8f3cf6ec104734ccd1112fcb4af85a7c26c9c3d43495494b9b799f25\",\n",
      "                \"sha256:affd18c8e88f35e75bd02158e0418f3aeb4eec4269a208ede24cc829fa88c850\"\n",
      "            ]\n",
      "        },\n",
      "        \"Metadata\": {\n",
      "            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!docker inspect 8a6ea8272ad0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass hyperparameters to SKLearn estimator\n",
    "\n",
    "Let's pass some dummy hyperparameters to the estimator and see how it affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating is8juu33rz-algo-1-wcm5g ... \n",
      "Creating is8juu33rz-algo-1-wcm5g ... done\n",
      "Attaching to is8juu33rz-algo-1-wcm5g\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:04,882 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:04,887 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:04,895 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:05,087 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:05,104 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:05,116 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:05,125 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m Training Env:\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m {\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"current_host\": \"algo-1-wcm5g\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m         \"algo-1-wcm5g\"\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     ],\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     },\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-15-36-01-969\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"master_hostname\": \"algo-1-wcm5g\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-01-969/source/sourcedir.tar.gz\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m         \"current_host\": \"algo-1-wcm5g\",\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m             \"algo-1-wcm5g\"\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m         ]\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     },\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m }\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m Environment variables:\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_HOSTS=[\"algo-1-wcm5g\"]\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-wcm5g\",\"hosts\":[\"algo-1-wcm5g\"]}\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_CURRENT_HOST=algo-1-wcm5g\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-01-969/source/sourcedir.tar.gz\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-wcm5g\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-wcm5g\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-15-36-01-969\",\"log_level\":20,\"master_hostname\":\"algo-1-wcm5g\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-01-969/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-wcm5g\",\"hosts\":[\"algo-1-wcm5g\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m \n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g |\u001b[0m 2022-07-15 15:36:05,152 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mis8juu33rz-algo-1-wcm5g exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-hyperparams](images/2022-07-07-sagemaker-script-mode/sklearn-output-hyperparams.png)\n",
    "\n",
    "From the output we can see that our hyperparameters were passed to our training script as command line arguments. This is an important point and we will update our script using this information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker SKLearn container environment variables\n",
    "Let's now discuss the essential environment variables we see in the output.\n",
    "\n",
    "### SM_MODULE_DIR\n",
    "```\n",
    "SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\n",
    "```\n",
    "`SM_MODULE_DIR` points to a location in the S3 bucket where SageMaker will automatically backup our source code for that particular run. SageMaker will create a separate folder in the default bucket for each new run. The default value is `s3://sagemaker-{aws-region}-{aws-id}/{training-job-name}/source/sourcedir.tar.gz`\n",
    "\n",
    "### SM_MODEL_DIR\n",
    "```\n",
    "SM_MODEL_DIR=/opt/ml/model\n",
    "```\n",
    "`SM_MODEL_DIR` points to a directory located inside the container. When the training job finishes, the container and its file system will be deleted, except for the `/opt/ml/model` and `/opt/ml/output` directories. Use `/opt/ml/model` to save the trained model artifacts. These artifacts are uploaded to S3 for model hosting.\n",
    "\n",
    "### SM_OUTPUT_DATA_DIR\n",
    "```\n",
    "SM_OUTPUT_DIR=/opt/ml/output\n",
    "```\n",
    "`SM_OUTPUT_DIR` points to a directory in the container to write output artifacts. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "### SM_CHANNELS\n",
    "From the SKLearn estimator output\n",
    "```\n",
    "SM_CHANNELS='[\"testing\",\"training\"]'\n",
    "```\n",
    "A channel is a named input source that training algorithms can consume. You can partition your training data into different logical \"channels\" when you run training. Depending on your problem, some common channel ideas are: \"training\", \"testing\", \"evaluation\" or \"images\" and \"labels\". You can read more about the channels from SageMaker API reference [Channel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Channel.html)\n",
    "\n",
    "### SM_CHANNEL_{channel_name}\n",
    "```\n",
    "SM_CHANNEL_TRAIN='/opt/ml/input/data/train'\n",
    "SM_CHANNEL_TEST='/opt/ml/input/data/test'\n",
    "```\n",
    "Supposing that you have passed two input channels, 'train' and 'test', to the Scikit-learn estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "* **`SM_CHANNEL_TRAIN`**: it points to the directory in the container that has the *train* channel data downloaded\n",
    "* **`SM_CHANNEL_TEST`**: Same as above, but for the *test* channel\n",
    "\n",
    "Note that the channel names `train` and `test` are the conventions. Still, you can use any name here, and the environment variables will be created accordingly. It is important to know that the SageMaker container automatically downloads the data from the provided input channels and makes them available in the respective local directories once it starts executing. The training script can then load the data from the local container directories.\n",
    "\n",
    "There are more environment variables available, and you can read about them from [Environment variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass input channel to SKLearn estimator\n",
    "\n",
    "Now that we understand the SKLearn container environment more let's pass the training data channel to the estimator and see if the data becomes available inside the container directory. \n",
    "\n",
    "Update our script to list all the files in the `SM_CHANNEL_TRAIN` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "\n",
    "    print(\"training_dir files list: \", dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating og7ky0suq7-algo-1-6mno5 ... \n",
      "Creating og7ky0suq7-algo-1-6mno5 ... done\n",
      "Attaching to og7ky0suq7-algo-1-6mno5\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:07,974 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:07,980 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:07,994 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:08,259 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:08,273 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:08,286 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:08,295 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m Training Env:\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m {\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     },\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"current_host\": \"algo-1-6mno5\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"algo-1-6mno5\"\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     ],\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     },\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"train\": {\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         }\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     },\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-15-36-05-536\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"master_hostname\": \"algo-1-6mno5\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-05-536/source/sourcedir.tar.gz\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"current_host\": \"algo-1-6mno5\",\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m             \"algo-1-6mno5\"\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m         ]\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     },\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m }\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m Environment variables:\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_HOSTS=[\"algo-1-6mno5\"]\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-6mno5\",\"hosts\":[\"algo-1-6mno5\"]}\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_CURRENT_HOST=algo-1-6mno5\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-05-536/source/sourcedir.tar.gz\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-6mno5\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-6mno5\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-15-36-05-536\",\"log_level\":20,\"master_hostname\":\"algo-1-6mno5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-05-536/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-6mno5\",\"hosts\":[\"algo-1-6mno5\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 |\u001b[0m 2022-07-15 15:36:08,339 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mog7ky0suq7-algo-1-6mno5 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": f\"file://{local_train_path}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-traincsv](images/2022-07-07-sagemaker-script-mode/sklearn-output-traincsv.png)\n",
    "\n",
    "From the output, we can see that `train.csv`, which was in our local environment, is now available inside the container on path `SM_CHANNEL_TRAIN=/opt/ml/input/data/train`. \n",
    "\n",
    "Let's also test the same with our training data on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating nb47vcydpp-algo-1-uyjey ... \n",
      "Creating nb47vcydpp-algo-1-uyjey ... done\n",
      "Attaching to nb47vcydpp-algo-1-uyjey\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,110 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,115 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,133 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,379 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,399 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,420 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,435 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m Training Env:\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m {\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     },\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"current_host\": \"algo-1-uyjey\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"algo-1-uyjey\"\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     ],\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     },\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"train\": {\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         }\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     },\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-15-36-08-737\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"master_hostname\": \"algo-1-uyjey\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-08-737/source/sourcedir.tar.gz\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"current_host\": \"algo-1-uyjey\",\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m             \"algo-1-uyjey\"\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m         ]\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     },\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m }\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m Environment variables:\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_HOSTS=[\"algo-1-uyjey\"]\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-uyjey\",\"hosts\":[\"algo-1-uyjey\"]}\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_CURRENT_HOST=algo-1-uyjey\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-08-737/source/sourcedir.tar.gz\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-uyjey\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-uyjey\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-15-36-08-737\",\"log_level\":20,\"master_hostname\":\"algo-1-uyjey\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-36-08-737/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-uyjey\",\"hosts\":[\"algo-1-uyjey\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey |\u001b[0m 2022-07-15 15:36:11,493 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mnb47vcydpp-algo-1-uyjey exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the results are the same. SageMaker will download the data from the S3 bucket and make it available in the container. In the environment variables section we also learned that two directories are special `/opt/ml/model` and `/opt/ml/output`. Container environment variables `SM_MODEL_DIR` and `SM_OUTPUT_DATA_DIR` point to them, respectively. Whatever artifacts we put on them will be stored on the S3 bucket when the training job finishes. \"SM_MODEL_DIR\" is for trained models, and \"SM_OUTPUT_DATA_DIR\" is for other artifacts like logs, graphs, plots, resutls, etc. Let's update our training script and put some dummy data in these directories. Once the job is complete, we will verify the stored artifacts on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    # list files in SM_CHANNEL_TRAIN\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "    print(\"training_dir files list: \", dir_list)\n",
    "\n",
    "    # write dummy model file to SM_MODEL_DIR\n",
    "    sm_model_dir = os.environ.get(\"SM_MODEL_DIR\")\n",
    "    with open(f\"{sm_model_dir}/dummy-model.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy model\")\n",
    "\n",
    "    # write dummy artifact file to SM_OUTPUT_DATA_DIR\n",
    "    sm_output_data_dir = os.environ.get(\"SM_OUTPUT_DATA_DIR\")\n",
    "    with open(f\"{sm_output_data_dir}/dummy-output-data.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy output data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating k9pmsvrsp9-algo-1-djiyl ... \n",
      "Creating k9pmsvrsp9-algo-1-djiyl ... done\n",
      "Attaching to k9pmsvrsp9-algo-1-djiyl\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:24,782 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:24,787 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:24,796 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:25,028 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:25,041 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:25,053 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:25,062 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m Training Env:\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m {\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     },\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"current_host\": \"algo-1-djiyl\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"algo-1-djiyl\"\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     ],\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     },\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"train\": {\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         }\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     },\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-15-43-22-192\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"master_hostname\": \"algo-1-djiyl\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/source/sourcedir.tar.gz\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"current_host\": \"algo-1-djiyl\",\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m             \"algo-1-djiyl\"\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m         ]\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     },\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m }\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m Environment variables:\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_HOSTS=[\"algo-1-djiyl\"]\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-djiyl\",\"hosts\":[\"algo-1-djiyl\"]}\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_CURRENT_HOST=algo-1-djiyl\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/source/sourcedir.tar.gz\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-djiyl\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-djiyl\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-15-43-22-192\",\"log_level\":20,\"master_hostname\":\"algo-1-djiyl\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-djiyl\",\"hosts\":[\"algo-1-djiyl\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl |\u001b[0m 2022-07-15 15:43:25,100 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mk9pmsvrsp9-algo-1-djiyl exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpzaenwk6d/algo-1-djiyl Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training job is now complete. Let us check the S3 bucket to see if our dummy model and other artifacts are present.\n",
    "\n",
    "First, we need the S3 URI for these artifacts. For our dummy model (from SM_MODEL_DIR), we can use our estimator object to get the URI. Let's call it `model_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/model.tar.gz'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = sk_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_data` from S3 will be downloaded to a local directory for verification. Let's create a local `tmp` to store these downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/2022-07-07-sagemaker-script-mode/tmp\n"
     ]
    }
   ],
   "source": [
    "local_tmp_path = local_path + \"/tmp\"\n",
    "print(local_tmp_path)\n",
    "\n",
    "# create the local '/tmp' directory\n",
    "Path(local_tmp_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SageMaker `S3Downloader` object to download the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "S3Downloader.download(\n",
    "    s3_uri=model_data, local_path=local_tmp_path, sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File is downloaded. Let's uncompress it to verify the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy-model.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_tmp_path/model.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the \"dummy-model.txt\" file is present. This tells us that SageMaker will automatically upload the files from the model directory (SM_MODEL_DIR) to the S3 bucket. Let's do the same for the output data directory (SM_OUTPUT_DATA_DIR). There is no direct way to get the S3 URI from the estimator object for the output data directory. But we can prepare it ourselves. So let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator.output_path:  s3://sagemaker-us-east-1-801598032724/\n",
      "estimator.latest_training_job.name:  sagemaker-scikit-learn-2022-07-15-15-43-22-192\n"
     ]
    }
   ],
   "source": [
    "print(\"estimator.output_path: \", sk_estimator.output_path)\n",
    "print(\"estimator.latest_training_job.name: \", sk_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_s3_output_uri(estimator):\n",
    "    return estimator.output_path + estimator.latest_training_job.name\n",
    "    \n",
    "get_s3_output_uri(sk_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/output.tar.gz'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for output data artifacts\n",
    "s3_output_uri = get_s3_output_uri(sk_estimator) + '/output.tar.gz'\n",
    "s3_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/model.tar.gz'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "# S3 URI for model artifact. We have already veirifed it.\n",
    "s3_model_uri = get_s3_output_uri(sk_estimator) + '/model.tar.gz'\n",
    "s3_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/source/sourcedir.tar.gz'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for source code\n",
    "s3_source_uri = get_s3_output_uri(sk_estimator) + '/source/sourcedir.tar.gz'\n",
    "s3_source_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download these artifacts to our local '/tmp' directory for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/output.tar.gz to datasets/2022-07-07-sagemaker-script-mode/tmp/output.tar.gz\n",
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-43-22-192/source/sourcedir.tar.gz to datasets/2022-07-07-sagemaker-script-mode/tmp/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $s3_output_uri $local_tmp_path\n",
    "!aws s3 cp $s3_source_uri $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/dummy-output-data.txt\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# extract the output data files from 'output.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/output.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# extract the source code files from 'sourcedir.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/sourcedir.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary till now\n",
    "Let's summarize what we have learned till now.\n",
    "* We can use SageMaker SKLearn local mode to test our code in a local environment\n",
    "* SKLearn container executes our provided script with the command `/miniconda3/bin/python train_and_server.py`\n",
    "* Hyperparameters passed to the container are passed to our script as command line arguments\n",
    "* Data from input channels will be downloaded by the container and made available for our script to load and process\n",
    "* '/opt/ml/model' and '/opt/ml/output' directories are special. Anything stored on them will be automatically backed up on the S3 bucket when the job finishes. These directories are defined in the container environment variables 'SM_MODEL_DIR' and 'SM_OUTPUT_DATA_DIR', respectively. SM_MODEL_DIR should be used to write model artifacts. SM_OUTPUT_DATA_DIR should be used to write any other supporting artifact.\n",
    "\n",
    "Let's use this knowledge to update our script to train a RandomForrestClassifier on the Iris flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# cleanup /tmp directory before moving to next section\n",
    "!rm -r $local_tmp_path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training script for RandomForestClassifier\n",
    "\n",
    "Let's update our training script to train a scikit-learn random forest classifier model on the iris data set. The script will read training and testing data from input data channel directories and trains a classifier on it. It will then save the model to the model directory and validation results ('y_pred.csv') to the output data directory. Notice that we have also parsed container environment variables as command line arguments. It makes sense for hyperparameters ('estimators') because we know they will be passed to the script as command line parameters. For container environment variables (e.g. 'SM_MODEL_DIR'), we have checked first if they are given as command line arguments. If they are, then we parse them to get the values. Otherwise, we read their values from the environment. This is done because we can quickly test our script locally from the command line without setting the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")\n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now give proper execution rights to the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x $script_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our script once before passing it to the SKLearn estimator. We will invoke this script from a command line and pass the required parameters similar to how an estimator container will execute it. For testing this script, we need to pass four directory paths:\n",
    "* **sm-model-dir** This will point to a directory where our script will store the trained model. We can point it to '/tmp' directory for test purposes\n",
    "* **sm-channel-train** This will point to a directory containing training data. We already have it as 'local_train_path'\n",
    "* **sm-channel-test** This will point to a directory containing test data. We also have it as 'local_test_path'\n",
    "* **sm-output-data-dir** This will point to a directory where our script will store other artifacts. We can also point it to '/tmp' directory for test purposes\n",
    "\n",
    "Once the script is successfully run, we will find the trained model file 'model.joblib' and 'y_pred.csv' in the '/tmp' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command line arguments:  Namespace(estimators=10, sm_channel_test='./datasets/2022-07-07-sagemaker-script-mode/test', sm_channel_train='./datasets/2022-07-07-sagemaker-script-mode/train', sm_model_dir='./datasets/2022-07-07-sagemaker-script-mode/tmp', sm_output_data_dir='./datasets/2022-07-07-sagemaker-script-mode/tmp')\n",
      "training_dir: ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "training_dir files list: ['train.csv']\n",
      "testing_dir: ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "testing_dir files list: ['test.csv']\n",
      "sm_model_dir: ./datasets/2022-07-07-sagemaker-script-mode/tmp\n",
      "output_data_dir: ./datasets/2022-07-07-sagemaker-script-mode/tmp\n",
      "X_train.shape: (120, 4)\n",
      "y_train.shape: (120,)\n",
      "X_train.shape: (30, 4)\n",
      "y_train.shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!python3 $script_file \\\n",
    "    --sm-model-dir $local_tmp_path \\\n",
    "    --sm-channel-train $local_train_path \\\n",
    "    --sm-channel-test $local_test_path \\\n",
    "    --sm-output-data-dir $local_tmp_path \\\n",
    "    --estimators 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the local '/tmp' directory for artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib  y_pred.csv\n"
     ]
    }
   ],
   "source": [
    "!ls $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have test our script and it is working as expected, let's pass it to SKLean container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fbf900wrc3-algo-1-rpajw ... \n",
      "Creating fbf900wrc3-algo-1-rpajw ... done\n",
      "Attaching to fbf900wrc3-algo-1-rpajw\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:04,886 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:04,891 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:04,900 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:05,138 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:05,151 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:05,163 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:05,172 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m Training Env:\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     },\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"current_host\": \"algo-1-rpajw\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"algo-1-rpajw\"\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     ],\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     },\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"train\": {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         },\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"test\": {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         }\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     },\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-15-45-01-891\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"master_hostname\": \"algo-1-rpajw\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-45-01-891/source/sourcedir.tar.gz\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"current_host\": \"algo-1-rpajw\",\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m             \"algo-1-rpajw\"\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m         ]\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     },\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m }\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m Environment variables:\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_HOSTS=[\"algo-1-rpajw\"]\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-rpajw\",\"hosts\":[\"algo-1-rpajw\"]}\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_CURRENT_HOST=algo-1-rpajw\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-45-01-891/source/sourcedir.tar.gz\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-rpajw\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-rpajw\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-15-45-01-891\",\"log_level\":20,\"master_hostname\":\"algo-1-rpajw\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-45-01-891/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-rpajw\",\"hosts\":[\"algo-1-rpajw\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m \n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw |\u001b[0m 2022-07-15 15:45:06,501 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mfbf900wrc3-algo-1-rpajw exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpsntvy68r/algo-1-rpajw Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# cleanup /tmp directory before moving to next section\n",
    "!rm -r $local_tmp_path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing custom libraries and dependencies to SKLean container\n",
    "\n",
    "We have successfully trained our classifier but assume we have an additional task. One of your colleagues has created a library that takes the confusion matrix array and plots it with [seaborn visualization library](https://seaborn.pydata.org/). You have been told to use this custom library with the training script and save the confusion matrix plot to the output data directory.\n",
    "\n",
    "Let's prepare code for this custom library to take an array and return a confusion matrix plot from seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_library_path: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library\n",
      "custom_library_file: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "# create a path to store the custom library code\n",
    "custom_library_path = local_path + \"/my_custom_library\"\n",
    "custom_library_file = custom_library_path + \"/seaborn_confusion_matrix.py\"\n",
    "\n",
    "print(f\"custom_library_path: {custom_library_path}\")\n",
    "print(f\"custom_library_file: {custom_library_file}\")\n",
    "\n",
    "# make sure the path exists\n",
    "Path(custom_library_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code to plot the confusion matrix. We have added some code to test this library in our local environment from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_file\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import argparse, os\n",
    "\n",
    "\n",
    "def save_confusion_matrix(cf_matrix, path=\"./\"):\n",
    "    sns_plot = sns.heatmap(cf_matrix, annot=True)\n",
    "    sns_plot.figure.savefig(path + \"/output_cm.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--path\", type=str, default=\"./\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    path = args.path\n",
    "\n",
    "    dummy_cm = np.array([[23, 5], [3, 30]])\n",
    "    save_confusion_matrix(dummy_cm, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert directory container seaborn code into a Python package directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_path/__init__.py\n",
    "\n",
    "from .seaborn_confusion_matrix import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom library has a dependency on the seaborn Python package. So let's create 'requirements.txt' and put all our dependencies in it. Later it will be passed to the SKLean container to install them during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path/requirements.txt\n",
    "\n",
    "seaborn==0.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this library in our local environment first. It should plot a dummy confusion matrix in local temp directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: seaborn==0.11.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from -r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (4.28.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt (line 2)) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "# intall the dependiencies first\n",
    "!pip install -r $script_path/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# test the custom library\n",
    "!python3 $custom_library_file --path $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_cm.png\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# verify the custom library output from the /tmp directory\n",
    "!ls $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our custom library code works. Let's update our script to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")  \n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")\n",
    "\n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "\n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\")\n",
    "\n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all the ingredients are ready. Let's run our script from the SKLean container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 92ur61eo7m-algo-1-s3euc ... \n",
      "Creating 92ur61eo7m-algo-1-s3euc ... done\n",
      "Attaching to 92ur61eo7m-algo-1-s3euc\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:50:57,659 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:50:57,663 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:50:57,672 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:50:57,872 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Collecting seaborn==0.11.2\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[?25hRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Collecting matplotlib>=2.2\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Requirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Requirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Collecting pyparsing>=2.2.1\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Collecting fonttools>=4.22.0\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.3 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \u001b[0m2022-07-15 15:51:04,191 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:51:04,205 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:51:04,218 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:51:04,227 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Training Env:\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     },\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"current_host\": \"algo-1-s3euc\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"algo-1-s3euc\"\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     ],\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     },\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"train\": {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         },\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"test\": {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         }\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     },\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-15-50-54-741\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"master_hostname\": \"algo-1-s3euc\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-50-54-741/source/sourcedir.tar.gz\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"current_host\": \"algo-1-s3euc\",\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m             \"algo-1-s3euc\"\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m         ]\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     },\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m }\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Environment variables:\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_HOSTS=[\"algo-1-s3euc\"]\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-s3euc\",\"hosts\":[\"algo-1-s3euc\"]}\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_CURRENT_HOST=algo-1-s3euc\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-50-54-741/source/sourcedir.tar.gz\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-s3euc\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-s3euc\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-15-50-54-741\",\"log_level\":20,\"master_hostname\":\"algo-1-s3euc\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-15-50-54-741/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-s3euc\",\"hosts\":[\"algo-1-s3euc\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m \n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36m92ur61eo7m-algo-1-s3euc |\u001b[0m 2022-07-15 15:51:06,714 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp4vo1y3fi/algo-1-s3euc Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m92ur61eo7m-algo-1-s3euc exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**image here**\n",
    "SKLearn container shows that our classifier is successfully trained, and the model and output artifacts are placed in their respective folders. We know from the first section of this post that these artifacts will automatically be uploaded to the S3 bucket. This concluded the model training part of our implementation. Let's now proceed to model serving part of our solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve SKLearn model in local mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have our trained model ready. Can we deploy it already?\n",
    "\n",
    "The answer is no. If we try to deploy this model using command\n",
    "```\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")\n",
    "```\n",
    "It will generate an exception message telling us that the estimator does not know how to load the model. So we need to tell the estimator by implementing `model_fn` function in our script.\n",
    "\n",
    "```\n",
    "[2022-07-09 06:15:45 +0000] [31] [ERROR] Error handling request /ping\n",
    "Traceback (most recent call last):\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
    "    return fn(*args, **kwargs)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/serving.py\", line 43, in default_model_fn\n",
    "    return transformer.default_model_fn(model_dir)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 35, in default_model_fn\n",
    "    raise NotImplementedError(\n",
    "NotImplementedError: \n",
    "Please provide a model_fn implementation.\n",
    "See documentation for model_fn at https://github.com/aws/sagemaker-python-sdk\n",
    "```\n",
    "\n",
    "The *model_fn* should have the following signature:\n",
    "```\n",
    "def model_fn(model_dir)\n",
    "```\n",
    "\n",
    "Besides loading the model, we also need the model server to get predictions from the loaded model. For this, we need to implement the second function *predict_fn* which should have the following signature.\n",
    "```\n",
    "def predict_fn(input_data, model)\n",
    "```\n",
    "\n",
    "After we have called the `fit` function on our SKLearn estimator, we can deploy it by calling the `deploy` function to create an inference endpoint. Once you call `deploy` on the estimator two objects are created in response\n",
    "* SageMaker scikit-learn Endpoint: This Endpoint encapsulates a model server running under it. The model server will load the model saved during training and perform inference on it. It requires two helper functions to load the model and make inferences on it: model_fn and predict_fn.\n",
    "* Predictor object: This object is returned in response to the deploy call. It can be used to do inference on the Endpoint hosting our SKLearn model.\n",
    "\n",
    "Let's update our script and add these two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    # sm-channel-train: input training data location\n",
    "    # sm-channel-test: input test data location\n",
    "    # sm-output-data-dir: output artifacts location\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"command line arguments: \", args)\n",
    "\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "\n",
    "    print(f\"training_dir: {training_dir}\")\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\")  \n",
    "    print(f\"testing_dir: {testing_dir}\")\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\")\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "\n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir + \"/model.joblib\")\n",
    "\n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir + \"/y_pred.csv\")\n",
    "\n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "\n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\")\n",
    "\n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\")\n",
    "\n",
    "\n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 2x2umr6uyk-algo-1-475rz ... \n",
      "Creating 2x2umr6uyk-algo-1-475rz ... done\n",
      "Attaching to 2x2umr6uyk-algo-1-475rz\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:01,871 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:01,878 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:01,892 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:02,113 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Collecting seaborn==0.11.2\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[?25hCollecting matplotlib>=2.2\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[?25hRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Requirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Requirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m818.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Collecting pyparsing>=2.2.1\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Collecting cycler>=0.10\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.3 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \u001b[0m2022-07-15 16:48:08,784 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:08,802 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:08,822 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:08,835 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Training Env:\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     },\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"current_host\": \"algo-1-475rz\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"algo-1-475rz\"\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     ],\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     },\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"train\": {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         },\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"test\": {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         }\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     },\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-15-16-47-59-202\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"master_hostname\": \"algo-1-475rz\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-16-47-59-202/source/sourcedir.tar.gz\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"current_host\": \"algo-1-475rz\",\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m             \"algo-1-475rz\"\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m         ]\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     },\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m }\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Environment variables:\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_HOSTS=[\"algo-1-475rz\"]\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-475rz\",\"hosts\":[\"algo-1-475rz\"]}\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_CURRENT_HOST=algo-1-475rz\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-16-47-59-202/source/sourcedir.tar.gz\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-475rz\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-475rz\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-15-16-47-59-202\",\"log_level\":20,\"master_hostname\":\"algo-1-475rz\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-15-16-47-59-202/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-475rz\",\"hosts\":[\"algo-1-475rz\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m \n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz |\u001b[0m 2022-07-15 16:48:11,962 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m2x2umr6uyk-algo-1-475rz exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpz8otahgz/algo-1-475rz Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to qveck8plk5-algo-1-j6ron\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,368 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,372 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,373 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m worker_processes auto;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m daemon off;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m events {\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m }\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m http {\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   }\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   server {\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     }\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     location / {\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m     }\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   }\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m }\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,594 INFO - sagemaker-containers - Module train_and_serve does not provide a setup.py. \n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Generating setup.py\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,595 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,595 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:19,595 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m /miniconda3/bin/python3 -m pip install . -r requirements.txt\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hCollecting seaborn==0.11.2\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022/07/15 16:48:22 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 172.18.0.1 - - [15/Jul/2022:16:48:22 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Requirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.1.3)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Collecting matplotlib>=2.2\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Collecting pyparsing>=2.2.1\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Collecting cycler>=0.10\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Requirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hCollecting packaging>=20.0\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 2)) (2022.1)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Building wheels for collected packages: train-and-serve\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Building wheel for train-and-serve (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[?25h  Created wheel for train-and-serve: filename=train_and_serve-1.0.0-py2.py3-none-any.whl size=6122 sha256=6691974465579da8871d511531da3d05b51290a2cc27ed694f999ed3dfcd6137\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-ragqrv8c/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Successfully built train-and-serve\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Installing collected packages: train-and-serve, pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022/07/15 16:48:27 [crit] 13#13: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 172.18.0.1 - - [15/Jul/2022:16:48:27 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.8\"\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.3 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2 train-and-serve-1.0.0\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m \u001b[0m2022-07-15 16:48:31,169 INFO - matplotlib.font_manager - generated new fontManager\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m [2022-07-15 16:48:32 +0000] [35] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m [2022-07-15 16:48:32 +0000] [35] [INFO] Listening at: unix:/tmp/gunicorn.sock (35)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m [2022-07-15 16:48:32 +0000] [35] [INFO] Using worker: gevent\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m [2022-07-15 16:48:32 +0000] [37] [INFO] Booting worker with pid: 37\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m [2022-07-15 16:48:32 +0000] [38] [INFO] Booting worker with pid: 38\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 2022-07-15 16:48:33,388 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m model_fn model_dir: /opt/ml/model\n",
      "!\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 172.18.0.1 - - [15/Jul/2022:16:48:34 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mqveck8plk5-algo-1-j6ron |\u001b[0m 172.18.0.1 - - [15/Jul/2022:16:48:52 +0000] \"POST /invocations HTTP/1.1\" 200 136 \"-\" \"python-urllib3/1.26.8\"\n"
     ]
    }
   ],
   "source": [
    "request = [[9.0, 3571, 1976, 0.525]]\n",
    "\n",
    "response  = sk_predictor.predict(request)\n",
    "response = int(response[0])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class category 2 (Iris-virginica)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted class category {} ({})\".format(response, categories_map[response]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                                               COMMAND   CREATED          STATUS          PORTS                                       NAMES\n",
      "dac241b02727   683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3   \"serve\"   59 seconds ago   Up 57 seconds   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp   qveck8plk5-algo-1-j6ron\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "* if you are already running a local endpoint then you will not be able to create a new one. if you have lost the kernel session then you can delete the running endpoint from terminal using kill command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the inputs and outputs\n",
    "# input in json and output in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # do i need this?\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.train\n",
    "    \n",
    "    # print training_dir info\n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X = df.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y = df[\"class_cat\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestRegressor(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(regressor, os.path.join(sm_model_dir, \"model.joblib\"))\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "\n",
    "    \n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == \"application/json\":\n",
    "        request_body = json.loads(request_body)\n",
    "        inpVar = request_body[\"Input\"]\n",
    "        return inpVar\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {\"Output\": res}\n",
    "    return respJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri})\n",
    "\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_endpoint_name = sk_predictor.endpoint_name\n",
    "sk_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "client = session_local.sagemaker_runtime_client\n",
    "\n",
    "request_body = {\"Input\": [[9.0, 3571, 1976, 0.525]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=sk_endpoint_name, ContentType=\"application/json\", Body=payload\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())[\"Output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted class category {} ({})\".format(result, categories_map[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
