{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Scikit-learn Models to Amazon SageMaker with the SageMaker Python SDK using Script mode\n",
    "> The aim of this notebook is to demonstrate how to train and deploy a scikit-learn model in Amazon SageMaker using script mode.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [aws, ml, sagemaker]\n",
    "- keyword: [aws, ml, sagemaker, sklearn, scikit-learn, python]\n",
    "- image: images/copied_from_nb/images/2022-07-07-sagemaker-script-mode.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/2022-07-07-sagemaker-script-mode.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "You may have trained a model with your favorite ML framework, and now you are asked to move your code to Amazon SageMaker. The good news is that SageMaker's fully managed training works well with many popular ML frameworks, including `scikit-learn.` In addition, SageMaker provides its prebuilt container for the scikit-learn framework, enabling us to port our scripts to SageMaker and benefit from its training and deployment capabilities. SageMaker's scikit-learn container is an open source library for making the scikit-learn framework run on the Amazon SageMaker platform. You can read more about sklearn container features from its GitHub page [SageMaker Scikit-learn Container](https://github.com/aws/sagemaker-scikit-learn-container).\n",
    "\n",
    "Amazon SageMaker also provides open source Python SDK to train and deploy models on SageMaker. SageMaker SDK provides several high-level abstractions (classes), including:\n",
    "* `Session` Provides a collection of methods for working with SageMaker resources \n",
    "* `Estimators` Encapsulate training on SageMaker\n",
    "* `Predictors` Provide real-time inference and transformation using Python data types against a SageMaker endpoint\n",
    "You can read more on SageMaker Python SDK from its official site [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html)\n",
    "\n",
    "This approach of using a custom training script with SageMaker's prebuilt container is commonly called **Script Mode**. To train a scikit-learn model by using the SageMaker Python SDK involves three steps:\n",
    "\n",
    "1. **Prepare a training script**. The training script is similar to any other scikit-learn training script that you might use outside of SageMaker\n",
    "2. **Create an Estimator object from class `sagemaker.sklearn.SKLearn`**. Scikit-learn estimator class handles end-to-end training and deployment of custom scikit-learn code. It will execute a scikit-learn script within a SageMaker Training Job. The managed scikit-learn environment is an Amazon-built Docker container that runs functions defined in the supplied `entry_point` Python script. \n",
    "3. **Call the Estimator's `fit` method on training data**. Training is started by calling `fit()` on this Estimator. After training is complete, calling `deploy()` creates a hosted SageMaker endpoint and returns a `SKLearnPredictor` instance that can be used to perform inference against the hosted model. We will discuss the `SKLearn` Estimator in more detail later in this post.\n",
    "\n",
    "To read more about using scikit-learn with the SageMaker Python SDK, you may refer to the official documentation [using Scikit-learn with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html). The official documentation is valuable, and I would highly recommend checking it and keeping it as a reference.\n",
    "\n",
    "In this post we will built a scikit-learn [RandomForrestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) on [iris public dataset](https://archive.ics.uci.edu/ml/datasets/iris). There is a similar example in SageMaker documentation. [Train a SKLearn Model using Script Mode](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-script-mode/sklearn/sklearn_byom_outputs.html). Still, it does not discuss many important elements of a scikit-learn container and its environment. This post will cover all the stages of training a scikit-learn model with script mode. I also noted that the example in the documentation uses `RandomForrestRegressor` on a classification problem which I believe is a mistake.\n",
    "\n",
    "We have much to cover and learn, so let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "notebook environment.\n",
    "\n",
    "# Prepare training and test data\n",
    "We will use **Iris flower dataset**. It includes three iris species (Iris setosa, Iris virginica, and Iris versicolor) with 50 samples each and some properties about each flower. You can read more about this dataset at [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class: Iris Setosa, Iris Versicolour, Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# download dataset\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-sample-files\", \"datasets/tabular/iris/iris.data\", \"iris.data\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"iris.data\",\n",
    "    header=None,\n",
    "    names=[\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"class\"],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len</th>\n",
       "      <th>sepal_wid</th>\n",
       "      <th>petal_len</th>\n",
       "      <th>petal_wid</th>\n",
       "      <th>class</th>\n",
       "      <th>class_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len  sepal_wid  petal_len  petal_wid        class  class_cat\n",
       "0        5.1        3.5        1.4        0.2  Iris-setosa          0\n",
       "1        4.9        3.0        1.4        0.2  Iris-setosa          0\n",
       "2        4.7        3.2        1.3        0.2  Iris-setosa          0\n",
       "3        4.6        3.1        1.5        0.2  Iris-setosa          0\n",
       "4        5.0        3.6        1.4        0.2  Iris-setosa          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# Convert the three classes from strings to integers in {0,1,2}\n",
    "df[\"class_cat\"] = df[\"class\"].astype(\"category\").cat.codes\n",
    "categories_map = dict(enumerate(df[\"class\"].astype(\"category\").cat.categories))\n",
    "print(categories_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and store train and test sets as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (120, 6)\n",
      "test.shape: (30, 6)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "print(f\"test.shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our dataset ready. Let's define a local directory where we keep all the files and artifacts related to this post. I will refer to this directory as 'workspace'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# `local_path` will be the root directory for this post.\n",
    "local_path = \"./datasets/2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have train and test sets ready. Let's create two more directories in our workspace and store our data in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_train_path: ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "local_test_path: ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "local_train_file: ./datasets/2022-07-07-sagemaker-script-mode/train/train.csv\n",
      "local_test_file: ./datasets/2022-07-07-sagemaker-script-mode/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# local paths\n",
    "local_train_path = f\"{local_path}/train\"\n",
    "local_test_path = f\"{local_path}/test\"\n",
    "\n",
    "# create local directories\n",
    "Path(local_train_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(local_test_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"local_train_path: {local_train_path}\")\n",
    "print(f\"local_test_path: {local_test_path}\")\n",
    "\n",
    "# local file names\n",
    "local_train_file = local_train_path + \"/train.csv\"\n",
    "local_test_file = local_test_path + \"/test.csv\"\n",
    "\n",
    "# write train and test CSV files\n",
    "train.to_csv(local_train_file, index=False)\n",
    "test.to_csv(local_test_file, index=False)\n",
    "\n",
    "print(f\"local_train_file: {local_train_file}\")\n",
    "print(f\"local_test_file: {local_test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "\n",
    "print(f\"sagemaker.__version__: {sagemaker.__version__}\")\n",
    "print(f\"Session: {session}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done is\n",
    "* imported the SageMaker Python SDK into our runtime\n",
    "* get a session to work with SageMaker API and other AWS services\n",
    "* get the execution role associated with the user profile. It is the same profile that is available to the user to work from console UI and has `AmazonSageMakerFullAccess` policy attached to it.\n",
    "* create or get a default bucket to use and return its name. Default bucket name has the format `sagemaker-{region}-{account_id}`. If it doesn't exist then our session will automatically create it. You may also use any other bucket in its place given that you have enough permission for reading and writing.\n",
    "* get the region name attached to our session\n",
    "\n",
    "Next, we will use this session to upload data to our default bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# You may choose any other prefix for your bucket.\n",
    "# All the data related to this post will be under this prefix.\n",
    "bucket_prefix = \"2022-07-07-sagemaker-script-mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload the data. In the output, we will get the complete path (S3 URI) for our uploaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_train_uri: s3://sagemaker-us-east-1-801598032724/sklearn-iris/data/train.csv\n",
      "s3_test_uri: s3://sagemaker-us-east-1-801598032724/sklearn-iris/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "s3_train_uri = session.upload_data(local_train_file, key_prefix=bucket_prefix + \"/data\")\n",
    "s3_test_uri = session.upload_data(local_test_file, key_prefix=bucket_prefix + \"/data\")\n",
    "\n",
    "print(f\"s3_train_uri: {s3_train_uri}\")\n",
    "print(f\"s3_test_uri: {s3_test_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point our data preparation step is complete. Training and test CSV files are available both on the local system, and in our default Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker local environment\n",
    "The Amazon SageMaker training environment is managed, but SageMaker Python SDK also supports **local mode**, allowing you to train and deploy models to your local environment. This is a great way to test training scripts before running them in SageMaker's managed training or hosting environment.\n",
    "\n",
    "## How SageMaker managed environment works?\n",
    "When you send a request to SageMaker API (fit or deploy call)\n",
    "* it spins up new instances with the provided specification\n",
    "* loads the algorithm container\n",
    "* pulls the data from S3\n",
    "* runs the training code\n",
    "* store the results and trained model artifacts to S3\n",
    "* terminates the new instances\n",
    "\n",
    "All this happens behind the scenes with a single line of code and is a huge advantage. Spinning up new hardware every time can be good for repeatability and security, but it can add some friction while testing and debugging our code. We can test our code on a small dataset in our local environment with SageMaker local mode and then switch seamlessly to SageMaker managed environment by changing a single line of code.\n",
    "\n",
    "## Steps to prepare Amazon SageMaker local environment\n",
    "Install the following pre-requisites if you want to set up Amazon SageMaker on your local system.\n",
    "1. Install required Python packages:\n",
    "    ```\n",
    "    pip install boto3 sagemaker pandas scikit-learn\n",
    "    pip install 'sagemaker[local]'\n",
    "    ```\n",
    "2. Docker Desktop installed and running on your computer:\n",
    "    ```\n",
    "    docker ps\n",
    "    ```\n",
    "3. You should have AWS credentials configured on your local machine to be able to pull the docker image from ECR.\n",
    "\n",
    "### Instructions for SageMaker notebook instances\n",
    "You can also set up SageMaker's local environment in SageMaker notebook instances. Required Python packages and Docker service is already there. You only need to upgrade the `sagemaker[local]` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker[local] in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.99.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.3.4)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.0.1)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (3.19.1)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (20.3.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.1.5)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (21.3)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.21.42)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (0.2.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.20.3)\n",
      "Requirement already satisfied: urllib3==1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.26.8)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.4.1)\n",
      "Requirement already satisfied: docker-compose==1.29.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (1.29.2)\n",
      "Requirement already satisfied: docker~=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker[local]) (5.0.3)\n",
      "Requirement already satisfied: dockerpty<1,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.4.1)\n",
      "Requirement already satisfied: websocket-client<1,>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.59.0)\n",
      "Requirement already satisfied: texttable<2,>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.6.4)\n",
      "Requirement already satisfied: jsonschema<4,>=2.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: python-dotenv<1,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.20.0)\n",
      "Requirement already satisfied: distro<2,>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (1.7.0)\n",
      "Requirement already satisfied: docopt<1,>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (0.6.2)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker-compose==1.29.2->sagemaker[local]) (2.26.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.42 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (1.24.46)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker[local]) (0.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker[local]) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker[local]) (3.0.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker[local]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker[local]) (2021.3)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker[local]) (1.6.6.4)\n",
      "Requirement already satisfied: paramiko>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from docker~=5.0.0->sagemaker[local]) (2.10.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose==1.29.2->sagemaker[local]) (59.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose==1.29.2->sagemaker[local]) (2.0.8)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (3.2.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (36.0.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker~=5.0.0->sagemaker[local]) (2.21)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#collapse_output\n",
    "# this is required for SageMaker notebook instances\n",
    "!pip install 'sagemaker[local]' --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for SageMaker Studio environment\n",
    "Note that SageMaker local mode will not work in SageMaker Studio environment as it does not have docker service installed on instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker local session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.local.local_session.LocalSession at 0x7f85747c6a30>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "\n",
    "session_local = LocalSession()\n",
    "session_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# configure local session\n",
    "session_local.config = {\"local\": {\"local_code\": True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker training script\n",
    "\n",
    "We will call our training script `train_and_serve.py` and place it in our workspace under the `/src` folder. Then, we will start with a simple `Hello World` message code. After that, we will update and complete our training script as we learn more about the SageMaker `scikit-learn` container environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_file_name: train_and_serve.py\n",
      "script_path: ./datasets/2022-07-07-sagemaker-script-mode/src\n",
      "script_file: ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "script_file_name = \"train_and_serve.py\"\n",
    "script_path = f\"{local_path}/src\"\n",
    "script_file = script_path + \"/\" + script_file_name\n",
    "\n",
    "print(f\"script_file_name: {script_file_name}\")\n",
    "print(f\"script_path: {script_path}\")\n",
    "print(f\"script_file: {script_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the directory exists\n",
    "Path(script_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*** Hello from the SageMaker script mode***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SageMaker SKLearn estimator\n",
    "\n",
    "To use our `train_and_serve.py` script with SageMaker SKLearn estimator, we need to provide the following required items\n",
    "* **`entry_point (str)`** Path (absolute or relative) to the Python source file, which should be executed as the entry point to training. If source_dir is specified, then entry_point must point to a file located at the root of source_dir.\n",
    "* **`framework_version (str)`** Scikit-learn version you want to use for executing your model training code.\n",
    "* **`role (str)`** An AWS IAM role (either name or full ARN)\n",
    "* **`instance_type (str)`** Type of instance to use for training. For local mode use string **`local`**\n",
    "* **`instance_count (int)`** Number of instances to use for training. Since we will train in the local environment and have a single instance, we will use '1' here.\n",
    "\n",
    "You can read more about the SKLearn Estimator class from the official documentation [Scikit Learn Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the SKLearn framework version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that version number `1.0.1` has to be provided to the SKLearn estimator class as **`1.0-1`**. Otherwise, you will get the following error message.\n",
    "```\n",
    "ValueError: Unsupported sklearn version: 1.0.1. You may need to upgrade your SDK version (pip install -U sagemaker) for newer sklearn versions. Supported sklearn version(s): 0.20.0, 0.23-1, 1.0-1.\n",
    "```\n",
    "\n",
    "Now let us create the SageMaker SKLearn estimator object and pass our training script to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating uws5uf81g1-algo-1-sboaf ... \n",
      "Creating uws5uf81g1-algo-1-sboaf ... done\n",
      "Attaching to uws5uf81g1-algo-1-sboaf\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,717 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,722 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,731 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,886 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,899 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,912 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,922 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m Training Env:\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m {\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"current_host\": \"algo-1-sboaf\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"hosts\": [\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m         \"algo-1-sboaf\"\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     ],\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-05-45-584\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"master_hostname\": \"algo-1-sboaf\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-45-584/source/sourcedir.tar.gz\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m         \"current_host\": \"algo-1-sboaf\",\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m         \"hosts\": [\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m             \"algo-1-sboaf\"\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m         ]\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     },\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m }\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m Environment variables:\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_HOSTS=[\"algo-1-sboaf\"]\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_HPS={}\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-sboaf\",\"hosts\":[\"algo-1-sboaf\"]}\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_CURRENT_HOST=algo-1-sboaf\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-45-584/source/sourcedir.tar.gz\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-sboaf\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-sboaf\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-05-45-584\",\"log_level\":20,\"master_hostname\":\"algo-1-sboaf\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-45-584/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-sboaf\",\"hosts\":[\"algo-1-sboaf\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m /miniconda3/bin/python train_and_serve.py\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m \n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf |\u001b[0m 2022-07-13 13:05:47,950 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36muws5uf81g1-algo-1-sboaf exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"local\",\n",
    "    framework_version=\"1.0-1\",\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first run the SKLearn estimator, executing it may take some time as it has to download the scikit-learn container to the local docker environment. You will get the container logs in the output when the container completes the execution. The logs show that the container has successfully run the training script, and the `hello` message is also printed. But there is a lot more information available in the logs. So in the coming section, we will discuss that.\n",
    "\n",
    "![sklearn-output-1](images/2022-07-07-sagemaker-script-mode/sklearn-output-1.png)\n",
    "\n",
    "# Understanding SKLearn container output and environment varaibles\n",
    "From the SKLearn estimator output, we can see that our `train_and_server.py` script is executed by the container with the following command.\n",
    "\n",
    "```\n",
    "/miniconda3/bin/python train_and_server.py\n",
    "```\n",
    "\n",
    "## Inspecting SageMaker SKLearn docker image\n",
    "Since the container was executed in the local environment, we can also inspect the SageMaker SKLearn local image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                            TAG             IMAGE ID       CREATED       SIZE\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn   1.0-1-cpu-py3   ff85d0034e62   5 weeks ago   3.63GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the docker image. Notice the multiple container environment variables and their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Id\": \"sha256:ff85d0034e624cce6f1114c32807437e2d5fd13b3593caeadb736db13bc7e2a8\",\n",
      "        \"RepoTags\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3\"\n",
      "        ],\n",
      "        \"RepoDigests\": [\n",
      "            \"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:2ec1580756e6135455bcbcdff996c87bac72a0c8aa3bd924ff79372bd294f37a\"\n",
      "        ],\n",
      "        \"Parent\": \"\",\n",
      "        \"Comment\": \"\",\n",
      "        \"Created\": \"2022-06-02T23:29:51.803646532Z\",\n",
      "        \"Container\": \"24e79034ec0d3a22e1ef5059f99c18e3a496fd49beb41206560f5018de6f07f2\",\n",
      "        \"ContainerConfig\": {\n",
      "            \"Hostname\": \"24e79034ec0d\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"/bin/sh\",\n",
      "                \"-c\",\n",
      "                \"#(nop) \",\n",
      "                \"LABEL transform_id=ad0946aa-4ca2-49f8-9952-dfd9be087cb0_sagemaker-scikit-learn-1_0\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:86938f6074c305d134f2bcdc30467bf73711ff8181f632c8044ab06ec3360984\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6083519883\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"ad0946aa-4ca2-49f8-9952-dfd9be087cb0_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"DockerVersion\": \"20.10.11\",\n",
      "        \"Author\": \"\",\n",
      "        \"Config\": {\n",
      "            \"Hostname\": \"\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8080/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": false,\n",
      "            \"OpenStdin\": false,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"PATH=/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PYTHONIOENCODING=UTF-8\",\n",
      "                \"LANG=C.UTF-8\",\n",
      "                \"LC_ALL=C.UTF-8\",\n",
      "                \"SAGEMAKER_SKLEARN_VERSION=1.0-1\",\n",
      "                \"SAGEMAKER_TRAINING_MODULE=sagemaker_sklearn_container.training:main\",\n",
      "                \"SAGEMAKER_SERVING_MODULE=sagemaker_sklearn_container.serving:main\",\n",
      "                \"SKLEARN_MMS_CONFIG=/home/model-server/config.properties\",\n",
      "                \"SM_INPUT=/opt/ml/input\",\n",
      "                \"SM_INPUT_TRAINING_CONFIG_FILE=/opt/ml/input/config/hyperparameters.json\",\n",
      "                \"SM_INPUT_DATA_CONFIG_FILE=/opt/ml/input/config/inputdataconfig.json\",\n",
      "                \"SM_CHECKPOINT_CONFIG_FILE=/opt/ml/input/config/checkpointconfig.json\",\n",
      "                \"SM_MODEL_DIR=/opt/ml/model\",\n",
      "                \"TEMP=/home/model-server/tmp\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"bash\"\n",
      "            ],\n",
      "            \"Image\": \"sha256:86938f6074c305d134f2bcdc30467bf73711ff8181f632c8044ab06ec3360984\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": null,\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"TRANSFORM_TYPE\": \"Aggregate-1.0\",\n",
      "                \"VERSION_SET_NAME\": \"SMFrameworksSKLearn/release-cdk\",\n",
      "                \"VERSION_SET_REVISION\": \"6083519883\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.accept-bind-to-port\": \"true\",\n",
      "                \"com.amazonaws.sagemaker.capabilities.multi-models\": \"true\",\n",
      "                \"transform_id\": \"ad0946aa-4ca2-49f8-9952-dfd9be087cb0_sagemaker-scikit-learn-1_0\"\n",
      "            }\n",
      "        },\n",
      "        \"Architecture\": \"amd64\",\n",
      "        \"Os\": \"linux\",\n",
      "        \"Size\": 3633153014,\n",
      "        \"VirtualSize\": 3633153014,\n",
      "        \"GraphDriver\": {\n",
      "            \"Data\": {\n",
      "                \"LowerDir\": \"/var/lib/docker/overlay2/ba43580e98522f6446e7e8c598a703e1b9d4402d348c882895a7b5b95a1566d6/diff:/var/lib/docker/overlay2/50a931ea97e482a3df2865dc9febfe9d66ce4a3eb13276ff4b98b8eca23f0c54/diff:/var/lib/docker/overlay2/4ee2abdd56b16502e59ba13afa7cd3c1e9d2f4a2a4dfca4f5d0f0a6c9c992c6f/diff:/var/lib/docker/overlay2/47c80d1ead4706a27636fbe20f358c87b4de2f1a9a7a37300db47d3dae28a487/diff:/var/lib/docker/overlay2/f2a6b5574fc15a12921526014d7a4162691adb93ab3bd9dada1cc64bd352f81f/diff:/var/lib/docker/overlay2/2b5977d59718be93248994ef216602a0665ac61956c835e1e79fda45424d7801/diff:/var/lib/docker/overlay2/e7fc0748fe6f1156af1aec9b26c43b77257e16bea097d57ff405e6c0de11f731/diff:/var/lib/docker/overlay2/a5d42940ebdef95c956d614d52ffd44a7d43a62744374f0eb83ff1d75f98637a/diff:/var/lib/docker/overlay2/b06cdff43faa546dec30bf1a44096d15336fd4efb5bd3c828a1c455784873578/diff:/var/lib/docker/overlay2/b5800ba058ba5bf79b5a434377d782132d625d8e7f082c60e46b0fdf9c709e36/diff:/var/lib/docker/overlay2/065338b19925092d20aaea802e5929e2c6bdfd0fdad08d170b74d49d7297b73d/diff:/var/lib/docker/overlay2/d8278fb7a7defdff2d4d6e9189ef46fd602d582c992e8faf6c405da50d35f583/diff:/var/lib/docker/overlay2/297d0dff1a65d2e6f8b3b9a2a8b61cb6003ee92e02c40cfb8cb41c41ffc5f656/diff:/var/lib/docker/overlay2/8f725a2f19d2d702ee0e14d9fef108f0898da19dc8f73102d6ee2df2f067ebcb/diff:/var/lib/docker/overlay2/836f3bf3e998ac88ba6aa93837e46c179e9165a2df5033f883a087d1e84472e8/diff:/var/lib/docker/overlay2/f6d6f1c038697949b761b6b9aca3b162cde671fc8be8a7dec3aacd93ee2b2a24/diff:/var/lib/docker/overlay2/99b502c354d5e45d665721d12e6769aab2569abc1f83f40d4c10c4f29ba83f93/diff\",\n",
      "                \"MergedDir\": \"/var/lib/docker/overlay2/170b58f4a0e77fccd1ab733da2ab790b94ce89b949e89d22c7c5c9abb81302de/merged\",\n",
      "                \"UpperDir\": \"/var/lib/docker/overlay2/170b58f4a0e77fccd1ab733da2ab790b94ce89b949e89d22c7c5c9abb81302de/diff\",\n",
      "                \"WorkDir\": \"/var/lib/docker/overlay2/170b58f4a0e77fccd1ab733da2ab790b94ce89b949e89d22c7c5c9abb81302de/work\"\n",
      "            },\n",
      "            \"Name\": \"overlay2\"\n",
      "        },\n",
      "        \"RootFS\": {\n",
      "            \"Type\": \"layers\",\n",
      "            \"Layers\": [\n",
      "                \"sha256:1dc52a6b4de8561423dd3ec5a1f7f77f5309fd8cb340f80b8bc3d87fa112003e\",\n",
      "                \"sha256:99ca1a32584a06316ff1b48bb8ce664807566aa3017ef4b3dad53fd712f89de6\",\n",
      "                \"sha256:ed3fdfb46cd962aa39f6fb6c48e17f759f264cf338e153c5d4199f3bd3481bd0\",\n",
      "                \"sha256:787a104db1820509b4b8d20746d0b9df387498c8138a412ffc8fa698199118d8\",\n",
      "                \"sha256:68b766b62ca39331143f1d19dcaca6ebae2eebc1200fff1990a7ca47743be384\",\n",
      "                \"sha256:218bd4cc4fbdb5e30c78992d909cd556a4625d32a928970a697cc9e89d71846b\",\n",
      "                \"sha256:6ce2a9fe1d6ba9f9b9b4116b4ea8be89ffc2e7a14b9a886cce3534c83d69a313\",\n",
      "                \"sha256:68f522e62b787a7af4210caa9f1c16f9324cf94920c0e9a47eecd6baf744c123\",\n",
      "                \"sha256:9ddd41c83df357d4ac64043bcd27e338cb46047fef7e5c336fce8c7e603409a2\",\n",
      "                \"sha256:817e3a683251861369a12cb28add2f92104d34ed9e38e82213a1885815fe424f\",\n",
      "                \"sha256:d743afac96f62a3135874ee777eadf51cf5380a5c8017f60ab59123cd0e7e34e\",\n",
      "                \"sha256:b30a1fd61124bc41cb6431d6e228d0f7ba93e491777dd5b6b329de9b0e2677d7\",\n",
      "                \"sha256:99eb2741d927b6b109cd56edeb0787fb50b4df98d2fd39e3bd14edd25cbe5cfe\",\n",
      "                \"sha256:748916b673b3a238c9302c6146d0808e9116e6ae80a6a80b45dca8cf5a69d736\",\n",
      "                \"sha256:77fabbe5cc9110fa755db3ff256b41296ce839b2a49a37588bf7821a2e9667f6\",\n",
      "                \"sha256:33436664608d4569966290856ed7ecb5c4217717d22567db57435805e0798b3b\",\n",
      "                \"sha256:60a7b116599276fc04f16e84359319dacf4854e559c1a89d2688f6c384e9b3ce\",\n",
      "                \"sha256:82debf3a36033f35f4cb85c295a187ca0d84d47a3c4e01e4806ff8def7d25276\"\n",
      "            ]\n",
      "        },\n",
      "        \"Metadata\": {\n",
      "            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "!docker inspect ff85d0034e62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass hyperparameters to SKLearn estimator\n",
    "\n",
    "Let's pass some dummy hyperparameters to the estimator and see how it affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vatky0ulv7-algo-1-79qnt ... \n",
      "Creating vatky0ulv7-algo-1-79qnt ... done\n",
      "Attaching to vatky0ulv7-algo-1-79qnt\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:50,867 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:50,871 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:50,880 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:51,053 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:51,067 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:51,083 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:51,092 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m Training Env:\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m {\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"current_host\": \"algo-1-79qnt\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m         \"algo-1-79qnt\"\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     ],\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     },\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-05-48-675\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"master_hostname\": \"algo-1-79qnt\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m         \"current_host\": \"algo-1-79qnt\",\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m             \"algo-1-79qnt\"\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m         ]\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     },\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m }\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m Environment variables:\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_HOSTS=[\"algo-1-79qnt\"]\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-79qnt\",\"hosts\":[\"algo-1-79qnt\"]}\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_CURRENT_HOST=algo-1-79qnt\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-79qnt\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-79qnt\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-05-48-675\",\"log_level\":20,\"master_hostname\":\"algo-1-79qnt\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-79qnt\",\"hosts\":[\"algo-1-79qnt\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m \n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m *** Hello from the SageMaker script mode***\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt |\u001b[0m 2022-07-13 13:05:51,121 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mvatky0ulv7-algo-1-79qnt exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn-output-hyperparams](images/2022-07-07-sagemaker-script-mode/sklearn-output-hyperparams.png)\n",
    "\n",
    "From the output we can see that our hyperparameters were passed to our training script as command line arguments. This is an important point and we will update our script using this information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker SKLearn container environment variables\n",
    "Let's now discuss the essential environment variables we see in the output.\n",
    "\n",
    "### SM_MODULE_DIR\n",
    "```\n",
    "SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-48-675/source/sourcedir.tar.gz\n",
    "```\n",
    "`SM_MODULE_DIR` points to a location in the S3 bucket where SageMaker will automatically backup our source code for that particular run. SageMaker will create a separate folder in the default bucket for each new run. The default value is `s3://sagemaker-{aws-region}-{aws-id}/{training-job-name}/source/sourcedir.tar.gz`\n",
    "\n",
    "### SM_MODEL_DIR\n",
    "```\n",
    "SM_MODEL_DIR=/opt/ml/model\n",
    "```\n",
    "`SM_MODEL_DIR` points to a directory located inside the container. When the training job finishes, the container and its file system will be deleted, except for the `/opt/ml/model` and `/opt/ml/output` directories. Use `/opt/ml/model` to save the trained model artifacts. These artifacts are uploaded to S3 for model hosting.\n",
    "\n",
    "### SM_OUTPUT_DATA_DIR\n",
    "```\n",
    "SM_OUTPUT_DIR=/opt/ml/output\n",
    "```\n",
    "`SM_OUTPUT_DIR` points to a directory in the container to write output artifacts. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "### SM_CHANNELS\n",
    "From the SKLearn estimator output\n",
    "```\n",
    "SM_CHANNELS='[\"testing\",\"training\"]'\n",
    "```\n",
    "A channel is a named input source that training algorithms can consume. You can partition your training data into different logical \"channels\" when you run training. Depending on your problem, some common channel ideas are: \"training\", \"testing\", \"evaluation\" or \"images\" and \"labels\". You can read more about the channels from SageMaker API reference [Channel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Channel.html)\n",
    "\n",
    "### SM_CHANNEL_{channel_name}\n",
    "```\n",
    "SM_CHANNEL_TRAIN='/opt/ml/input/data/train'\n",
    "SM_CHANNEL_TEST='/opt/ml/input/data/test'\n",
    "```\n",
    "Supposing that you have passed two input channels, 'train' and 'test', to the Scikit-learn estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "* **`SM_CHANNEL_TRAIN`**: it points to the directory in the container that has the *train* channel data downloaded\n",
    "* **`SM_CHANNEL_TEST`**: Same as above, but for the *test* channel\n",
    "\n",
    "Note that the channel names `train` and `test` are the conventions. Still, you can use any name here, and the environment variables will be created accordingly. It is important to know that the SageMaker container automatically downloads the data from the provided input channels and makes them available in the respective local directories once it starts executing. The training script can then load the data from the local container directories.\n",
    "\n",
    "There are more environment variables available, and you can read about them from [Environment variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass input channel to SKLearn estimator\n",
    "\n",
    "Now that we understand the SKLearn container environment more let's pass the training data channel to the estimator and see if the data becomes available inside the container directory. \n",
    "\n",
    "Update our script to list all the files in the `SM_CHANNEL_TRAIN` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "\n",
    "    print(\"training_dir files list: \", dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ajvs4neawf-algo-1-vcoo5 ... \n",
      "Creating ajvs4neawf-algo-1-vcoo5 ... done\n",
      "Attaching to ajvs4neawf-algo-1-vcoo5\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:53,961 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:53,966 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:53,975 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:54,165 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:54,179 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:54,193 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:54,202 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m Training Env:\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m {\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     },\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"current_host\": \"algo-1-vcoo5\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"algo-1-vcoo5\"\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     ],\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     },\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"train\": {\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         }\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     },\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-05-51-514\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"master_hostname\": \"algo-1-vcoo5\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-51-514/source/sourcedir.tar.gz\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"current_host\": \"algo-1-vcoo5\",\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m             \"algo-1-vcoo5\"\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m         ]\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     },\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m }\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m Environment variables:\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_HOSTS=[\"algo-1-vcoo5\"]\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-vcoo5\",\"hosts\":[\"algo-1-vcoo5\"]}\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_CURRENT_HOST=algo-1-vcoo5\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-51-514/source/sourcedir.tar.gz\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-vcoo5\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-vcoo5\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-05-51-514\",\"log_level\":20,\"master_hostname\":\"algo-1-vcoo5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-51-514/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-vcoo5\",\"hosts\":[\"algo-1-vcoo5\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m training_dir files list:  ['train.csv', '.ipynb_checkpoints']\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 |\u001b[0m 2022-07-13 13:05:54,246 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36majvs4neawf-algo-1-vcoo5 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": f\"file://{local_train_path}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[image here]**\n",
    "From the output, we can see that `train.csv`, which was in our local environment, is now available inside the container on path `SM_CHANNEL_TRAIN=/opt/ml/input/data/train`. \n",
    "\n",
    "Let's also test the same with our training data on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ej721wg4x0-algo-1-4b1nb ... \n",
      "Creating ej721wg4x0-algo-1-4b1nb ... done\n",
      "Attaching to ej721wg4x0-algo-1-4b1nb\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:56,826 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:56,833 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:56,842 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:57,027 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:57,041 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:57,054 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:57,063 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m Training Env:\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m {\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     },\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"current_host\": \"algo-1-4b1nb\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"algo-1-4b1nb\"\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     ],\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     },\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"train\": {\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         }\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     },\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-05-54-602\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"master_hostname\": \"algo-1-4b1nb\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-54-602/source/sourcedir.tar.gz\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"current_host\": \"algo-1-4b1nb\",\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m             \"algo-1-4b1nb\"\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m         ]\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     },\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m }\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m Environment variables:\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_HOSTS=[\"algo-1-4b1nb\"]\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-4b1nb\",\"hosts\":[\"algo-1-4b1nb\"]}\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_CURRENT_HOST=algo-1-4b1nb\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-54-602/source/sourcedir.tar.gz\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-4b1nb\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-4b1nb\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-05-54-602\",\"log_level\":20,\"master_hostname\":\"algo-1-4b1nb\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-54-602/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-4b1nb\",\"hosts\":[\"algo-1-4b1nb\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb |\u001b[0m 2022-07-13 13:05:57,104 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mej721wg4x0-algo-1-4b1nb exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the results are the same. SageMaker will download the data from the S3 bucket and make it available in the container. In the environment variables section we also learned that two directories are special `/opt/ml/model` and `/opt/ml/output`. Container environment variables `SM_MODEL_DIR` and `SM_OUTPUT_DATA_DIR` point to them, respectively. Whatever artifacts we put on them will be stored on the S3 bucket when the training job finishes. \"SM_MODEL_DIR\" is for trained models, and \"SM_OUTPUT_DATA_DIR\" is for other artifacts like logs, graphs, plots, resutls, etc. Let's update our training script and put some dummy data in these directories. Once the job is complete, we will verify the stored artifacts on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import argparse, os, sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" *** Hello from SageMaker script container *** \")\n",
    "\n",
    "    # list files in SM_CHANNEL_TRAIN\n",
    "    training_dir = os.environ.get(\"SM_CHANNEL_TRAIN\")\n",
    "    dir_list = os.listdir(training_dir)\n",
    "    print(\"training_dir files list: \", dir_list)\n",
    "\n",
    "    # write dummy model file to SM_MODEL_DIR\n",
    "    sm_model_dir = os.environ.get(\"SM_MODEL_DIR\")\n",
    "    with open(f\"{sm_model_dir}/dummy-model.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy model\")\n",
    "\n",
    "    # write dummy artifact file to SM_OUTPUT_DATA_DIR\n",
    "    sm_output_data_dir = os.environ.get(\"SM_OUTPUT_DATA_DIR\")\n",
    "    with open(f\"{sm_output_data_dir}/dummy-output-data.txt\", \"w\") as f:\n",
    "        f.write(\"this is a dummy output data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 7kxyzpqlld-algo-1-w41kb ... \n",
      "Creating 7kxyzpqlld-algo-1-w41kb ... done\n",
      "Attaching to 7kxyzpqlld-algo-1-w41kb\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:05:59,899 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:05:59,903 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:05:59,913 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:06:00,115 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:06:00,129 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:06:00,142 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:06:00,151 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m Training Env:\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m {\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     },\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"current_host\": \"algo-1-w41kb\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"algo-1-w41kb\"\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     ],\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"dummy_param_1\": \"val1\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"dummy_param_2\": \"val2\"\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     },\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"train\": {\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         }\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     },\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-05-57-790\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"master_hostname\": \"algo-1-w41kb\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/source/sourcedir.tar.gz\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"current_host\": \"algo-1-w41kb\",\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m             \"algo-1-w41kb\"\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m         ]\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     },\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m }\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m Environment variables:\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_HOSTS=[\"algo-1-w41kb\"]\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_HPS={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"}\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-w41kb\",\"hosts\":[\"algo-1-w41kb\"]}\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_CURRENT_HOST=algo-1-w41kb\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/source/sourcedir.tar.gz\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-w41kb\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-w41kb\"],\"hyperparameters\":{\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-05-57-790\",\"log_level\":20,\"master_hostname\":\"algo-1-w41kb\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-w41kb\",\"hosts\":[\"algo-1-w41kb\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_USER_ARGS=[\"--dummy_param_1\",\"val1\",\"--dummy_param_2\",\"val2\"]\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_HP_DUMMY_PARAM_1=val1\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m SM_HP_DUMMY_PARAM_2=val2\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m /miniconda3/bin/python train_and_serve.py --dummy_param_1 val1 --dummy_param_2 val2\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m  *** Hello from SageMaker script container *** \n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m training_dir files list:  ['train.csv']\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb |\u001b[0m 2022-07-13 13:06:00,192 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m7kxyzpqlld-algo-1-w41kb exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmpgsc_yr3n/algo-1-w41kb Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#collapse-output\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"dummy_param_1\":\"val1\",\"dummy_param_2\":\"val2\"},\n",
    ")\n",
    "\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training job is now complete. Let us check the S3 bucket to see if our dummy model and other artifacts are present.\n",
    "\n",
    "First, we need the S3 URI for these artifacts. For our dummy model (from SM_MODEL_DIR), we can use our estimator object to get the URI. Let's call it `model_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/model.tar.gz'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = sk_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_data` from S3 will be downloaded to a local directory for verification. Let's create a local `tmp` to store these downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/model'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_tmp_path = local_path + \"/tmp\"\n",
    "print(local_tmp_path)\n",
    "\n",
    "# create the local '/tmp' directory\n",
    "Path(local_tmp_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SageMaker `S3Downloader` object to download the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "S3Downloader.download(\n",
    "    s3_uri=model_data, local_path=local_tmp_path, sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File is downloaded. Let's uncompress it to verify the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy-model.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_model_path/model.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the \"dummy-model.txt\" file is present. This tells us that SageMaker will automatically upload the files from the model directory (SM_MODEL_DIR) to the S3 bucket. Let's do the same for the output data directory (SM_OUTPUT_DATA_DIR). There is no direct way to get the S3 URI from the estimator object for the output data directory. But we can prepare it ourselves. So let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"estimator.output_path: \", estimator.output_path)\n",
    "print(\"estimator.latest_training_job.name: \", estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_s3_output_uri(estimator):\n",
    "    return estimator.output_path + estimator.latest_training_job.name\n",
    "    \n",
    "get_s3_output_uri(sk_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/output.tar.gz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for output data artifacts\n",
    "s3_output_uri = get_s3_output_uri(sk_estimator) + '/output.tar.gz'\n",
    "s3_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/model.tar.gz'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "# S3 URI for model artifact. We have already veirifed it.\n",
    "s3_model_uri = get_s3_output_uri(sk_estimator) + '/model.tar.gz'\n",
    "s3_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-05-57-790/source/sourcedir.tar.gz'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# S3 URI for source code\n",
    "s3_source_uri  get_s3_output_uri(sk_estimator) + '/source/sourcedir.tar.gz'\n",
    "s3_source_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download these artifacts to our local '/tmp' directory for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $s3_output_uri $local_tmp_path\n",
    "!aws s3 cp $s3_source_uri $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# extract the output data files from 'output.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/output.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# extract the source code files from 'sourcedir.tar.gz'\n",
    "!tar -xzvf $local_tmp_path/sourcedir.tar.gz -C $local_tmp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary till now\n",
    "Let's summarize what we have learned till now.\n",
    "* We can use SageMaker SKLearn local mode to test our code in a local environment\n",
    "* SKLearn container executes our provided script with the command `/miniconda3/bin/python train_and_server.py`\n",
    "* Hyperparameters passed to the container are passed to our script as command line arguments\n",
    "* Data from input channels will be downloaded by the container and made available for our script to load and process\n",
    "* '/opt/ml/model' and '/opt/ml/output' directories are special. Anything stored on them will be automatically backed up on the S3 bucket when the job finishes. These directories are defined in the container environment variables 'SM_MODEL_DIR' and 'SM_OUTPUT_DATA_DIR', respectively. SM_MODEL_DIR should be used to write model artifacts. SM_OUTPUT_DATA_DIR should be used to write any other supporting artifact.\n",
    "\n",
    "Let's use this knowledge to update our script to train a RandomForrestClassifier on the Iris flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup /tmp directory\n",
    "!rm -r $local_tmp_path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"command line arguments: \", args)\n",
    "    \n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "    \n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    print(f\"testing_dir: {testing_dir}\") # print testing_dir path\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\") # print testing_dir files list\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    \n",
    "    \n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "    \n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir+\"/model.joblib\")\n",
    "    \n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir+\"/y_pred.csv\")\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x $script_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean model output directory\n",
    "!rm -r $local_model_path/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command line arguments:  Namespace(estimators=10, sm_channel_test='./datasets/2022-07-07-sagemaker-script-mode/test', sm_channel_train='./datasets/2022-07-07-sagemaker-script-mode/train', sm_model_dir='./datasets/2022-07-07-sagemaker-script-mode/model', sm_output_data_dir='./datasets/2022-07-07-sagemaker-script-mode/output/data')\n",
      "training_dir: ./datasets/2022-07-07-sagemaker-script-mode/train\n",
      "training_dir files list: ['train.csv', '.ipynb_checkpoints']\n",
      "testing_dir: ./datasets/2022-07-07-sagemaker-script-mode/test\n",
      "testing_dir files list: ['.ipynb_checkpoints', 'test.csv']\n",
      "sm_model_dir: ./datasets/2022-07-07-sagemaker-script-mode/model\n",
      "output_data_dir: ./datasets/2022-07-07-sagemaker-script-mode/output/data\n",
      "X_train.shape: (120, 4)\n",
      "y_train.shape: (120,)\n",
      "X_train.shape: (30, 4)\n",
      "y_train.shape: (30,)\n",
      "sm_model_dir: ./datasets/2022-07-07-sagemaker-script-mode/model\n",
      "sm_model_dir files list: ['.ipynb_checkpoints', 'model.joblib']\n"
     ]
    }
   ],
   "source": [
    "!python3 $script_file \\\n",
    "    --sm-model-dir $local_model_path \\\n",
    "    --sm-channel-train $local_train_path \\\n",
    "    --sm-channel-test $local_test_path \\\n",
    "    --sm-output-data-dir $local_output_data_path \\\n",
    "    --estimators 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/model'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have tested our script locally. so let's test this with SageMaker SKlean container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0b3yb3qvjt-algo-1-n90bz ... \n",
      "Creating 0b3yb3qvjt-algo-1-n90bz ... done\n",
      "Attaching to 0b3yb3qvjt-algo-1-n90bz\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,304 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,308 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,317 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,498 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,512 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,525 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:06,534 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m Training Env:\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"current_host\": \"algo-1-n90bz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"algo-1-n90bz\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     ],\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"train\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"test\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         }\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-06-03-671\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"master_hostname\": \"algo-1-n90bz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/source/sourcedir.tar.gz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"current_host\": \"algo-1-n90bz\",\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m             \"algo-1-n90bz\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m         ]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     },\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m }\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m Environment variables:\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_HOSTS=[\"algo-1-n90bz\"]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-n90bz\",\"hosts\":[\"algo-1-n90bz\"]}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CURRENT_HOST=algo-1-n90bz\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/source/sourcedir.tar.gz\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-n90bz\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-n90bz\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-06-03-671\",\"log_level\":20,\"master_hostname\":\"algo-1-n90bz\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-n90bz\",\"hosts\":[\"algo-1-n90bz\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m \n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz |\u001b[0m 2022-07-13 13:06:07,727 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m0b3yb3qvjt-algo-1-n90bz exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp5kv1g_u7/algo-1-n90bz Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/model.tar.gz'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/output.tar.gz'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_uri = get_s3_output_uri(sk_estimator) + '/output.tar.gz'\n",
    "s3_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/output/data'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/2022-07-07-sagemaker-script-mode/output/data\n"
     ]
    }
   ],
   "source": [
    "print(local_output_data_path)\n",
    "\n",
    "!rm -r $local_output_data_path/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-06-03-671/output.tar.gz to datasets/2022-07-07-sagemaker-script-mode/output/data/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $s3_output_uri $local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/y_pred.csv\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_output_data_path/output.tar.gz -C $local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### requirements and custom_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task we need to generate confusion matrix using seaborn library and store it in output data driectory\n",
    "# create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom library to save a seaborn CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_library_path: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library\n",
      "custom_library_file: ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "custom_library_path = local_path+\"/my_custom_library\"\n",
    "custom_library_file = custom_library_path+\"/seaborn_confusion_matrix.py\"\n",
    "\n",
    "print(f\"custom_library_path: {custom_library_path}\")\n",
    "print(f\"custom_library_file: {custom_library_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom library folder\n",
    "Path(custom_library_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/seaborn_confusion_matrix.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import argparse, os\n",
    "\n",
    "def save_confusion_matrix(cf_matrix, path=\"./\"):\n",
    "    sns_plot = sns.heatmap(cf_matrix, annot=True)\n",
    "    sns_plot.figure.savefig(path+\"/output_cm.png\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--path\", type=str, default=\"./\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    path = args.path\n",
    "    \n",
    "    dummy_cm = np.array([[23,  5],[ 3, 30]])\n",
    "    save_confusion_matrix(dummy_cm, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/my_custom_library/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $custom_library_path/__init__.py\n",
    "\n",
    "from .seaborn_confusion_matrix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $custom_library_file --path $local_output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/train_and_serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from my_custom_library import save_confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--sm-channel-train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--sm-channel-test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--sm-output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"command line arguments: \", args)\n",
    "    \n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.sm_channel_train\n",
    "    testing_dir = args.sm_channel_test\n",
    "    output_data_dir = args.sm_output_data_dir\n",
    "    \n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    print(f\"testing_dir: {testing_dir}\") # print testing_dir path\n",
    "    print(f\"testing_dir files list: {os.listdir(testing_dir)}\") # print testing_dir files list\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\")\n",
    "    print(f\"output_data_dir: {output_data_dir}\")\n",
    "    \n",
    "    \n",
    "    # Read in data\n",
    "    df_train = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "    df_test = pd.read_csv(testing_dir + \"/test.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train = df_train.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_train = df_train[\"class_cat\"]\n",
    "    X_test = df_test.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y_test = df_test[\"class_cat\"]\n",
    "    \n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"y_train.shape: {y_train.shape}\")\n",
    "    print(f\"X_train.shape: {X_test.shape}\")\n",
    "    print(f\"y_train.shape: {y_test.shape}\")\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestClassifier(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(regressor, sm_model_dir+\"/model.joblib\")\n",
    "    \n",
    "    # Save the results\n",
    "    pd.DataFrame(y_pred).to_csv(output_data_dir+\"/y_pred.csv\")\n",
    "    \n",
    "    # save the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    save_confusion_matrix(cf_matrix, output_data_dir)\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "    \n",
    "    # print output_data_dir info\n",
    "    print(f\"output_data_dir: {output_data_dir}\") # print sm_model_dir path\n",
    "    print(f\"output_data_dir files list: {os.listdir(output_data_dir)}\") # print sm_model_dir files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/2022-07-07-sagemaker-script-mode/src'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./datasets/2022-07-07-sagemaker-script-mode/src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path/requirements.txt\n",
    "\n",
    "matplotlib==3.5.2\n",
    "seaborn==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 96mwnip853-algo-1-gcn8f ... \n",
      "Creating 96mwnip853-algo-1-gcn8f ... done\n",
      "Attaching to 96mwnip853-algo-1-gcn8f\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,389 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,393 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,403 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:46,574 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Collecting matplotlib==3.5.2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting seaborn==0.11.2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting pyparsing>=2.2.1\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (9.1.1)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Collecting cycler>=0.10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: numpy>=1.17 in /miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (1.21.0)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Collecting packaging>=20.0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m   Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[?25hRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 3)) (1.5.3)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.8/site-packages (from seaborn==0.11.2->-r requirements.txt (line 3)) (1.1.3)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.2->-r requirements.txt (line 3)) (2022.1)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Requirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.5.2->-r requirements.txt (line 2)) (1.15.0)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, packaging, matplotlib, seaborn\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.3 matplotlib-3.5.2 packaging-21.3 pyparsing-3.0.9 seaborn-0.11.2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \u001b[0m2022-07-13 13:07:51,183 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:51,197 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:51,210 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:51,219 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Training Env:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"current_host\": \"algo-1-gcn8f\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"algo-1-gcn8f\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     ],\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"estimators\": 10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"train\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"test\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         }\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2022-07-13-13-07-43-761\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"master_hostname\": \"algo-1-gcn8f\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-07-43-761/source/sourcedir.tar.gz\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"module_name\": \"train_and_serve\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"current_host\": \"algo-1-gcn8f\",\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m             \"algo-1-gcn8f\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m         ]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     },\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m     \"user_entry_point\": \"train_and_serve.py\"\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m }\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Environment variables:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_HOSTS=[\"algo-1-gcn8f\"]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_HPS={\"estimators\":10}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_USER_ENTRY_POINT=train_and_serve.py\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-gcn8f\",\"hosts\":[\"algo-1-gcn8f\"]}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CURRENT_HOST=algo-1-gcn8f\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_MODULE_NAME=train_and_serve\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-07-43-761/source/sourcedir.tar.gz\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-gcn8f\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-gcn8f\"],\"hyperparameters\":{\"estimators\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2022-07-13-13-07-43-761\",\"log_level\":20,\"master_hostname\":\"algo-1-gcn8f\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-801598032724/sagemaker-scikit-learn-2022-07-13-13-07-43-761/source/sourcedir.tar.gz\",\"module_name\":\"train_and_serve\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-gcn8f\",\"hosts\":[\"algo-1-gcn8f\"]},\"user_entry_point\":\"train_and_serve.py\"}\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_USER_ARGS=[\"--estimators\",\"10\"]\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m SM_HP_ESTIMATORS=10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m /miniconda3/bin/python train_and_serve.py --estimators 10\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m \n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m command line arguments:  Namespace(estimators=10, sm_channel_test='/opt/ml/input/data/test', sm_channel_train='/opt/ml/input/data/train', sm_model_dir='/opt/ml/model', sm_output_data_dir='/opt/ml/output/data')\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m training_dir: /opt/ml/input/data/train\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m training_dir files list: ['train.csv']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m testing_dir: /opt/ml/input/data/test\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m testing_dir files list: ['test.csv']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m X_train.shape: (120, 4)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m y_train.shape: (120,)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m X_train.shape: (30, 4)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m y_train.shape: (30,)\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m sm_model_dir: /opt/ml/model\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m sm_model_dir files list: ['model.joblib']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m output_data_dir: /opt/ml/output/data\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m output_data_dir files list: ['y_pred.csv', 'output_cm.png']\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f |\u001b[0m 2022-07-13 13:07:53,296 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m96mwnip853-algo-1-gcn8f exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to delete: /tmp/tmp58lfmx49/algo-1-gcn8f Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file_name,\n",
    "    source_dir=script_path,\n",
    "    dependencies=[custom_library_path],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri, \"test\": s3_test_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a trained model. Can we deploy this model already?\n",
    "\n",
    "If I try to deploy this model using command\n",
    "```\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")\n",
    "```\n",
    "i will get exception messages \n",
    "```\n",
    "[2022-07-09 06:15:45 +0000] [31] [ERROR] Error handling request /ping\n",
    "Traceback (most recent call last):\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
    "    return fn(*args, **kwargs)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/serving.py\", line 43, in default_model_fn\n",
    "    return transformer.default_model_fn(model_dir)\n",
    "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_transformer.py\", line 35, in default_model_fn\n",
    "    raise NotImplementedError(\n",
    "NotImplementedError: \n",
    "Please provide a model_fn implementation.\n",
    "See documentation for model_fn at https://github.com/aws/sagemaker-python-sdk\n",
    "```\n",
    "this is because Before a model can be served, it must be loaded. The SageMaker Scikit-learn model server loads your model by invoking a model_fn function that you must provide in your script. The model_fn should have the following signature:\n",
    "\n",
    "def model_fn(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.train\n",
    "    \n",
    "    # print training_dir info\n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X = df.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y = df[\"class_cat\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestRegressor(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(regressor, os.path.join(sm_model_dir, \"model.joblib\"))\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "\n",
    "    \n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [[9.0, 3571, 1976, 0.525]]\n",
    "\n",
    "response  = sk_predictor.predict(request)\n",
    "response = int(response[0])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted class category {} ({})\".format(response, categories_map[response]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "* if you are already running a local endpoint then you will not be able to create a new one. if you have lost the kernel session then you can delete the running endpoint from terminal using kill command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the inputs and outputs\n",
    "# input in json and output in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_file\n",
    "\n",
    "import argparse, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # do i need this?\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Pass in environment variables and hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters\n",
    "    parser.add_argument(\"--estimators\", type=int, default=15)\n",
    "\n",
    "    # sm_model_dir: model artifacts stored here after training\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    estimators = args.estimators\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir = args.train\n",
    "    \n",
    "    # print training_dir info\n",
    "    print(f\"training_dir: {training_dir}\") # print training_dir path\n",
    "    print(f\"training_dir files list: {os.listdir(training_dir)}\") # print training_dir files list\n",
    "    \n",
    "    # Read in data\n",
    "    df = pd.read_csv(training_dir + \"/train.csv\", sep=\",\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X = df.drop([\"class\", \"class_cat\"], axis=1)\n",
    "    y = df[\"class_cat\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Build model\n",
    "    regressor = RandomForestRegressor(n_estimators=estimators)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(regressor, os.path.join(sm_model_dir, \"model.joblib\"))\n",
    "    \n",
    "    # print sm_model_dir info\n",
    "    print(f\"sm_model_dir: {sm_model_dir}\") # print sm_model_dir path\n",
    "    print(f\"sm_model_dir files list: {os.listdir(sm_model_dir)}\") # print sm_model_dir files list\n",
    "\n",
    "    \n",
    "# Model serving\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    print(f\"model_fn model_dir: {model_dir}\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == \"application/json\":\n",
    "        request_body = json.loads(request_body)\n",
    "        inpVar = request_body[\"Input\"]\n",
    "        return inpVar\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {\"Output\": res}\n",
    "    return respJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_estimator = SKLearn(\n",
    "    entry_point=script_file,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    framework_version=\"1.0-1\",\n",
    "    hyperparameters={\"estimators\":10},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": s3_train_uri})\n",
    "\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_endpoint_name = sk_predictor.endpoint_name\n",
    "sk_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "client = session_local.sagemaker_runtime_client\n",
    "\n",
    "request_body = {\"Input\": [[9.0, 3571, 1976, 0.525]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=sk_endpoint_name, ContentType=\"application/json\", Body=payload\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())[\"Output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted class category {} ({})\".format(result, categories_map[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
