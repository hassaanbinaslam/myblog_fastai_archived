{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading SageMaker Linear Learner Model with Apache MXNet in Python\n",
    "> How to load SageMaker builtin Linear Learner model with Apache MXNet in Python.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [aws, ml, sagemaker]\n",
    "- keyword: [aws, ml, sagemaker, apache, mxnet, gluon]\n",
    "- image: images/copied_from_nb/images/2022-07-05-aws-linear-learner-apache-mxnet-python.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/2022-07-05-aws-linear-learner-apache-mxnet-python.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "You have trained a model with Amazon SageMaker's built-in algorithm [Linear Learner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html). You can test this model by deploying it on a SageMaker endpoint. But you want to test this model in your local environment. In this post, we will learn to use Apache MXNet and Gluon API to load the model in a local environment, extract its parameters, and perform predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdcution\n",
    "[Apache MXNet](https://mxnet.apache.org/) is a fully featured, flexibly programmable, and ultra-scalable deep learning framework supporting state of the art in deep learning models, including convolutional neural networks (CNNs) and long short-term memory networks (LSTMs). Amazon has selected MXNet as their deep learning framework of choice (see [Amazon CTO, Werner Vogels blog post on this](https://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html)). When you train a deep learning model using Amazon SageMaker builtin algorithm then there are high chances that the model has been trained and saved using MXNet framework. If a model has been saved with MXNet then we can use the same library to load that model in a local environment.\n",
    "\n",
    "In my last post [Demystifying Amazon SageMaker Training for scikit-learn Lovers](https://hassaanbinaslam.github.io/myblog/aws/ml/sagemaker/2022/06/08/sagemaker-training-overview.html), I used SageMaker builtin Linear Learner algorithm to train a model on Boston housing dataset. Once the training was complete the model artifacts were stored on the S3 bucket at the following location\n",
    "```\n",
    "s3://sagemaker-us-east-1-801598032724/2022-06-08-sagemaker-training-overview/output/linear-learner-2022-06-16-09-04-57-576/output/model.tar.gz\n",
    "```\n",
    "\n",
    "Note that Amazon Linear Learner is built using a Neural Network and is different from [scikit-learn linear regression algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Linear Learner documentation does not provide details on the architecture of this neural network but it does mention that it trains using a distributed implementation of stochastic gradient descent (SGD). We can also specify the hyperparameters such as momentum, learning rate, and the learning rate schedule. Also, note that not all SageMaker built-in models are using deep learning e.g. XGBoost which is based on regression trees. If you have trained xgboost model then to load this model in a local environment you will have to use xgboost library, and the MXNet library will not work for it.\n",
    "\n",
    "Since Linear Learner is based on deep learning, We can use MXNet Gluon API to load this model in our local environment and make some predictions.\n",
    "\n",
    "This post assumes that you have already trained a Linear Learner model and its artifacts are available on the S3 bucket. If you have not done so then you may use my [another post](https://hassaanbinaslam.github.io/myblog/aws/ml/sagemaker/2022/06/08/sagemaker-training-overview.html) to train a Linear Learner on the Boston housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "This notebook is prepared with Amazon SageMaker Studio using Python 3 (MXNet 1.9 Python 3.8 CPU Optimized) Kernel and ml.t3.medium instance.\n",
    "\n",
    "image here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.22.42 Python/3.8.10 Linux/4.14.281-212.502.amzn2.x86_64 botocore/1.23.42\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# AWS CLI version\n",
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Ubuntu\"\n",
      "VERSION=\"20.04.3 LTS (Focal Fossa)\"\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "PRETTY_NAME=\"Ubuntu 20.04.3 LTS\"\n",
      "VERSION_ID=\"20.04\"\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "VERSION_CODENAME=focal\n",
      "UBUNTU_CODENAME=focal\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# OS version\n",
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a SageMaker Linear Learner model with Apache MXNet in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize SageMaker API session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.__version__: 2.73.0\n",
      "Session: <sagemaker.session.Session object at 0x7f6b0500a760>\n",
      "Role: arn:aws:iam::801598032724:role/service-role/AmazonSageMaker-ExecutionRole-20220516T161743\n",
      "Bucket: sagemaker-us-east-1-801598032724\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "\n",
    "print(f\"sagemaker.__version__: {sagemaker.__version__}\")\n",
    "print(f\"Session: {session}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our trained model artifacts available on S3 bucket. Let's define that bucket path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = \"s3://sagemaker-us-east-1-801598032724/2022-06-08-sagemaker-training-overview/output/linear-learner-2022-06-16-09-04-57-576/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SageMaker SDK to download model artifacts from the S3 bucket to a local directory. Let's define the local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"datasets/2022-07-05-aws-linear-learner-apache-mxnet-python/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "S3Downloader.download(s3_uri=model_data,\n",
    "    local_path=local_path,\n",
    "sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, you will find an archive \"model.tar.gz\" in the local directory. Let's extract this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_algo-1\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf $local_path/model.tar.gz -C $local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting once will give us a zip file. Let's unzip it to get the model contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasets/2022-07-05-aws-linear-learner-apache-mxnet-python//model_algo-1\n",
      " extracting: datasets/2022-07-05-aws-linear-learner-apache-mxnet-python/additional-params.json  \n",
      " extracting: datasets/2022-07-05-aws-linear-learner-apache-mxnet-python/mx-mod-symbol.json  \n",
      " extracting: datasets/2022-07-05-aws-linear-learner-apache-mxnet-python/manifest.json  \n",
      " extracting: datasets/2022-07-05-aws-linear-learner-apache-mxnet-python/mx-mod-0000.params  \n"
     ]
    }
   ],
   "source": [
    "!unzip $local_path/model_algo-1 -d $local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted model has two important files.\n",
    "* `mx-mod-symbol.json` is the JSON file that defines the computational graph for the model\n",
    "* `mx-mod-0000.params` is a binary file that contains the parameters for the trained model\n",
    "\n",
    "Serializing models as JSON files has the benefit that these models can be loaded from other language bindings like C++ or Scala for faster inference or inference in different environments. You can read more about it here: [Saving and Loading Gluon Models](https://mxnet.apache.org/versions/1.9.1/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html). Let's load our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet\n",
    "import pprint\n",
    "\n",
    "from mxnet import gluon\n",
    "from json import load as json_load\n",
    "from json import dumps as json_dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gluon API is a wrapper around low level MXNet API to provide a simple interface for deep learning. You may read more about this API here: [mxnet.gluon](https://mxnet.apache.org/versions/1.6/api/python/docs/api/gluon/index.html)\n",
    "\n",
    "Let's read model computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_json = json_load(open(f\"{local_path}mx-mod-symbol.json\"))\n",
    "sym_json_string = json_dumps(sym_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arg_nodes': [0, 1, 3, 5],\n",
      " 'attrs': {'mxnet_version': ['int', 10301]},\n",
      " 'heads': [[6, 0, 0]],\n",
      " 'node_row_ptr': [0, 1, 2, 3, 4, 5, 6, 7],\n",
      " 'nodes': [{'inputs': [], 'name': 'data', 'op': 'null'},\n",
      "           {'attrs': {'__shape__': '(12, 1)'},\n",
      "            'inputs': [],\n",
      "            'name': 'fc0_weight',\n",
      "            'op': 'null'},\n",
      "           {'inputs': [[0, 0, 0], [1, 0, 0]], 'name': 'dot46', 'op': 'dot'},\n",
      "           {'attrs': {'__lr_mult__': '10.0', '__shape__': '(1, 1)'},\n",
      "            'inputs': [],\n",
      "            'name': 'fc0_bias',\n",
      "            'op': 'null'},\n",
      "           {'inputs': [[2, 0, 0], [3, 0, 0]],\n",
      "            'name': 'broadcast_plus46',\n",
      "            'op': 'broadcast_add'},\n",
      "           {'inputs': [], 'name': 'out_label', 'op': 'null'},\n",
      "           {'inputs': [[4, 0, 0], [5, 0, 0]],\n",
      "            'name': 'linearregressionoutput46',\n",
      "            'op': 'LinearRegressionOutput'}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(sym_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mxnet/gluon/block.py:1849: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# initialize the model graph\n",
    "\n",
    "model = gluon.nn.SymbolBlock(\n",
    "    outputs=mxnet.sym.load_json(sym_json_string),\n",
    "    inputs=mxnet.sym.var('data')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# load the model parameters\n",
    "\n",
    "model.load_parameters(\n",
    "    f'{local_path}mx-mod-0000.params',\n",
    "    allow_missing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mxnet/gluon/parameter.py:896: UserWarning: Parameter 'fc0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/usr/local/lib/python3.8/dist-packages/mxnet/gluon/parameter.py:896: UserWarning: Parameter 'fc0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# finally let's initialize our model\n",
    "\n",
    "model.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point our model is ready in our local environment, and we can use it to make some predictions.\n",
    "\n",
    "Let's prepare an input request. This request is same as used in the [model training blog post](https://hassaanbinaslam.github.io/myblog/aws/ml/sagemaker/2022/06/08/sagemaker-training-overview.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_request = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,4.98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert our request Python list to MXNet array to be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_request_nd = mxnet.nd.array(input_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(input_request): <class 'list'>\n",
      "type(input_request_nd): <class 'mxnet.ndarray.ndarray.NDArray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"type(input_request): {type(input_request)}\")\n",
    "print(f\"type(input_request_nd): {type(input_request_nd)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pass our converted request to model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/dist-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-07-05 10:53:31.777 mxnet-1-9-cpu-py38-ub-ml-t3-medium-3179f602905714e1b45dfa06b970:222 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-07-05 10:53:31.944 mxnet-1-9-cpu-py38-ub-ml-t3-medium-3179f602905714e1b45dfa06b970:222 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.986717"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_request_nd)[0].asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We have loaded SageMaker built-in model in our local envionment and have done prediction from it. But we can go a step further and explore this model's trained parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  Parameter fc0_weight (shape=(12, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter fc0_bias (shape=(1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter out_label (shape=(1,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.collect_params()\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to extract model's weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': array([[-1.6160294e-01],\n",
       "        [ 5.2438524e-02],\n",
       "        [ 1.5013154e-02],\n",
       "        [-4.4300285e-01],\n",
       "        [-2.0226759e+01],\n",
       "        [ 3.2423832e+00],\n",
       "        [ 7.3540364e-03],\n",
       "        [-1.4330027e+00],\n",
       "        [ 2.0710023e-01],\n",
       "        [-8.0383439e-03],\n",
       "        [-1.0465978e+00],\n",
       "        [-5.0012934e-01]], dtype=float32),\n",
       " 'bias': 44.62983}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_weight_and_bias(model):\n",
    "    params = model.collect_params()\n",
    "    weight = params['fc0_weight'].data().asnumpy()\n",
    "    bias = params['fc0_bias'].data()[0].asscalar()\n",
    "    return {\n",
    "    \"weight\": weight,\n",
    "    \"bias\": bias\n",
    "}\n",
    "\n",
    "weight_and_bias = extract_weight_and_bias(model)\n",
    "\n",
    "weight_and_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that model has 12 weights, one for each input parameter, and a bias. For linear learner there is no activation function so we can use summation formula to create a prediction using the provided weights and bais.\n",
    "\n",
    "image here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# convert the input request to np.array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_request = np.array(input_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = weight_and_bias['weight']\n",
    "bias = weight_and_bias['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.98671686516441"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# calculate the prediction\n",
    "np.sum(input_request.reshape((-1,1)) * weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.9 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/mxnet-1.9-cpu-py38-ubuntu20.04-sagemaker-v1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "bbac80ad2bfd54975e0c0f7ddf300156d5b24b5126f35dc262fa887f22fb28f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
