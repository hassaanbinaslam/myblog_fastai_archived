{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation with SageMaker Data Wrangler (Part 3)\n",
    "> A detailed guide on AWS SageMaker Data Wrangler to prepare data for machine learning models. This is a five parts series where we will prepare, import, explore, process, and export data using AWS Data Wrangler. You are reading **Part 3:Explore data with Data Wrangler visualizations**.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [aws, ml, sagemaker]\n",
    "- keyword: [aws, ml, sagemaker, wrangler]\n",
    "- image: images/copied_from_nb/images/2022-05-24-aws-sagemaker-wrangler-p3.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/2022-05-24-aws-sagemaker-wrangler-p3.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enviornment\n",
    "\n",
    "This notebook is prepared with Amazon SageMaker Studio using `Python 3 (Data Science)` Kernel and `ml.t3.medium` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This is a detailed guide on using **AWS SageMaker Data Wrangler** service to prepare data for machine learning models. SageMaker Data Wrangler is a multipurpose tool with which you can\n",
    "* import data from multiple sources\n",
    "* explore data with visualizations\n",
    "* apply transformations\n",
    "* export data for ml training\n",
    "\n",
    "There will be five parts if the post\n",
    "* [Part 1: Prepare synthetic data and place it on multiple sources](https://hassaanbinaslam.github.io/myblog/aws/ml/sagemaker/2022/05/17/aws-sagemaker-wrangler-p1.html)\n",
    "* [Part 2: Import data from multiple sources using Data Wrangler](https://hassaanbinaslam.github.io/myblog/aws/ml/sagemaker/2022/05/23/aws-sagemaker-wrangler-p2.html)\n",
    "* **Part 3: Explore data with Data Wrangler visualizations (You are here)**\n",
    "* Part 4: Preprocess data using Data Wrangler\n",
    "* Part 5: Export data for ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Explore data with Data Wrangler visualizations\n",
    "\n",
    "In this post, we will use SageMaker Data Wrangler to create some visualizations to do some exploratory analysis. Open the `customer-churn.flow` from part-2. It is also available on GitHub [here](https://github.com/hassaanbinaslam/myblog/blob/master/_notebooks/datasets/2022-05-23-aws-sagemaker-wrangler-p2/customer-churn.flow). We will create a histogram to explore the frequency distribution of daily calls. Once the flow process is open on the Data Flow UI it will look like this\n",
    "\n",
    "![customer-churn](images/2022-05-24-aws-sagemaker-wrangler-p3/customer-churn.png)\n",
    "\n",
    "Click on the 2nd join plus sign and select 'Add Analysis'. From the next analysis UI select\n",
    "* Analysis Type = Histogram\n",
    "* Analysis Name = call_minutes_churn\n",
    "* X_axis = day_min\n",
    "* Facet by = Churn?\n",
    "\n",
    "Click Preview and Data Wrangler will create the following histogram\n",
    "\n",
    "![call_minutes_chrun](images/2022-05-24-aws-sagemaker-wrangler-p3/call_minutes_chrun.png)\n",
    "\n",
    "From this histogram you can see that customers whose calls duration are 4 minutes or less are more likely to stay, and customer having call duration longer than 4 minutes are more likely to churn. Save the flow to return back to main Data Flow UI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview ML model performance using Quick Model\n",
    "\n",
    "Quick Model is another great feature of SageMaker wrangler with which we can quickly train a **Random Forrest Classification** model and analyse the importance of features. For this again click on the plus sign against the 2nd Join, and select *Add Analysis*. Then from the Analysis UI select\n",
    "\n",
    "* Analysis Type = Quick Model\n",
    "* Analysis Name = Quick model\n",
    "* Label = Churn?\n",
    "\n",
    "*Label* is our target identifier. Click preview. Data Wrangler will take around a minute to train the model, and will provide a chart with feature importances.\n",
    "\n",
    "![quick_model.png](images/2022-05-24-aws-sagemaker-wrangler-p3/quick_model.png)\n",
    "\n",
    "From this feature importance chart we can see that `day_mins` and `night_charge` features have the highest importance. It also shows that the model has achieved F1 score of 0.841 on the test data. We can take this model as a baseline and work on the importance features and model tuning to improve it's performane. Click Save to return to main Data Flow UI.\n",
    "\n",
    "# Summary\n",
    "In this post we have seen that we can quickly create visualization from Data Wrangler to do our EDA work. There are many other buildin analysis reports available (check Data Leakage and Data Quality reports) that can quickly provide very detailed analysis on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
