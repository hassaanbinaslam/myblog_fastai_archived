<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hassaanbinaslam.github.io/myblog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hassaanbinaslam.github.io/myblog/" rel="alternate" type="text/html" /><updated>2022-11-08T23:10:16-06:00</updated><id>https://hassaanbinaslam.github.io/myblog/feed.xml</id><title type="html">Random Thoughts</title><subtitle>A log of my mistakes, thoughts, and learning.</subtitle><entry><title type="html">Build Temporal Models for Univariate Time series Data with RNN, GRU, LSTM, CNN using PyTorch</title><link href="https://hassaanbinaslam.github.io/myblog/pytorch/dl/2022/11/07/timeseries-rnn-gru-lstm-cnn-pytorch.html" rel="alternate" type="text/html" title="Build Temporal Models for Univariate Time series Data with RNN, GRU, LSTM, CNN using PyTorch" /><published>2022-11-07T00:00:00-06:00</published><updated>2022-11-07T00:00:00-06:00</updated><id>https://hassaanbinaslam.github.io/myblog/pytorch/dl/2022/11/07/timeseries-rnn-gru-lstm-cnn-pytorch</id><author><name></name></author><category term="pytorch" /><category term="dl" /><summary type="html"><![CDATA[This is a practice notebook to understand and build models for timeseries data. We will explore some popular neural network architectures inclusing RNN, GRU, LSTM, and CNN.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-11-07-timeseries-rnn-gru-lstm-cnn-pytorch.jpeg" /><media:content medium="image" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-11-07-timeseries-rnn-gru-lstm-cnn-pytorch.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Detect Vanishing Gradients in Deep Neural Networks by Plotting Gradient Distributions</title><link href="https://hassaanbinaslam.github.io/myblog/pytorch/dl/2022/10/23/pytorch-vanishing-gradients-deep-neural-networks.html" rel="alternate" type="text/html" title="Detect Vanishing Gradients in Deep Neural Networks by Plotting Gradient Distributions" /><published>2022-10-23T00:00:00-05:00</published><updated>2022-10-23T00:00:00-05:00</updated><id>https://hassaanbinaslam.github.io/myblog/pytorch/dl/2022/10/23/pytorch-vanishing-gradients-deep-neural-networks</id><author><name></name></author><category term="pytorch" /><category term="dl" /><summary type="html"><![CDATA[In this notebook, we will explore how vanishing gradients can affect the training of a deep neural network. We will visualize the gradient flow from the deeper to starting layers during the backpropagation for two popular activation functions, Sigmoid and ReLU.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-23-pytorch-vanishing-gradients-deep-neural-networks.jpeg" /><media:content medium="image" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-23-pytorch-vanishing-gradients-deep-neural-networks.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Convolutional Neural Networks Filters and Feature Maps with PyTorch</title><link href="https://hassaanbinaslam.github.io/myblog/pytorch/2022/10/18/pytorch-mnist-convolutional-neural-networks.html" rel="alternate" type="text/html" title="Convolutional Neural Networks Filters and Feature Maps with PyTorch" /><published>2022-10-18T00:00:00-05:00</published><updated>2022-10-18T00:00:00-05:00</updated><id>https://hassaanbinaslam.github.io/myblog/pytorch/2022/10/18/pytorch-mnist-convolutional-neural-networks</id><author><name></name></author><category term="pytorch" /><summary type="html"><![CDATA[This is a practice notebook for implementing a convolutional neural network (CNN) on the MNIST dataset with PyTorch. We will implement the now famous LeNet-5 from Yann LeCun, a 7-layer CNN from 1989. Then we will explore and visualize the layers learned by our network including filters, feature maps, and output layers.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-18-pytorch-mnist-convolutional-neural-networks.jpeg" /><media:content medium="image" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-18-pytorch-mnist-convolutional-neural-networks.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Two Class (Binary) Logistic Regression in Pytorch</title><link href="https://hassaanbinaslam.github.io/myblog/pytorch/2022/10/11/pytorch-two-class-logistic-regression.html" rel="alternate" type="text/html" title="Two Class (Binary) Logistic Regression in Pytorch" /><published>2022-10-11T00:00:00-05:00</published><updated>2022-10-11T00:00:00-05:00</updated><id>https://hassaanbinaslam.github.io/myblog/pytorch/2022/10/11/pytorch-two-class-logistic-regression</id><author><name></name></author><category term="pytorch" /><summary type="html"><![CDATA[This is a practice notebook for implementing a two class logistic regression model in PyTorch. We will start by generating some synthetic data and then build an end-to-end pipeline to train a model. We will also see two ways to implement logistic regression models.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-11-pytorch-two-class-logistic-regression.jpeg" /><media:content medium="image" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-11-pytorch-two-class-logistic-regression.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Linear Regression with PyTorch</title><link href="https://hassaanbinaslam.github.io/myblog/pytorch/2022/10/10/pytorch-linear-regression.html" rel="alternate" type="text/html" title="Linear Regression with PyTorch" /><published>2022-10-10T00:00:00-05:00</published><updated>2022-10-10T00:00:00-05:00</updated><id>https://hassaanbinaslam.github.io/myblog/pytorch/2022/10/10/pytorch-linear-regression</id><author><name></name></author><category term="pytorch" /><summary type="html"><![CDATA[This is a practice notebook for implementing a linear regression model in PyTorch. We will start by generating some synthetic linear data and then load it into DataLoader class for creating mini-batches. Then build the complete pipeline to train the model and visualize its loss progress in TensorBoard.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-10-pytorch-linear-regression.jpeg" /><media:content medium="image" url="https://hassaanbinaslam.github.io/myblog/images/copied_from_nb/images/2022-10-10-pytorch-linear-regression.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>