---
keywords: fastai
description: This is a practice notebook for implementing a two class logistic regression model in PyTorch. We will start by generating some synthetic data and then build an end-to-end pipeline to train a model. We will also see two ways to implement logistic regression models.
title: Two Class (Binary) Logistic Regression in Pytorch
toc: true 
badges: true
comments: true
categories: [pytorch]
keyword: [ml, dl, logistic, regression, pytorch]
image: images/copied_from_nb/images/2022-10-11-pytorch-two-class-logistic-regression.jpeg
nb_path: _notebooks/2022-10-11-pytorch-two-class-logistic-regression.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-10-11-pytorch-two-class-logistic-regression.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/myblog/images/copied_from_nb/images/2022-10-11-pytorch-two-class-logistic-regression.jpeg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>In this notebook, we will train a logistic regression model using PyTorch. Given below is the summary of the steps followed in this notebook.</p>
<ul>
<li>Create a synthetic binary class dataset</li>
<li>Split the data into <code>Train</code> and <code>Validation</code> datasets. Then convert them into mini-batches using PyTorch <code>DataLoader</code> class</li>
<li>Create a Neural Net model configuration, an SGD optimizer, and a loss function</li>
<li>Create a pipeline that will train the model on given data and update the weights based on the loss </li>
<li>Compare the results with scikit-learn logistic regression model</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Environment">Environment<a class="anchor-link" href="#Environment"> </a></h2><p>This notebook is prepared with Google Colab.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">platform</span> <span class="kn">import</span> <span class="n">python_version</span>
<span class="kn">import</span> <span class="nn">sklearn</span><span class="o">,</span> <span class="nn">numpy</span><span class="o">,</span> <span class="nn">matplotlib</span><span class="o">,</span> <span class="nn">pandas</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;python==&quot;</span> <span class="o">+</span> <span class="n">python_version</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sklearn==&quot;</span> <span class="o">+</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;numpy==&quot;</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch==&quot;</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;matplotlib==&quot;</span> <span class="o">+</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>python==3.7.14
sklearn==1.0.2
numpy==1.21.6
torch==1.12.1+cu113
matplotlib==3.2.2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Credits">Credits<a class="anchor-link" href="#Credits"> </a></h2><p>This notebook takes inspiration from the book "Deep Learning with PyTorch Step-by-Step" by "Daniel Voigt Godoy". You can get the book from its website: <a href="https://pytorchstepbystep.com/">pytorchstepbystep</a>. The GitHub repository for this book has valuable notebooks and can be used independently: <a href="https://github.com/dvgodoy/PyTorchStepByStep">github.com/dvgodoy/PyTorchStepByStep</a>. Parts of the code you see in this notebook are taken <a href="https://colab.research.google.com/github/dvgodoy/PyTorchStepByStep/blob/master/Chapter03.ipynb">chapter 3 notebook</a> of the same book.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generate-synthetic-data">Generate synthetic data<a class="anchor-link" href="#Generate-synthetic-data"> </a></h2><p>In this section, we will generate some data representing two interleaving half-circles using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html">sklearn.datasets.make_moons</a>. The purpose of this function is defined as</p>
<blockquote><p>Make two interleaving half circles. A simple toy dataset to visualize clustering and classification algorithms ... It generate 2d binary classification datasets that are challenging to certain algorithms (e.g. centroid-based clustering or linear classification), including optional Gaussian noise.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># split data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=.</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="c1"># standardize data</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's view the generated data.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's plot our generated data to see how it looks.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">figure</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Train and Validation Dataset&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Training Data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Validation Data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_val</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_val</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Combined Data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_val</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_val</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-generated-data-into-PyTorch-Dataset-and-DataLoader-class">Load generated data into PyTorch Dataset and DataLoader class<a class="anchor-link" href="#Load-generated-data-into-PyTorch-Dataset-and-DataLoader-class"> </a></h2><p>In this section, we will load our data in PyTorch helper classes Dataset and DataLoader. PyTorch documentation defines them as: [see <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">basics/data_tutorial</a>]</p>
<blockquote><p>Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives:<code>torch.utils.data.DataLoader</code> and <code>torch.utils.data.Dataset</code> that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.</p>
</blockquote>
<p>For this, we first need to convert NumPy data arrays to PyTorch tensors.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Builds tensors from numpy arrays</span>
<span class="n">x_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">x_val_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_val_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y_val</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now load the tensors into Dataset and DataLoader class. PyTorch Datasets are helper classes that contain data and labels as a list of tuples. DataLoader is another helper class to create batches from Dataset tuples. <code>batch_size</code> means the number of tuples we want in a single batch. We have used 16 here since our data is small. So each fetch from DataLoader will give us a list of 16 tuples.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load tensors into Dataset and DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="c1"># Builds dataset containing ALL data points</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_val_tensor</span><span class="p">,</span> <span class="n">y_val_tensor</span><span class="p">)</span>

<span class="c1"># Builds a loader of each set</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="k">class</span> <span class="nc">DeepLearningPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="c1"># Here we define the attributes of our class</span>
        
        <span class="c1"># We start by storing the arguments as attributes </span>
        <span class="c1"># to use them later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
        <span class="c1"># Let&#39;s send the model to the specified device right away</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># These attributes are defined here, but since they are</span>
        <span class="c1"># not informed at the moment of creation, we keep them None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="c1"># These attributes are going to be computed internally</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Creates the train_step function for our model, </span>
        <span class="c1"># loss function and optimizer</span>
        <span class="c1"># Note: there are NO ARGS there! It makes use of the class</span>
        <span class="c1"># attributes directly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_train_step_fn</span><span class="p">()</span>
        <span class="c1"># Creates the val_step function for our model and loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_val_step_fn</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_loaders</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># This method allows the user to define which train_loader (and val_loader, optionally) to use</span>
        <span class="c1"># Both loaders are then assigned to attributes of the class</span>
        <span class="c1"># So they can be referred to later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="n">val_loader</span>

    <span class="k">def</span> <span class="nf">_make_train_step_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># This method does not need ARGS... it can refer to</span>
        <span class="c1"># the attributes: self.model, self.loss_fn and self.optimizer</span>
        
        <span class="c1"># Builds function that performs a step in the train loop</span>
        <span class="k">def</span> <span class="nf">perform_train_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Sets model to TRAIN mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Step 2 - Computes the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># Step 3 - Computes gradients for both &quot;a&quot; and &quot;b&quot; parameters</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="c1"># Step 4 - Updates parameters using gradients and the learning rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Returns the loss</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Returns the function that will be called inside the train loop</span>
        <span class="k">return</span> <span class="n">perform_train_step_fn</span>
    
    <span class="k">def</span> <span class="nf">_make_val_step_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Builds function that performs a step in the validation loop</span>
        <span class="k">def</span> <span class="nf">perform_val_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Sets model to EVAL mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Step 2 - Computes the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># There is no need to compute Steps 3 and 4, </span>
            <span class="c1"># since we don&#39;t update parameters during evaluation</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">perform_val_step_fn</span>
            
    <span class="k">def</span> <span class="nf">_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># The mini-batch can be used with both loaders</span>
        <span class="c1"># The argument `validation`defines which loader and </span>
        <span class="c1"># corresponding step function is going to be used</span>
        <span class="k">if</span> <span class="n">validation</span><span class="p">:</span>
            <span class="n">data_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span>
            <span class="n">step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_step_fn</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span>
            <span class="n">step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step_fn</span>

        <span class="k">if</span> <span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
            
        <span class="c1"># Once the data loader and step function, this is the </span>
        <span class="c1"># same mini-batch loop we had before</span>
        <span class="n">mini_batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">mini_batch_loss</span> <span class="o">=</span> <span class="n">step_fn</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="n">mini_batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mini_batch_loss</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mini_batch_losses</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>    
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
        <span class="c1"># To ensure reproducibility of the training process</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
            <span class="c1"># Keeps track of the numbers of epochs</span>
            <span class="c1"># by updating the corresponding attribute</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># inner loop</span>
            <span class="c1"># Performs training using mini-batches</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mini_batch</span><span class="p">(</span><span class="n">validation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># VALIDATION</span>
            <span class="c1"># no gradients in validation!</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="c1"># Performs evaluation using mini-batches</span>
                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mini_batch</span><span class="p">(</span><span class="n">validation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

            <span class="c1"># If a SummaryWriter has been set...</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
                <span class="n">scalars</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
                <span class="k">if</span> <span class="n">val_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">scalars</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">})</span>
                <span class="c1"># Records both losses for each epoch under the main tag &quot;loss&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="n">main_tag</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
                                        <span class="n">tag_scalar_dict</span><span class="o">=</span><span class="n">scalars</span><span class="p">,</span>
                                        <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
            <span class="c1"># Closes the writer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Set is to evaluation mode for predictions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> 
        <span class="c1"># Takes aNumpy input and make it a float tensor</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># Send input to device and uses model for prediction</span>
        <span class="n">y_hat_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="c1"># Set it back to train mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># Detaches it, brings it to CPU and back to Numpy</span>
        <span class="k">return</span> <span class="n">y_hat_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">plot_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">fig</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Defines a SGD optimizer to update the parameters</span>
<span class="n">optimizer_1</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a BCE loss function</span>
<span class="n">loss_fn_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">dlp_1</span> <span class="o">=</span> <span class="n">DeepLearningPipeline</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">loss_fn_1</span><span class="p">,</span> <span class="n">optimizer_1</span><span class="p">)</span>
<span class="n">dlp_1</span><span class="o">.</span><span class="n">set_loaders</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
<span class="n">dlp_1</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">dlp_1</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model_1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">logits_val</span> <span class="o">=</span> <span class="n">dlp_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
<span class="n">logits_val_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">logits_val</span><span class="p">)</span>
<span class="n">probabilities_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits_val_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">cm_thresh50</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="p">(</span><span class="n">probabilities_val</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">cm_thresh50</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>

<span class="c1"># Defines a SGD optimizer to update the parameters</span>
<span class="n">optimizer_2</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a BCE loss function</span>
<span class="n">loss_fn_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">dlp_2</span> <span class="o">=</span> <span class="n">DeepLearningPipeline</span><span class="p">(</span><span class="n">model_2</span><span class="p">,</span> <span class="n">loss_fn_2</span><span class="p">,</span> <span class="n">optimizer_2</span><span class="p">)</span>
<span class="n">dlp_2</span><span class="o">.</span><span class="n">set_loaders</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
<span class="n">dlp_2</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">dlp_2</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model_2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">probabilities_val</span> <span class="o">=</span> <span class="n">dlp_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">cm_thresh50</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="p">(</span><span class="n">probabilities_val</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">cm_thresh50</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilities_val</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
<span class="n">cm_thresh50</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="p">(</span><span class="n">probabilities_val</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">cm_thresh50</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

